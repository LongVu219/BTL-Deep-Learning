{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/k64t/person-reid\n"
     ]
    }
   ],
   "source": [
    "cd /home/k64t/person-reid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 10:17:17.297954: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-26 10:17:17.298006: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-26 10:17:17.298043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-26 10:17:17.312170: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-26 10:17:18.194802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 8,551\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_source</th>\n",
       "      <th>label</th>\n",
       "      <th>label_notes</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>ad03</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agamemnon seems to have left.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>l-93</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Smith inscribed his name over the door.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6554</th>\n",
       "      <td>g_81</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The kennel which Mary made and Fido sleeps in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4904</th>\n",
       "      <td>ks08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They all agreed to include those matters which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3295</th>\n",
       "      <td>l-93</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In the mountains there raged a fire.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>bc01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Everyone who had been worrying himself stiff s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5371</th>\n",
       "      <td>b_73</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Sally eats more the stuff.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7691</th>\n",
       "      <td>sks13</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>I sent Bill money to Mary to Sam.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4873</th>\n",
       "      <td>ks08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the student who everyone likes left.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>sks13</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What John told us is that he wants to quit sch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_source  label label_notes  \\\n",
       "7771            ad03      1         NaN   \n",
       "2914            l-93      1         NaN   \n",
       "6554            g_81      1         NaN   \n",
       "4904            ks08      1         NaN   \n",
       "3295            l-93      1         NaN   \n",
       "1058            bc01      1         NaN   \n",
       "5371            b_73      0           *   \n",
       "7691           sks13      0           *   \n",
       "4873            ks08      1         NaN   \n",
       "7216           sks13      1         NaN   \n",
       "\n",
       "                                               sentence  \n",
       "7771                      Agamemnon seems to have left.  \n",
       "2914            Smith inscribed his name over the door.  \n",
       "6554  The kennel which Mary made and Fido sleeps in ...  \n",
       "4904  They all agreed to include those matters which...  \n",
       "3295               In the mountains there raged a fire.  \n",
       "1058  Everyone who had been worrying himself stiff s...  \n",
       "5371                         Sally eats more the stuff.  \n",
       "7691                  I sent Bill money to Mary to Sam.  \n",
       "4873               the student who everyone likes left.  \n",
       "7216  What John told us is that he wants to quit sch...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import torch\n",
    "all_data_path = 'CoLA/data/'\n",
    "train_path = all_data_path + 'train.tsv'\n",
    "test_path = all_data_path + 'test.tsv'\n",
    "val_path = all_data_path + 'dev.tsv'\n",
    "\n",
    "df = pd.read_csv(train_path, delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
      "Token IDs: [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102]\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "\n",
    "for sent in sentences:\n",
    "    encoded_sent = tokenizer.encode(sent,add_special_tokens = True,)\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  47\n"
     ]
    }
   ],
   "source": [
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 64 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "MAX_LEN = 64\n",
    "\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = []\n",
    "\n",
    "for sent in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=69, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=69, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels = 2, \n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k64t/_conda/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.optim.lr_scheduler.LambdaLR at 0x7f4cbc44bb50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(),lr = 2e-5,eps = 1e-8)\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "epochs = 20\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n",
    "scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "\n",
    "def flat_accuracy_f1(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    f1_flat = f1_score(labels_flat, pred_flat)\n",
    "\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat), f1_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:23.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:46.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:10.\n",
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  F1_score: 0.88\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 2 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:11.\n",
      "\n",
      "  Average training loss: 0.25\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  F1_score: 0.88\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 3 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:12.\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.82\n",
      "  F1_score: 0.88\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 4 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:12.\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.82\n",
      "  F1_score: 0.88\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 5 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:12.\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.82\n",
      "  F1_score: 0.88\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 6 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:12.\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  F1_score: 0.89\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 7 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:12.\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  F1_score: 0.89\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 8 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:12.\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.82\n",
      "  F1_score: 0.88\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 9 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:12.\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  F1_score: 0.89\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 10 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:11.\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  F1_score: 0.89\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 11 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:11.\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  F1_score: 0.89\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 12 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:11.\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  F1_score: 0.88\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 13 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:12.\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  F1_score: 0.88\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 14 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:12.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  F1_score: 0.89\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 15 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:12.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  F1_score: 0.89\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 16 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:12.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  F1_score: 0.89\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 17 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:12.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  F1_score: 0.89\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 18 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:12.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  F1_score: 0.89\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 19 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:12.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  F1_score: 0.89\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 20 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    121.    Elapsed: 0:00:24.\n",
      "  Batch    80  of    121.    Elapsed: 0:00:48.\n",
      "  Batch   120  of    121.    Elapsed: 0:01:12.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  F1_score: 0.89\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def eval_dataset(validation_dataloader):\n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    eval_f1 = 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy, tmp_f1 = flat_accuracy_f1(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        eval_f1 += tmp_f1\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  F1_score: {0:.2f}\".format(eval_f1/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    eval_dataset(validation_dataloader)\n",
    "    \n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 1,043\n",
      "\n",
      "Predicting labels for 1,043 test sentences...\n",
      "  Accuracy: 0.82\n",
      "  F1_score: 0.88\n",
      "  Validation took: 0:01:18\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(val_path, delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "\n",
    "input_ids = []\n",
    "\n",
    "for sent in sentences:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "attention_masks = []\n",
    "\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask) \n",
    "\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "\n",
    "batch_size = 64  \n",
    "\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "eval_accuracy, eval_f1, nb_eval_steps = 0, 0, 0\n",
    "\n",
    "for batch in prediction_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    tmp_eval_accuracy, tmp_f1 = flat_accuracy_f1(logits, label_ids)\n",
    "        \n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    eval_f1 += tmp_f1\n",
    "\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"  F1_score: {0:.2f}\".format(eval_f1/nb_eval_steps))\n",
    "print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def save_model(name):\n",
    "    MODEL_PATH = Path('CoLA/models/')\n",
    "    MODEL_NAME = Path(name + '.pth')\n",
    "    MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "    #print(f'Saving model to : {MODEL_SAVE_PATH}')\n",
    "    torch.save(obj = model.state_dict(),\n",
    "            f = MODEL_SAVE_PATH)\n",
    "\n",
    "save_model('finetuneBERT_CoLA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
