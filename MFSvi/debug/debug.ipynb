{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset initializing start\n",
      "dataset initializing done\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "# model parameter setting\n",
    "batch_size = 128\n",
    "max_len = 256\n",
    "d_model = 512\n",
    "n_layers = 6\n",
    "n_heads = 8\n",
    "ffn_hidden = 512\n",
    "drop_prob = 0.1\n",
    "\n",
    "# optimizer parameter setting\n",
    "init_lr = 1e-5\n",
    "factor = 0.9\n",
    "adam_eps = 5e-9\n",
    "patience = 10\n",
    "warmup = 100\n",
    "epoch = 1000\n",
    "clip = 1.0\n",
    "weight_decay = 5e-4\n",
    "inf = float('inf')\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim import Adam\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "from collections import Counter\n",
    "import collections\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import spacy\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "class DataLoader:\n",
    "    source: Field = None\n",
    "    target: Field = None\n",
    "\n",
    "    def __init__(self, ext, tokenize_en, tokenize_vi, init_token, eos_token):\n",
    "        self.ext = ext\n",
    "        self.tokenize_en = tokenize_en\n",
    "        self.tokenize_vi = tokenize_vi\n",
    "        self.init_token = init_token\n",
    "        self.eos_token = eos_token\n",
    "        print('dataset initializing start')\n",
    "\n",
    "    def make_dataset(self):\n",
    "        if self.ext == ('.vi', '.en'):\n",
    "            self.source = Field(tokenize=self.tokenize_vi, init_token=self.init_token, eos_token=self.eos_token,\n",
    "                                lower=True, batch_first=True)\n",
    "            self.target = Field(tokenize=self.tokenize_en, init_token=self.init_token, eos_token=self.eos_token,\n",
    "                                lower=True, batch_first=True)\n",
    "\n",
    "        elif self.ext == ('.en', '.vi'):\n",
    "            self.source = Field(tokenize=self.tokenize_en, init_token=self.init_token, eos_token=self.eos_token,\n",
    "                                lower=True, batch_first=True)\n",
    "            self.target = Field(tokenize=self.tokenize_vi, init_token=self.init_token, eos_token=self.eos_token,\n",
    "                                lower=True, batch_first=True)\n",
    "\n",
    "        train_data, valid_data, test_data = Multi30k.splits(exts=self.ext, fields=(self.source, self.target))\n",
    "        return train_data, valid_data, test_data\n",
    "\n",
    "    def build_vocab(self, train_data, min_freq):\n",
    "        self.source.build_vocab(train_data, min_freq=min_freq)\n",
    "        self.target.build_vocab(train_data, min_freq=min_freq)\n",
    "\n",
    "    def make_iter(self, train, validate, test, batch_size):\n",
    "        train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train, validate, test),\n",
    "                                                                              batch_size=batch_size)\n",
    "        print('dataset initializing done')\n",
    "        return train_iterator, valid_iterator, test_iterator\n",
    "\n",
    "from pyvi import ViTokenizer\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "# Custom tokenizer function\n",
    "def custom_tokenizer(nlp, text):\n",
    "    words = ViTokenizer.tokenize(text).split()\n",
    "    return Doc(nlp.vocab, words=words)\n",
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self):\n",
    "        self.spacy_vi = spacy.blank(\"en\")\n",
    "        self.spacy_vi.tokenizer = custom_tokenizer.__get__(self.spacy_vi)\n",
    "        \n",
    "        self.spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "    def tokenize_vi(self, text):\n",
    "        return [tok.text for tok in self.spacy_vi.tokenizer(text)]\n",
    "\n",
    "    def tokenize_en(self, text):\n",
    "        return [tok.text for tok in self.spacy_en.tokenizer(text)]\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "loader = DataLoader(ext=('.en', '.vi'),\n",
    "                    tokenize_en=tokenizer.tokenize_en,\n",
    "                    tokenize_vi=tokenizer.tokenize_vi,\n",
    "                    init_token='<sos>',\n",
    "                    eos_token='<eos>')\n",
    "\n",
    "train, valid, test = loader.make_dataset()\n",
    "loader.build_vocab(train_data=train, min_freq=1)\n",
    "train_iter, valid_iter, test_iter = loader.make_iter(train, valid, test,\n",
    "                                                     batch_size=batch_size)\n",
    "\n",
    "src_pad_idx = loader.source.vocab.stoi['<pad>']\n",
    "trg_pad_idx = loader.target.vocab.stoi['<pad>']\n",
    "trg_sos_idx = loader.target.vocab.stoi['<sos>']\n",
    "\n",
    "enc_voc_size = len(loader.source.vocab)\n",
    "dec_voc_size = len(loader.target.vocab)\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Vocabulary:\n",
      "0: <unk>\n",
      "1: <pad>\n",
      "2: <sos>\n",
      "3: <eos>\n",
      "4: .\n",
      "5: the\n",
      "6: ,\n",
      "7: to\n",
      "8: of\n",
      "9: &\n",
      "10: and\n",
      "11: we\n",
      "12: you\n",
      "13: in\n",
      "14: that\n",
      "15: a\n",
      "16: this\n",
      "17: it\n",
      "18: apos;s\n",
      "19: brain\n",
      "20: is\n",
      "21: can\n",
      "22: look\n",
      "23: on\n",
      "24: do\n",
      "25: have\n",
      "26: they\n",
      "27: apos;re\n",
      "28: as\n",
      "29: i\n",
      "30: one\n",
      "31: pain\n",
      "32: --\n",
      "33: at\n",
      "34: but\n",
      "35: into\n",
      "36: like\n",
      "37: or\n",
      "38: your\n",
      "39: all\n",
      "40: are\n",
      "41: for\n",
      "42: their\n",
      "43: there\n",
      "44: what\n",
      "45: atmospheric\n",
      "46: be\n",
      "47: control\n",
      "48: inside\n",
      "49: when\n",
      "50: fly\n",
      "51: going\n",
      "52: headlines\n",
      "53: molecule\n",
      "54: our\n",
      "55: scientific\n",
      "56: see\n",
      "57: these\n",
      "58: time\n",
      "59: will\n",
      "60: with\n",
      "61: -\n",
      "62: ;\n",
      "63: able\n",
      "64: apos;t\n",
      "65: apos;ve\n",
      "66: areas\n",
      "67: climate\n",
      "68: from\n",
      "69: his\n",
      "70: hundreds\n",
      "71: make\n",
      "72: peter\n",
      "73: real\n",
      "74: scientists\n",
      "75: so\n",
      "76: technology\n",
      "77: which\n",
      "78: about\n",
      "79: activation\n",
      "80: an\n",
      "81: by\n",
      "82: each\n",
      "83: every\n",
      "84: few\n",
      "85: field\n",
      "86: form\n",
      "87: get\n",
      "88: he\n",
      "89: if\n",
      "90: mind\n",
      "91: molecules\n",
      "92: now\n",
      "93: order\n",
      "94: own\n",
      "95: people\n",
      "96: research\n",
      "97: soon\n",
      "98: study\n",
      "99: system\n",
      "100: take\n",
      "101: thousands\n",
      "102: up\n",
      "103: weight\n",
      "104: :\n",
      "105: aircraft\n",
      "106: arms\n",
      "107: because\n",
      "108: big\n",
      "109: campaign\n",
      "110: change\n",
      "111: chronic\n",
      "112: don\n",
      "113: effort\n",
      "114: equal\n",
      "115: go\n",
      "116: has\n",
      "117: here\n",
      "118: human\n",
      "119: imagine\n",
      "120: ipcc\n",
      "121: isoprene\n",
      "122: just\n",
      "123: measurements\n",
      "124: models\n",
      "125: out\n",
      "126: over\n",
      "127: paper\n",
      "128: rainforest\n",
      "129: six\n",
      "130: stuff\n",
      "131: summary\n",
      "132: thing\n",
      "133: those\n",
      "134: today\n",
      "135: tower\n",
      "136: us\n",
      "137: very\n",
      "138: was\n",
      "139: were\n",
      "140: while\n",
      "141: yourself\n",
      "142: 15,000\n",
      "143: ?\n",
      "144: above\n",
      "145: apos\n",
      "146: apos;ll\n",
      "147: apos;m\n",
      "148: arm\n",
      "149: back\n",
      "150: behind\n",
      "151: being\n",
      "152: body\n",
      "153: brains\n",
      "154: christopher\n",
      "155: community\n",
      "156: countries\n",
      "157: dangerous\n",
      "158: data\n",
      "159: decharms\n",
      "160: dozen\n",
      "161: even\n",
      "162: flex\n",
      "163: flight\n",
      "164: flying\n",
      "165: generation\n",
      "166: group\n",
      "167: hand\n",
      "168: happen\n",
      "169: happening\n",
      "170: how\n",
      "171: important\n",
      "172: incredibly\n",
      "173: inject\n",
      "174: integrations\n",
      "175: literally\n",
      "176: longer\n",
      "177: me\n",
      "178: middle\n",
      "179: months\n",
      "180: more\n",
      "181: much\n",
      "182: my\n",
      "183: narrow\n",
      "184: new\n",
      "185: non\n",
      "186: other\n",
      "187: others\n",
      "188: pages\n",
      "189: perform\n",
      "190: pieces\n",
      "191: pike\n",
      "192: plane\n",
      "193: probably\n",
      "194: process\n",
      "195: processes\n",
      "196: produce\n",
      "197: producing\n",
      "198: program\n",
      "199: put\n",
      "200: quot\n",
      "201: rachel\n",
      "202: recently\n",
      "203: report\n",
      "204: run\n",
      "205: same\n",
      "206: scale\n",
      "207: science\n",
      "208: seeing\n",
      "209: seen\n",
      "210: select\n",
      "211: show\n",
      "212: small\n",
      "213: smog\n",
      "214: some\n",
      "215: special\n",
      "216: still\n",
      "217: subsection\n",
      "218: takes\n",
      "219: taking\n",
      "220: things\n",
      "221: thoughts\n",
      "222: took\n",
      "223: topics\n",
      "224: two\n",
      "225: understand\n",
      "226: understanding\n",
      "227: using\n",
      "228: want\n",
      "229: wave\n",
      "230: way\n",
      "231: world\n",
      "232: write\n",
      "233: written\n",
      "234: year\n",
      "235: years\n",
      "236: 10\n",
      "237: 100\n",
      "238: 11\n",
      "239: 113\n",
      "240: 120\n",
      "241: 130\n",
      "242: 21st\n",
      "243: 3d\n",
      "244: 4\n",
      "245: 40\n",
      "246: 400\n",
      "247: 44\n",
      "248: 620\n",
      "249: 64\n",
      "250: 65,000\n",
      "251: 900\n",
      "252: activity\n",
      "253: actually\n",
      "254: affects\n",
      "255: air\n",
      "256: allows\n",
      "257: almost\n",
      "258: also\n",
      "259: alternative\n",
      "260: although\n",
      "261: always\n",
      "262: am\n",
      "263: amount\n",
      "264: analysis\n",
      "265: anatomy\n",
      "266: annual\n",
      "267: another\n",
      "268: any\n",
      "269: anything\n",
      "270: apos;d\n",
      "271: approximately\n",
      "272: around\n",
      "273: arteries\n",
      "274: ask\n",
      "275: aspects\n",
      "276: assessment\n",
      "277: assessments\n",
      "278: assimilation\n",
      "279: atmosphere\n",
      "280: attacked\n",
      "281: audience\n",
      "282: away\n",
      "283: ba146\n",
      "284: banks\n",
      "285: been\n",
      "286: before\n",
      "287: below\n",
      "288: bicep\n",
      "289: biofuels\n",
      "290: blood\n",
      "291: bloodstream\n",
      "292: blow\n",
      "293: board\n",
      "294: bold\n",
      "295: both\n",
      "296: boxes\n",
      "297: branches\n",
      "298: brought\n",
      "299: builds\n",
      "300: burn\n",
      "301: calculating\n",
      "302: called\n",
      "303: cambridge\n",
      "304: canopy\n",
      "305: car\n",
      "306: cells\n",
      "307: chamber\n",
      "308: channels\n",
      "309: chapters\n",
      "310: chemist\n",
      "311: chemistry\n",
      "312: circuits\n",
      "313: clearance\n",
      "314: clinical\n",
      "315: clip\n",
      "316: collapsed\n",
      "317: colleague\n",
      "318: combustion\n",
      "319: come\n",
      "320: coming\n",
      "321: completely\n",
      "322: contributed\n",
      "323: controlled\n",
      "324: controlling\n",
      "325: couch\n",
      "326: could\n",
      "327: course\n",
      "328: crops\n",
      "329: days\n",
      "330: decrease\n",
      "331: deep\n",
      "332: demonstrates\n",
      "333: despite\n",
      "334: detail\n",
      "335: didn\n",
      "336: difficult\n",
      "337: display\n",
      "338: doesn\n",
      "339: dollars\n",
      "340: down\n",
      "341: dozens\n",
      "342: el\n",
      "343: electrodes\n",
      "344: emissions\n",
      "345: emitted\n",
      "346: emotions\n",
      "347: endogenous\n",
      "348: enormous\n",
      "349: enough\n",
      "350: enter\n",
      "351: envision\n",
      "352: equipment\n",
      "353: euphore\n",
      "354: example\n",
      "355: experiences\n",
      "356: explosions\n",
      "357: faam\n",
      "358: fact\n",
      "359: feel\n",
      "360: first\n",
      "361: flies\n",
      "362: fmri\n",
      "363: forces\n",
      "364: found\n",
      "365: fourth\n",
      "366: francisco\n",
      "367: full\n",
      "368: functioning\n",
      "369: gathering\n",
      "370: glimpse\n",
      "371: global\n",
      "372: goes\n",
      "373: grid\n",
      "374: gs\n",
      "375: had\n",
      "376: happens\n",
      "377: harnessed\n",
      "378: headline\n",
      "379: heard\n",
      "380: helping\n",
      "381: her\n",
      "382: hi\n",
      "383: hire\n",
      "384: huge\n",
      "385: hung\n",
      "386: illion\n",
      "387: imaging\n",
      "388: impact\n",
      "389: importantly\n",
      "390: inclination\n",
      "391: incline\n",
      "392: information\n",
      "393: insides\n",
      "394: interface\n",
      "395: intergovernmental\n",
      "396: invasively\n",
      "397: inventor\n",
      "398: investigational\n",
      "399: its\n",
      "400: joined\n",
      "401: journalists\n",
      "402: key\n",
      "403: kind\n",
      "404: knife\n",
      "405: know\n",
      "406: knowledge\n",
      "407: laboratory\n",
      "408: labs\n",
      "409: largest\n",
      "410: learn\n",
      "411: learning\n",
      "412: leave\n",
      "413: left\n",
      "414: lengths\n",
      "415: let\n",
      "416: looked\n",
      "417: looking\n",
      "418: makers\n",
      "419: making\n",
      "420: malaysia\n",
      "421: maneuvering\n",
      "422: massive\n",
      "423: matrix\n",
      "424: may\n",
      "425: maybe\n",
      "426: measure\n",
      "427: meeting\n",
      "428: meters\n",
      "429: methane\n",
      "430: military\n",
      "431: milliseconds\n",
      "432: mimic\n",
      "433: minds\n",
      "434: minute\n",
      "435: minutes\n",
      "436: model\n",
      "437: moves\n",
      "438: mri\n",
      "439: muscles\n",
      "440: need\n",
      "441: neuroscientist\n",
      "442: never\n",
      "443: niño\n",
      "444: no\n",
      "445: normally\n",
      "446: not\n",
      "447: off\n",
      "448: only\n",
      "449: opiates\n",
      "450: organic\n",
      "451: oscillation\n",
      "452: panel\n",
      "453: papers\n",
      "454: part\n",
      "455: pathway\n",
      "456: pathways\n",
      "457: patient\n",
      "458: patients\n",
      "459: pattern\n",
      "460: per\n",
      "461: percent\n",
      "462: person\n",
      "463: phd\n",
      "464: pills\n",
      "465: pilots\n",
      "466: place\n",
      "467: planet\n",
      "468: plus\n",
      "469: points\n",
      "470: policy\n",
      "471: possibility\n",
      "472: produces\n",
      "473: provides\n",
      "474: pull\n",
      "475: pursuit\n",
      "476: quality\n",
      "477: question\n",
      "478: radiation\n",
      "479: raise\n",
      "480: reading\n",
      "481: really\n",
      "482: region\n",
      "483: releases\n",
      "484: reviewed\n",
      "485: reviewers\n",
      "486: risky\n",
      "487: robotic\n",
      "488: royal\n",
      "489: san\n",
      "490: satellite\n",
      "491: scanner\n",
      "492: scanners\n",
      "493: second\n",
      "494: selected\n",
      "495: shock\n",
      "496: shrink\n",
      "497: similar\n",
      "498: sort\n",
      "499: spaceship\n",
      "500: spain\n",
      "501: spot\n",
      "502: state\n",
      "503: student\n",
      "504: students\n",
      "505: studies\n",
      "506: sub\n",
      "507: subject\n",
      "508: subsections\n",
      "509: such\n",
      "510: supercomputers\n",
      "511: tag\n",
      "512: taken\n",
      "513: talk\n",
      "514: team\n",
      "515: tell\n",
      "516: ten\n",
      "517: terribly\n",
      "518: test\n",
      "519: than\n",
      "520: thank\n",
      "521: then\n",
      "522: therapist\n",
      "523: thousand\n",
      "524: three\n",
      "525: through\n",
      "526: times\n",
      "527: timescales\n",
      "528: too\n",
      "529: top\n",
      "530: topic\n",
      "531: trials\n",
      "532: try\n",
      "533: typically\n",
      "534: upper\n",
      "535: use\n",
      "536: vacation\n",
      "537: valleys\n",
      "538: variables\n",
      "539: varied\n",
      "540: variety\n",
      "541: wanted\n",
      "542: watch\n",
      "543: watching\n",
      "544: watchtower\n",
      "545: ways\n",
      "546: weather\n",
      "547: weeks\n",
      "548: well\n",
      "549: where\n",
      "550: white\n",
      "551: who\n",
      "552: wide\n",
      "553: words\n",
      "554: working\n",
      "555: worth\n",
      "556: would\n",
      "557: wrote\n",
      "558: yellow\n",
      "559: yoked\n",
      "560: zeta\n",
      "Target Vocabulary Size: 561\n"
     ]
    }
   ],
   "source": [
    "print(\"Target Vocabulary:\")\n",
    "for idx, token in enumerate(loader.source.vocab.itos):\n",
    "    print(f\"{idx}: {token}\")\n",
    "\n",
    "print(f\"Target Vocabulary Size: {len(loader.source.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Vocabulary:\n",
      "0: <unk>\n",
      "1: <pad>\n",
      "2: <sos>\n",
      "3: <eos>\n",
      "4: .\n",
      "5: ,\n",
      "6: bạn\n",
      "7: của\n",
      "8: một\n",
      "9: trong\n",
      "10: là\n",
      "11: và\n",
      "12: -\n",
      "13: những\n",
      "14: này\n",
      "15: não\n",
      "16: chúng_tôi\n",
      "17: các\n",
      "18: có_thể\n",
      "19: để\n",
      "20: được\n",
      "21: có\n",
      "22: như\n",
      "23: thấy\n",
      "24: vào\n",
      "25: đó\n",
      "26: về\n",
      "27: khi\n",
      "28: nghiên_cứu\n",
      "29: tôi\n",
      "30: chúng_ta\n",
      "31: sẽ\n",
      "32: bộ\n",
      "33: cho\n",
      "34: khoa_học\n",
      "35: nhìn\n",
      "36: ra\n",
      "37: ta\n",
      "38: đây\n",
      "39: đã\n",
      "40: hàng\n",
      "41: phân_tử\n",
      "42: với\n",
      "43: bay\n",
      "44: họ\n",
      "45: trên\n",
      "46: từ\n",
      "47: đau\n",
      "48: đến\n",
      "49: ở\n",
      "50: không\n",
      "51: làm\n",
      "52: thế\n",
      "53: điều_khiển\n",
      "54: bên\n",
      "55: nhà\n",
      "56: điều\n",
      "57: chính\n",
      "58: cách\n",
      "59: cơn\n",
      "60: hay\n",
      "61: khác\n",
      "62: mà\n",
      "63: nhưng\n",
      "64: nó\n",
      "65: phải\n",
      "66: thời_gian\n",
      "67: anh\n",
      "68: khí_hậu\n",
      "69: khí_quyển\n",
      "70: mình\n",
      "71: nhiều\n",
      "72: nhỏ\n",
      "73: phép\n",
      "74: rất\n",
      "75: ;\n",
      "76: chiếc\n",
      "77: còn\n",
      "78: cả\n",
      "79: gì\n",
      "80: lại\n",
      "81: lớn\n",
      "82: năm\n",
      "83: peter\n",
      "84: theo\n",
      "85: thực\n",
      "86: trăm\n",
      "87: viết\n",
      "88: đề_tài\n",
      "89: đều\n",
      "90: &\n",
      "91: bài\n",
      "92: bản\n",
      "93: chỉ\n",
      "94: cái\n",
      "95: cánh_tay\n",
      "96: công_nghệ\n",
      "97: cùng\n",
      "98: cần\n",
      "99: hơn\n",
      "100: hệ_thống\n",
      "101: isoprene\n",
      "102: lượng\n",
      "103: máy_bay\n",
      "104: mỗi\n",
      "105: ngàn\n",
      "106: người\n",
      "107: nói\n",
      "108: nếu\n",
      "109: thực_hiện\n",
      "110: trọng_lượng\n",
      "111: từng\n",
      "112: đang\n",
      "113: đưa\n",
      "114: biến_đổi\n",
      "115: biết\n",
      "116: chọn\n",
      "117: con_người\n",
      "118: cuộc\n",
      "119: cũng\n",
      "120: dòng\n",
      "121: gần\n",
      "122: hoàn_toàn\n",
      "123: hoạt_động\n",
      "124: học\n",
      "125: ipcc\n",
      "126: khí_thải\n",
      "127: kinh_niên\n",
      "128: lĩnh_vực\n",
      "129: muốn\n",
      "130: mô_hình\n",
      "131: nỗ_lực\n",
      "132: phòng\n",
      "133: qua\n",
      "134: quan_trọng\n",
      "135: rừng\n",
      "136: sau\n",
      "137: sâu\n",
      "138: sản_xuất\n",
      "139: sớm\n",
      "140: sử_dụng\n",
      "141: sự\n",
      "142: tay\n",
      "143: thông_tin\n",
      "144: thứ\n",
      "145: thực_sự\n",
      "146: tiêu_đề\n",
      "147: tiểu\n",
      "148: tá\n",
      "149: tìm\n",
      "150: tất_cả\n",
      "151: vì\n",
      "152: vùng\n",
      "153: vẫn\n",
      "154: xem_xét\n",
      "155: #\n",
      "156: 10\n",
      "157: 15,000\n",
      "158: ?\n",
      "159: bây_giờ\n",
      "160: bước\n",
      "161: bằng\n",
      "162: bệnh_nhân\n",
      "163: bởi\n",
      "164: bụi\n",
      "165: christopher\n",
      "166: chuyến\n",
      "167: chương\n",
      "168: con\n",
      "169: cụ_thể\n",
      "170: decharms\n",
      "171: dưới\n",
      "172: gia\n",
      "173: giây\n",
      "174: giơ\n",
      "175: giữa\n",
      "176: hoá_học\n",
      "177: hãy\n",
      "178: hôm_nay\n",
      "179: hội_nghị\n",
      "180: khói\n",
      "181: không_khí\n",
      "182: khảo_sát\n",
      "183: khỏi\n",
      "184: khổng_lồ\n",
      "185: kích_hoạt\n",
      "186: lên\n",
      "187: máy_quét\n",
      "188: mảnh\n",
      "189: mẫu\n",
      "190: mỗi_một\n",
      "191: mới\n",
      "192: mục\n",
      "193: ngay\n",
      "194: nghiên_cứu_sinh\n",
      "195: nguy_hiểm\n",
      "196: nhóm\n",
      "197: nào\n",
      "198: nổ\n",
      "199: nữa\n",
      "200: phi_cơ\n",
      "201: quot\n",
      "202: quy_trình\n",
      "203: quá_trình\n",
      "204: quốc_gia\n",
      "205: suy_nghĩ\n",
      "206: sáu\n",
      "207: số\n",
      "208: tháng\n",
      "209: tháp\n",
      "210: thế_giới\n",
      "211: thế_hệ\n",
      "212: toàn_cầu\n",
      "213: trang\n",
      "214: trông\n",
      "215: tác_động\n",
      "216: tâm_trí\n",
      "217: tên\n",
      "218: tít\n",
      "219: tóm_lược\n",
      "220: tưởng_tượng\n",
      "221: tạo\n",
      "222: tổng\n",
      "223: việc\n",
      "224: vài\n",
      "225: vâng\n",
      "226: vô_cùng\n",
      "227: vẫy\n",
      "228: vậy\n",
      "229: xa\n",
      "230: xin\n",
      "231: xảy\n",
      "232: ý_nghĩa\n",
      "233: đi\n",
      "234: đo\n",
      "235: đo_đạc\n",
      "236: đường\n",
      "237: đằng\n",
      "238: đặc_biệt\n",
      "239: %\n",
      "240: 1\n",
      "241: 100\n",
      "242: 1000\n",
      "243: 11\n",
      "244: 113\n",
      "245: 120\n",
      "246: 130\n",
      "247: 21\n",
      "248: 2g\n",
      "249: 3\n",
      "250: 4\n",
      "251: 40\n",
      "252: 400\n",
      "253: 44\n",
      "254: 6\n",
      "255: 620\n",
      "256: 64\n",
      "257: 65000\n",
      "258: 900\n",
      "259: 91\n",
      "260: 93\n",
      "261: :\n",
      "262: ba\n",
      "263: ba146\n",
      "264: ban\n",
      "265: biến_số\n",
      "266: bàn\n",
      "267: báo\n",
      "268: bơm\n",
      "269: bạch_cầu\n",
      "270: bản_thân\n",
      "271: bất_kỳ\n",
      "272: bắt_chước\n",
      "273: bề_mặt\n",
      "274: bị\n",
      "275: bờ\n",
      "276: bức_xạ\n",
      "277: cambridge\n",
      "278: cao\n",
      "279: chi_tiết\n",
      "280: chia\n",
      "281: chiếm\n",
      "282: chiều\n",
      "283: chuyên\n",
      "284: chuyên_gia\n",
      "285: chuyện\n",
      "286: chào\n",
      "287: cháy\n",
      "288: chính_phủ\n",
      "289: chính_sách\n",
      "290: chúng\n",
      "291: chưa\n",
      "292: chạy\n",
      "293: chấm\n",
      "294: chất\n",
      "295: chất_lượng\n",
      "296: chậm\n",
      "297: chặt\n",
      "298: chống\n",
      "299: chồng\n",
      "300: chở\n",
      "301: chụp\n",
      "302: chủ_đề\n",
      "303: co_dãn\n",
      "304: cong\n",
      "305: cám_ơn\n",
      "306: cánh\n",
      "307: câu\n",
      "308: có_thể_hình_dung\n",
      "309: công_việc\n",
      "310: cơ\n",
      "311: cơ_bắp\n",
      "312: cơ_thể\n",
      "313: cảm_nhận\n",
      "314: cảm_xúc\n",
      "315: cống_hiến\n",
      "316: cộng_đồng\n",
      "317: cực\n",
      "318: dao\n",
      "319: dao_động\n",
      "320: di_chuyển\n",
      "321: di_động\n",
      "322: diễn\n",
      "323: do\n",
      "324: du_lịch\n",
      "325: dành\n",
      "326: dân_số\n",
      "327: dù\n",
      "328: dù_vậy\n",
      "329: dần\n",
      "330: dứt\n",
      "331: dự_án\n",
      "332: el_niño\n",
      "333: euphore\n",
      "334: faam\n",
      "335: fmri\n",
      "336: ghi\n",
      "337: ghế\n",
      "338: giai_đoạn\n",
      "339: giá\n",
      "340: giúp\n",
      "341: giường\n",
      "342: giải_quyết\n",
      "343: giảm\n",
      "344: giấy\n",
      "345: giật\n",
      "346: giống\n",
      "347: giới_thiệu\n",
      "348: gây\n",
      "349: góc\n",
      "350: góp_phần\n",
      "351: gọi\n",
      "352: gồm\n",
      "353: hai\n",
      "354: hiểu\n",
      "355: hiểu_biết\n",
      "356: hoàng_gia\n",
      "357: hoặc\n",
      "358: hình_dung\n",
      "359: hằng\n",
      "360: hỏi\n",
      "361: hộp\n",
      "362: hữu_cơ\n",
      "363: illion\n",
      "364: khiến\n",
      "365: khó\n",
      "366: khắp\n",
      "367: kiến_thức\n",
      "368: kiểm_định\n",
      "369: kèm\n",
      "370: kênh\n",
      "371: kí_ức\n",
      "372: kẹp\n",
      "373: kết_nối\n",
      "374: liên\n",
      "375: luôn\n",
      "376: làm_bạn\n",
      "377: làm_chủ\n",
      "378: làm_hàng\n",
      "379: làm_nên\n",
      "380: làm_việc\n",
      "381: lần\n",
      "382: lập\n",
      "383: lập_trình\n",
      "384: lệnh\n",
      "385: lụa\n",
      "386: lựa_chọn\n",
      "387: lực\n",
      "388: ma_trận\n",
      "389: malaysia\n",
      "390: mang\n",
      "391: mili\n",
      "392: miệt_mài\n",
      "393: mri\n",
      "394: màu\n",
      "395: máy_tính\n",
      "396: mét\n",
      "397: mêtan\n",
      "398: mũ\n",
      "399: mạch_máu\n",
      "400: mạo_hiểm\n",
      "401: mặc_dù\n",
      "402: mọi\n",
      "403: mức\n",
      "404: nay\n",
      "405: ngang_ngửa\n",
      "406: nghe\n",
      "407: nghiêng\n",
      "408: nghiệm\n",
      "409: nghĩa_đen\n",
      "410: ngoài\n",
      "411: ngành\n",
      "412: ngày\n",
      "413: ngắn\n",
      "414: nhanh_chóng\n",
      "415: nhau\n",
      "416: nhiên_liệu\n",
      "417: nhà_báo\n",
      "418: nhánh\n",
      "419: nhất\n",
      "420: nên\n",
      "421: nằm\n",
      "422: phi_thuyền\n",
      "423: phân_tích\n",
      "424: phép_tính\n",
      "425: phê_bình\n",
      "426: phía\n",
      "427: phút\n",
      "428: phương_diện\n",
      "429: phương_pháp\n",
      "430: phản_ứng\n",
      "431: phần\n",
      "432: phỏng\n",
      "433: pike\n",
      "434: quanh\n",
      "435: quy_mô\n",
      "436: quân_đội\n",
      "437: quét\n",
      "438: rachel\n",
      "439: robot\n",
      "440: rằng\n",
      "441: rừng_già\n",
      "442: san_francisco\n",
      "443: shock\n",
      "444: sinh_học\n",
      "445: siêu\n",
      "446: so\n",
      "447: suốt\n",
      "448: sáng_chế\n",
      "449: sát_hạch\n",
      "450: sông\n",
      "451: sơ_lược\n",
      "452: sọ\n",
      "453: sở_hữu\n",
      "454: sở_thích\n",
      "455: tham_dự\n",
      "456: tham_gia\n",
      "457: thay_đổi\n",
      "458: then_chốt\n",
      "459: theo_dõi\n",
      "460: theo_đuổi\n",
      "461: thiết_bị\n",
      "462: thu\n",
      "463: thung_lũng\n",
      "464: thuê\n",
      "465: thuốc_viên\n",
      "466: thuộc\n",
      "467: thành\n",
      "468: tháp_canh\n",
      "469: thì\n",
      "470: thí_nghiệm\n",
      "471: thôi\n",
      "472: thông_thường\n",
      "473: thùng\n",
      "474: thường\n",
      "475: thải\n",
      "476: thần_kinh\n",
      "477: thắt\n",
      "478: thời_tiết\n",
      "479: thứ_tư\n",
      "480: thử\n",
      "481: thử_nghiệm\n",
      "482: thực_tế\n",
      "483: thực_địa\n",
      "484: tia\n",
      "485: tiến_sĩ\n",
      "486: tiết\n",
      "487: tiểu_mục\n",
      "488: to_lớn\n",
      "489: treo\n",
      "490: trái\n",
      "491: trí_tuệ\n",
      "492: trước\n",
      "493: trị_giá\n",
      "494: trị_liệu\n",
      "495: tuần\n",
      "496: tuần_hoàn\n",
      "497: táo_bạo\n",
      "498: tây_ban_nha\n",
      "499: tìm_hiểu\n",
      "500: tìm_kiếm\n",
      "501: tình_cờ\n",
      "502: tích_phân\n",
      "503: tính_chất\n",
      "504: tính_toán\n",
      "505: tương_tự\n",
      "506: tại\n",
      "507: tấn_công\n",
      "508: tất_nhiên\n",
      "509: tầng\n",
      "510: tập\n",
      "511: tắt\n",
      "512: tới\n",
      "513: tụ_hội\n",
      "514: tự\n",
      "515: tự_nhiên\n",
      "516: vàng\n",
      "517: vào_khoảng\n",
      "518: vì_vậy\n",
      "519: ví_dụ\n",
      "520: vòm\n",
      "521: vòng\n",
      "522: vấn_đề\n",
      "523: vẻ\n",
      "524: vệ_tinh\n",
      "525: vốn\n",
      "526: xe\n",
      "527: xoa_dịu\n",
      "528: xong\n",
      "529: xung_kích_hoạt\n",
      "530: xâm_nhập\n",
      "531: xếp\n",
      "532: zeta\n",
      "533: ý_nghĩ\n",
      "534: ý_thức\n",
      "535: đa_dạng\n",
      "536: đau_đớn\n",
      "537: điều_hành\n",
      "538: điểm\n",
      "539: điện_cực\n",
      "540: đoàn\n",
      "541: đánh_giá\n",
      "542: đâu\n",
      "543: đính\n",
      "544: đô_la\n",
      "545: đại_loại\n",
      "546: đạt\n",
      "547: đất\n",
      "548: đầu_tiên\n",
      "549: đến_nỗi\n",
      "550: đề_nghị\n",
      "551: định_hình\n",
      "552: đọc\n",
      "553: đồng\n",
      "554: đồng_hoá\n",
      "555: đồng_nghiệp\n",
      "556: độ\n",
      "557: độc_giả\n",
      "558: động_cơ\n",
      "559: động_mạch\n",
      "560: ảnh\n",
      "561: ảnh_hưởng\n",
      "562: ấy\n",
      "Target Vocabulary Size: 563\n"
     ]
    }
   ],
   "source": [
    "print(\"Target Vocabulary:\")\n",
    "for idx, token in enumerate(loader.target.vocab.itos):\n",
    "    print(f\"{idx}: {token}\")\n",
    "\n",
    "print(f\"Target Vocabulary Size: {len(loader.target.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 19,278,387 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1147923/3693060398.py:322: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  nn.init.kaiming_uniform(m.weight.data)\n",
      "/home/dominhnhat/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/dominhnhat/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "class ScaleDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaleDotProductAttention, self).__init__()\n",
    "        self.softmax = nn.Softmax(dim = -1)\n",
    "\n",
    "    def forward(self, q, k ,v, mask = None, e = 1e-12):\n",
    "        batch_size, head, length, d_tensor = k.size()\n",
    "        k_t = k.transpose(2,3)\n",
    "        score = (q @ k_t) / math.sqrt(d_tensor)\n",
    "\n",
    "        if mask is not None:\n",
    "            score = score.masked_fill(mask == 0, -100000)\n",
    "\n",
    "        score = self.softmax(score)\n",
    "        v = score @ v\n",
    "        return v, score\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_head):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_head = n_head # Number of attention heads\n",
    "        self.attention = ScaleDotProductAttention()\n",
    "        self.w_q = nn.Linear(d_model, d_model) # Query transformation\n",
    "        self.w_k = nn.Linear(d_model, d_model) # Key\n",
    "        self.w_v = nn.Linear(d_model, d_model) # Value\n",
    "        self.w_concat = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split(self, tensor):\n",
    "        batch_size, length, d_model = tensor.size()\n",
    "        d_tensor = d_model // self.n_head\n",
    "        tensor = tensor.view(batch_size, length, self.n_head, d_tensor).transpose(1,2).to(device)\n",
    "        return tensor\n",
    "\n",
    "    def concat(self, tensor):\n",
    "        batch_size, head, length, d_tensor = tensor.size()\n",
    "        d_model = head * d_tensor\n",
    "        tensor = tensor.transpose(1,2).contiguous().view(batch_size, length, d_model).to(device)\n",
    "        return tensor\n",
    "\n",
    "    def forward(self, q, k, v, mask = None):\n",
    "        q, k, v = self.w_q(q), self.w_k(k), self.w_v(v)\n",
    "        q, k, v = self.split(q), self.split(k), self.split(v)\n",
    "\n",
    "        out, attention = self.attention(q, k, v, mask = mask)\n",
    "\n",
    "        out = self.concat(out)\n",
    "        out = self.w_concat(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, hidden)\n",
    "        self.linear2 = nn.Linear(hidden, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p = drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.relu(self.linear2(self.dropout(self.relu(self.linear1(x)))))\n",
    "        #return self.linear2(self.dropout(self.relu(self.linear1(x))))\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        self.encoding = torch.zeros(max_len, d_model).to(device)\n",
    "        self.encoding.requires_grad = False\n",
    "        pos = torch.arange(0, max_len, dtype = torch.float).unsqueeze(1).to(device)\n",
    "        _2i = torch.arange(0, d_model, step = 2).float().to(device)\n",
    "        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i/d_model)))\n",
    "        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i/d_model)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.size()\n",
    "        return self.encoding[:seq_len, :].to(device)\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-12):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, unbiased=False, keepdim=True)\n",
    "        # '-1' means last dimension.\n",
    "\n",
    "        out = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        out = self.gamma * out + self.beta\n",
    "        return out\n",
    "\n",
    "class TokenEmbedding(nn.Embedding):\n",
    "   def __init__(self, vocab_size, d_model):\n",
    "       super(TokenEmbedding, self).__init__(vocab_size, d_model, padding_idx=1)\n",
    "\n",
    "class TransformerEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, max_len, drop_prob):\n",
    "        super(TransformerEmbedding, self).__init__()\n",
    "        self.tok_emb = TokenEmbedding(vocab_size, d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model, max_len)\n",
    "        self.drop_out = nn.Dropout(p=drop_prob)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        tok_emb = self.tok_emb(x)\n",
    "        pos_emb = self.pos_emb(x)\n",
    "        return self.drop_out(tok_emb + pos_emb)\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, n_head, drop_prob):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, n_head)\n",
    "        self.ffn = PositionwiseFeedForward(d_model, ffn_hidden, drop_prob)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(p = drop_prob)\n",
    "        self.dropout2 = nn.Dropout(p = drop_prob)\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        _x = x\n",
    "        x = self.attention(x, x, x, src_mask)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.norm1(x + _x)\n",
    "\n",
    "        _x = x\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.norm2(x + _x)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, enc_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, drop_prob):\n",
    "        super().__init__()\n",
    "        self.emb = TransformerEmbedding(d_model=d_model,\n",
    "                                        max_len=max_len,\n",
    "                                        vocab_size=enc_voc_size,\n",
    "                                        drop_prob=drop_prob)\n",
    "\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model=d_model,\n",
    "                                                  ffn_hidden=ffn_hidden,\n",
    "                                                  n_head=n_head,\n",
    "                                                  drop_prob=drop_prob)\n",
    "                                     for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        x = self.emb(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, n_head, drop_prob):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attention = MultiHeadAttention(d_model, n_head)\n",
    "        self.enc_dec_attention = MultiHeadAttention(d_model, n_head)\n",
    "        self.ffn = PositionwiseFeedForward(d_model, ffn_hidden, drop_prob)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "        self.norm3 = LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(p = drop_prob)\n",
    "        self.dropout2 = nn.Dropout(p = drop_prob)\n",
    "        self.dropout3 = nn.Dropout(p = drop_prob)\n",
    "\n",
    "    def forward(self, dec, enc, trg_mask, src_mask):\n",
    "        _x = dec\n",
    "        x = self.self_attention(dec, dec, dec, trg_mask)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.norm1(x + _x)\n",
    "\n",
    "        if enc is not None:\n",
    "            _x = x\n",
    "            x = self.enc_dec_attention(q=x, k=enc, v=enc, mask=src_mask)\n",
    "\n",
    "            x = self.dropout2(x)\n",
    "            x = self.norm2(x + _x)\n",
    "\n",
    "        _x = x\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.norm3(x + _x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dec_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, drop_prob):\n",
    "        super().__init__()\n",
    "        self.emb = TransformerEmbedding(d_model=d_model,\n",
    "                                        drop_prob=drop_prob,\n",
    "                                        max_len=max_len,\n",
    "                                        vocab_size=dec_voc_size)\n",
    "\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model=d_model,\n",
    "                                                  ffn_hidden=ffn_hidden,\n",
    "                                                  n_head=n_head,\n",
    "                                                  drop_prob=drop_prob)\n",
    "                                     for _ in range(n_layers)])\n",
    "\n",
    "        self.linear = nn.Linear(d_model, dec_voc_size)\n",
    "\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        trg = self.emb(trg)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            trg = layer(trg, enc_src, trg_mask, src_mask)\n",
    "        output = self.linear(trg)\n",
    "        return output\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, src_pad_idx, trg_pad_idx, trg_sos_idx, enc_voc_size, dec_voc_size, d_model, n_head, max_len,\n",
    "                 ffn_hidden, n_layers, drop_prob):\n",
    "        super().__init__()\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.trg_sos_idx = trg_sos_idx\n",
    "        self.encoder = Encoder(d_model=d_model,\n",
    "                               n_head=n_head,\n",
    "                               max_len=max_len,\n",
    "                               ffn_hidden=ffn_hidden,\n",
    "                               enc_voc_size=enc_voc_size,\n",
    "                               drop_prob=drop_prob,\n",
    "                               n_layers=n_layers)\n",
    "\n",
    "        self.decoder = Decoder(d_model=d_model,\n",
    "                               n_head=n_head,\n",
    "                               max_len=max_len,\n",
    "                               ffn_hidden=ffn_hidden,\n",
    "                               dec_voc_size=dec_voc_size,\n",
    "                               drop_prob=drop_prob,\n",
    "                               n_layers=n_layers)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        output = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "        return output\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask.to(device)\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(3)\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_sub_mask = torch.tril(torch.ones(trg_len, trg_len)).type(torch.ByteTensor).to(device)\n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        return trg_mask.to(device)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "def get_bleu(pred_seq, label_seq, k = 4):\n",
    "    \"\"\"Compute the BLEU.\"\"\"\n",
    "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
    "\n",
    "\n",
    "    for n in range(1, min(k, len_pred) + 1):\n",
    "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
    "        for i in range(len_label - n + 1):\n",
    "            label_subs[' '.join(label_tokens[i: i + n])] += 1\n",
    "\n",
    "        for i in range(len_pred - n + 1):\n",
    "            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n",
    "                num_matches += 1\n",
    "                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n",
    "        \n",
    "        #print(num_matches)\n",
    "\n",
    "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
    "    return score\n",
    "\n",
    "\n",
    "def idx_to_word(x, vocab):\n",
    "    words = []\n",
    "    for i in x:\n",
    "        word = vocab.itos[i]\n",
    "        if '<' not in word:\n",
    "            words.append(word)\n",
    "    words = \" \".join(words)\n",
    "    return words\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.kaiming_uniform(m.weight.data)\n",
    "\n",
    "\n",
    "\n",
    "model = Transformer(src_pad_idx=src_pad_idx,\n",
    "                    trg_pad_idx=trg_pad_idx,\n",
    "                    trg_sos_idx=trg_sos_idx,\n",
    "                    d_model=d_model,\n",
    "                    enc_voc_size=enc_voc_size,\n",
    "                    dec_voc_size=dec_voc_size,\n",
    "                    max_len=max_len,\n",
    "                    ffn_hidden=ffn_hidden,\n",
    "                    n_head=n_heads,\n",
    "                    n_layers=n_layers,\n",
    "                    drop_prob=drop_prob).to(device)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "model.apply(initialize_weights)\n",
    "optimizer = Adam(params=model.parameters(),\n",
    "                 lr=init_lr,\n",
    "                 weight_decay=weight_decay,\n",
    "                 eps=adam_eps)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 verbose=True,\n",
    "                                                 factor=factor,\n",
    "                                                 patience=patience)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=src_pad_idx)\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.src.to(device)\n",
    "        trg = batch.trg.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg[:, :-1])\n",
    "        output_reshape = output.contiguous().view(-1, output.shape[-1])\n",
    "        trg = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "        loss = criterion(output_reshape, trg)\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        print('step :', round((i / len(iterator)) * 100, 2), '% , loss :', loss.item())\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    batch_bleu = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "\n",
    "            output = model(src, trg[:, :-1])\n",
    "            output_reshape = output.contiguous().view(-1, output.shape[-1])\n",
    "            trg = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "            loss = criterion(output_reshape, trg)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            total_bleu = []\n",
    "            for j in range(batch_size):\n",
    "                try:\n",
    "                    trg_words = idx_to_word(batch.trg[j], loader.target.vocab)\n",
    "                    output_words = output[j].max(dim=1)[1]\n",
    "                    output_words = idx_to_word(output_words, loader.target.vocab)\n",
    "\n",
    "                    #print(output_words + ' lmao')\n",
    "                    #print(trg_words + ' bruh')\n",
    "                    #print(get_bleu(output_words, trg_words))\n",
    "                    #print('-' * 30)\n",
    "\n",
    "                    bleu = get_bleu(output_words, trg_words)\n",
    "\n",
    "                    total_bleu.append(bleu)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            total_bleu = sum(total_bleu) / len(total_bleu)\n",
    "            batch_bleu.append(total_bleu)\n",
    "\n",
    "            #src = src.detach()\n",
    "            #trg = trg.detach()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    batch_bleu = sum(batch_bleu) / len(batch_bleu)\n",
    "    return epoch_loss / len(iterator), batch_bleu\n",
    "\n",
    "from pathlib import Path\n",
    "def save_model(name):\n",
    "    MODEL_PATH = Path('/home/dominhnhat/Pose_Estimation/MFSvi/debug/models')\n",
    "    MODEL_NAME = Path(name + '.pth')\n",
    "    MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "    #print(f'Saving model to : {MODEL_SAVE_PATH}')\n",
    "    torch.save(obj = model.state_dict(),\n",
    "            f = MODEL_SAVE_PATH)\n",
    "\n",
    "def run(total_epoch, best_loss, best_bleu):\n",
    "    #train_losses, test_losses, bleus = [], [], []\n",
    "    for step in range(total_epoch):\n",
    "        start_time = time.time()\n",
    "        train_loss = train(model, train_iter, optimizer, criterion, clip)\n",
    "        valid_loss, bleu = evaluate(model, valid_iter, criterion)\n",
    "        #end_time = time.time()\n",
    "\n",
    "        if step > warmup:\n",
    "            scheduler.step(valid_loss)\n",
    "\n",
    "        #train_losses.append(train_loss)\n",
    "        #test_losses.append(valid_loss)\n",
    "        #bleus.append(bleu)\n",
    "        #epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            #save_model('best_loss')\n",
    "        \n",
    "        if (bleu > best_bleu):\n",
    "            best_bleu = bleu\n",
    "            #save_model('best_bleu')\n",
    "\n",
    "        print(f'Epoch: {step + 1}')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "        print(f'\\tVal Loss: {valid_loss:.3f} |  Val PPL: {math.exp(valid_loss):7.3f}')\n",
    "        print(f'\\tBLEU Score: {bleu:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0.0 % , loss : 7.507517337799072\n",
      "Epoch: 1\n",
      "\tTrain Loss: 7.508 | Train PPL: 1821.685\n",
      "\tVal Loss: 7.369 |  Val PPL: 1585.333\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 7.363132476806641\n",
      "Epoch: 2\n",
      "\tTrain Loss: 7.363 | Train PPL: 1576.768\n",
      "\tVal Loss: 7.187 |  Val PPL: 1321.495\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 7.274956226348877\n",
      "Epoch: 3\n",
      "\tTrain Loss: 7.275 | Train PPL: 1443.688\n",
      "\tVal Loss: 7.036 |  Val PPL: 1137.138\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 7.147759437561035\n",
      "Epoch: 4\n",
      "\tTrain Loss: 7.148 | Train PPL: 1271.254\n",
      "\tVal Loss: 6.919 |  Val PPL: 1011.336\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 7.054183483123779\n",
      "Epoch: 5\n",
      "\tTrain Loss: 7.054 | Train PPL: 1157.692\n",
      "\tVal Loss: 6.830 |  Val PPL: 925.233\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.925076961517334\n",
      "Epoch: 6\n",
      "\tTrain Loss: 6.925 | Train PPL: 1017.473\n",
      "\tVal Loss: 6.764 |  Val PPL: 866.521\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.8362250328063965\n",
      "Epoch: 7\n",
      "\tTrain Loss: 6.836 | Train PPL: 930.968\n",
      "\tVal Loss: 6.711 |  Val PPL: 821.742\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.823963165283203\n",
      "Epoch: 8\n",
      "\tTrain Loss: 6.824 | Train PPL: 919.622\n",
      "\tVal Loss: 6.664 |  Val PPL: 783.975\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.777950763702393\n",
      "Epoch: 9\n",
      "\tTrain Loss: 6.778 | Train PPL: 878.267\n",
      "\tVal Loss: 6.621 |  Val PPL: 750.637\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.687367916107178\n",
      "Epoch: 10\n",
      "\tTrain Loss: 6.687 | Train PPL: 802.208\n",
      "\tVal Loss: 6.579 |  Val PPL: 719.627\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.6430182456970215\n",
      "Epoch: 11\n",
      "\tTrain Loss: 6.643 | Train PPL: 767.408\n",
      "\tVal Loss: 6.536 |  Val PPL: 689.745\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.6497626304626465\n",
      "Epoch: 12\n",
      "\tTrain Loss: 6.650 | Train PPL: 772.601\n",
      "\tVal Loss: 6.494 |  Val PPL: 661.054\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.568239212036133\n",
      "Epoch: 13\n",
      "\tTrain Loss: 6.568 | Train PPL: 712.115\n",
      "\tVal Loss: 6.454 |  Val PPL: 635.034\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.513744354248047\n",
      "Epoch: 14\n",
      "\tTrain Loss: 6.514 | Train PPL: 674.347\n",
      "\tVal Loss: 6.416 |  Val PPL: 611.436\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.50961446762085\n",
      "Epoch: 15\n",
      "\tTrain Loss: 6.510 | Train PPL: 671.567\n",
      "\tVal Loss: 6.383 |  Val PPL: 591.723\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.461581230163574\n",
      "Epoch: 16\n",
      "\tTrain Loss: 6.462 | Train PPL: 640.072\n",
      "\tVal Loss: 6.356 |  Val PPL: 575.977\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.474626064300537\n",
      "Epoch: 17\n",
      "\tTrain Loss: 6.475 | Train PPL: 648.477\n",
      "\tVal Loss: 6.334 |  Val PPL: 563.234\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.417710781097412\n",
      "Epoch: 18\n",
      "\tTrain Loss: 6.418 | Train PPL: 612.599\n",
      "\tVal Loss: 6.314 |  Val PPL: 552.284\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.423637390136719\n",
      "Epoch: 19\n",
      "\tTrain Loss: 6.424 | Train PPL: 616.241\n",
      "\tVal Loss: 6.296 |  Val PPL: 542.339\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.377523422241211\n",
      "Epoch: 20\n",
      "\tTrain Loss: 6.378 | Train PPL: 588.469\n",
      "\tVal Loss: 6.277 |  Val PPL: 532.346\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.337112903594971\n",
      "Epoch: 21\n",
      "\tTrain Loss: 6.337 | Train PPL: 565.162\n",
      "\tVal Loss: 6.258 |  Val PPL: 521.929\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.352553844451904\n",
      "Epoch: 22\n",
      "\tTrain Loss: 6.353 | Train PPL: 573.957\n",
      "\tVal Loss: 6.236 |  Val PPL: 510.999\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.297051906585693\n",
      "Epoch: 23\n",
      "\tTrain Loss: 6.297 | Train PPL: 542.969\n",
      "\tVal Loss: 6.215 |  Val PPL: 500.028\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.2858076095581055\n",
      "Epoch: 24\n",
      "\tTrain Loss: 6.286 | Train PPL: 536.898\n",
      "\tVal Loss: 6.193 |  Val PPL: 489.247\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.255307197570801\n",
      "Epoch: 25\n",
      "\tTrain Loss: 6.255 | Train PPL: 520.769\n",
      "\tVal Loss: 6.172 |  Val PPL: 479.075\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.225984573364258\n",
      "Epoch: 26\n",
      "\tTrain Loss: 6.226 | Train PPL: 505.721\n",
      "\tVal Loss: 6.153 |  Val PPL: 469.968\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.192921161651611\n",
      "Epoch: 27\n",
      "\tTrain Loss: 6.193 | Train PPL: 489.273\n",
      "\tVal Loss: 6.135 |  Val PPL: 461.703\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.235494613647461\n",
      "Epoch: 28\n",
      "\tTrain Loss: 6.235 | Train PPL: 510.553\n",
      "\tVal Loss: 6.118 |  Val PPL: 453.822\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.234545707702637\n",
      "Epoch: 29\n",
      "\tTrain Loss: 6.235 | Train PPL: 510.069\n",
      "\tVal Loss: 6.101 |  Val PPL: 446.414\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.206932067871094\n",
      "Epoch: 30\n",
      "\tTrain Loss: 6.207 | Train PPL: 496.177\n",
      "\tVal Loss: 6.085 |  Val PPL: 439.134\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.19056510925293\n",
      "Epoch: 31\n",
      "\tTrain Loss: 6.191 | Train PPL: 488.122\n",
      "\tVal Loss: 6.069 |  Val PPL: 432.369\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.151042938232422\n",
      "Epoch: 32\n",
      "\tTrain Loss: 6.151 | Train PPL: 469.206\n",
      "\tVal Loss: 6.054 |  Val PPL: 425.822\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.184178829193115\n",
      "Epoch: 33\n",
      "\tTrain Loss: 6.184 | Train PPL: 485.015\n",
      "\tVal Loss: 6.039 |  Val PPL: 419.614\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.146568298339844\n",
      "Epoch: 34\n",
      "\tTrain Loss: 6.147 | Train PPL: 467.112\n",
      "\tVal Loss: 6.026 |  Val PPL: 413.978\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.12575101852417\n",
      "Epoch: 35\n",
      "\tTrain Loss: 6.126 | Train PPL: 457.488\n",
      "\tVal Loss: 6.013 |  Val PPL: 408.599\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.138833522796631\n",
      "Epoch: 36\n",
      "\tTrain Loss: 6.139 | Train PPL: 463.513\n",
      "\tVal Loss: 6.001 |  Val PPL: 403.652\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.0914692878723145\n",
      "Epoch: 37\n",
      "\tTrain Loss: 6.091 | Train PPL: 442.070\n",
      "\tVal Loss: 5.990 |  Val PPL: 399.457\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.111717224121094\n",
      "Epoch: 38\n",
      "\tTrain Loss: 6.112 | Train PPL: 451.113\n",
      "\tVal Loss: 5.981 |  Val PPL: 395.778\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.081026077270508\n",
      "Epoch: 39\n",
      "\tTrain Loss: 6.081 | Train PPL: 437.478\n",
      "\tVal Loss: 5.972 |  Val PPL: 392.326\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.1031928062438965\n",
      "Epoch: 40\n",
      "\tTrain Loss: 6.103 | Train PPL: 447.284\n",
      "\tVal Loss: 5.964 |  Val PPL: 389.087\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.088937759399414\n",
      "Epoch: 41\n",
      "\tTrain Loss: 6.089 | Train PPL: 440.953\n",
      "\tVal Loss: 5.956 |  Val PPL: 386.083\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.040741920471191\n",
      "Epoch: 42\n",
      "\tTrain Loss: 6.041 | Train PPL: 420.205\n",
      "\tVal Loss: 5.949 |  Val PPL: 383.468\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.053211688995361\n",
      "Epoch: 43\n",
      "\tTrain Loss: 6.053 | Train PPL: 425.477\n",
      "\tVal Loss: 5.943 |  Val PPL: 380.972\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.025993347167969\n",
      "Epoch: 44\n",
      "\tTrain Loss: 6.026 | Train PPL: 414.053\n",
      "\tVal Loss: 5.936 |  Val PPL: 378.370\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.026978492736816\n",
      "Epoch: 45\n",
      "\tTrain Loss: 6.027 | Train PPL: 414.461\n",
      "\tVal Loss: 5.928 |  Val PPL: 375.421\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.000992774963379\n",
      "Epoch: 46\n",
      "\tTrain Loss: 6.001 | Train PPL: 403.830\n",
      "\tVal Loss: 5.920 |  Val PPL: 372.466\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 6.013920307159424\n",
      "Epoch: 47\n",
      "\tTrain Loss: 6.014 | Train PPL: 409.084\n",
      "\tVal Loss: 5.913 |  Val PPL: 369.713\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.988065242767334\n",
      "Epoch: 48\n",
      "\tTrain Loss: 5.988 | Train PPL: 398.643\n",
      "\tVal Loss: 5.905 |  Val PPL: 367.042\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.996399879455566\n",
      "Epoch: 49\n",
      "\tTrain Loss: 5.996 | Train PPL: 401.979\n",
      "\tVal Loss: 5.898 |  Val PPL: 364.434\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.994498252868652\n",
      "Epoch: 50\n",
      "\tTrain Loss: 5.994 | Train PPL: 401.215\n",
      "\tVal Loss: 5.891 |  Val PPL: 361.717\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.96407413482666\n",
      "Epoch: 51\n",
      "\tTrain Loss: 5.964 | Train PPL: 389.193\n",
      "\tVal Loss: 5.883 |  Val PPL: 358.923\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.957496643066406\n",
      "Epoch: 52\n",
      "\tTrain Loss: 5.957 | Train PPL: 386.641\n",
      "\tVal Loss: 5.876 |  Val PPL: 356.231\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.970465183258057\n",
      "Epoch: 53\n",
      "\tTrain Loss: 5.970 | Train PPL: 391.688\n",
      "\tVal Loss: 5.869 |  Val PPL: 353.766\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.984189987182617\n",
      "Epoch: 54\n",
      "\tTrain Loss: 5.984 | Train PPL: 397.101\n",
      "\tVal Loss: 5.862 |  Val PPL: 351.433\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.949905872344971\n",
      "Epoch: 55\n",
      "\tTrain Loss: 5.950 | Train PPL: 383.717\n",
      "\tVal Loss: 5.856 |  Val PPL: 349.249\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.951098918914795\n",
      "Epoch: 56\n",
      "\tTrain Loss: 5.951 | Train PPL: 384.175\n",
      "\tVal Loss: 5.850 |  Val PPL: 347.237\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.96212100982666\n",
      "Epoch: 57\n",
      "\tTrain Loss: 5.962 | Train PPL: 388.433\n",
      "\tVal Loss: 5.844 |  Val PPL: 345.270\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.939901828765869\n",
      "Epoch: 58\n",
      "\tTrain Loss: 5.940 | Train PPL: 379.898\n",
      "\tVal Loss: 5.839 |  Val PPL: 343.456\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.9324140548706055\n",
      "Epoch: 59\n",
      "\tTrain Loss: 5.932 | Train PPL: 377.064\n",
      "\tVal Loss: 5.834 |  Val PPL: 341.815\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.929387092590332\n",
      "Epoch: 60\n",
      "\tTrain Loss: 5.929 | Train PPL: 375.924\n",
      "\tVal Loss: 5.830 |  Val PPL: 340.344\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.931063652038574\n",
      "Epoch: 61\n",
      "\tTrain Loss: 5.931 | Train PPL: 376.555\n",
      "\tVal Loss: 5.826 |  Val PPL: 338.896\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.908178806304932\n",
      "Epoch: 62\n",
      "\tTrain Loss: 5.908 | Train PPL: 368.035\n",
      "\tVal Loss: 5.822 |  Val PPL: 337.482\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.925724983215332\n",
      "Epoch: 63\n",
      "\tTrain Loss: 5.926 | Train PPL: 374.550\n",
      "\tVal Loss: 5.817 |  Val PPL: 336.014\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.907414436340332\n",
      "Epoch: 64\n",
      "\tTrain Loss: 5.907 | Train PPL: 367.754\n",
      "\tVal Loss: 5.813 |  Val PPL: 334.654\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.883180141448975\n",
      "Epoch: 65\n",
      "\tTrain Loss: 5.883 | Train PPL: 358.949\n",
      "\tVal Loss: 5.809 |  Val PPL: 333.449\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.889638423919678\n",
      "Epoch: 66\n",
      "\tTrain Loss: 5.890 | Train PPL: 361.275\n",
      "\tVal Loss: 5.806 |  Val PPL: 332.342\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.884036540985107\n",
      "Epoch: 67\n",
      "\tTrain Loss: 5.884 | Train PPL: 359.256\n",
      "\tVal Loss: 5.803 |  Val PPL: 331.303\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.851837158203125\n",
      "Epoch: 68\n",
      "\tTrain Loss: 5.852 | Train PPL: 347.873\n",
      "\tVal Loss: 5.800 |  Val PPL: 330.315\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.86644172668457\n",
      "Epoch: 69\n",
      "\tTrain Loss: 5.866 | Train PPL: 352.991\n",
      "\tVal Loss: 5.797 |  Val PPL: 329.385\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.861578941345215\n",
      "Epoch: 70\n",
      "\tTrain Loss: 5.862 | Train PPL: 351.278\n",
      "\tVal Loss: 5.795 |  Val PPL: 328.606\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.851255416870117\n",
      "Epoch: 71\n",
      "\tTrain Loss: 5.851 | Train PPL: 347.671\n",
      "\tVal Loss: 5.792 |  Val PPL: 327.700\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.870159149169922\n",
      "Epoch: 72\n",
      "\tTrain Loss: 5.870 | Train PPL: 354.305\n",
      "\tVal Loss: 5.790 |  Val PPL: 326.927\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.871361255645752\n",
      "Epoch: 73\n",
      "\tTrain Loss: 5.871 | Train PPL: 354.732\n",
      "\tVal Loss: 5.787 |  Val PPL: 326.016\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.855592250823975\n",
      "Epoch: 74\n",
      "\tTrain Loss: 5.856 | Train PPL: 349.182\n",
      "\tVal Loss: 5.784 |  Val PPL: 325.117\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.839056015014648\n",
      "Epoch: 75\n",
      "\tTrain Loss: 5.839 | Train PPL: 343.455\n",
      "\tVal Loss: 5.782 |  Val PPL: 324.283\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.848587512969971\n",
      "Epoch: 76\n",
      "\tTrain Loss: 5.849 | Train PPL: 346.744\n",
      "\tVal Loss: 5.779 |  Val PPL: 323.434\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.812107086181641\n",
      "Epoch: 77\n",
      "\tTrain Loss: 5.812 | Train PPL: 334.323\n",
      "\tVal Loss: 5.776 |  Val PPL: 322.532\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.84396505355835\n",
      "Epoch: 78\n",
      "\tTrain Loss: 5.844 | Train PPL: 345.145\n",
      "\tVal Loss: 5.773 |  Val PPL: 321.417\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.84090518951416\n",
      "Epoch: 79\n",
      "\tTrain Loss: 5.841 | Train PPL: 344.091\n",
      "\tVal Loss: 5.769 |  Val PPL: 320.363\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.814049243927002\n",
      "Epoch: 80\n",
      "\tTrain Loss: 5.814 | Train PPL: 334.973\n",
      "\tVal Loss: 5.766 |  Val PPL: 319.315\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.830328941345215\n",
      "Epoch: 81\n",
      "\tTrain Loss: 5.830 | Train PPL: 340.471\n",
      "\tVal Loss: 5.763 |  Val PPL: 318.346\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.808283805847168\n",
      "Epoch: 82\n",
      "\tTrain Loss: 5.808 | Train PPL: 333.047\n",
      "\tVal Loss: 5.760 |  Val PPL: 317.337\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.826931476593018\n",
      "Epoch: 83\n",
      "\tTrain Loss: 5.827 | Train PPL: 339.316\n",
      "\tVal Loss: 5.757 |  Val PPL: 316.293\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.834507942199707\n",
      "Epoch: 84\n",
      "\tTrain Loss: 5.835 | Train PPL: 341.896\n",
      "\tVal Loss: 5.753 |  Val PPL: 315.251\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.824507236480713\n",
      "Epoch: 85\n",
      "\tTrain Loss: 5.825 | Train PPL: 338.494\n",
      "\tVal Loss: 5.750 |  Val PPL: 314.230\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.818350791931152\n",
      "Epoch: 86\n",
      "\tTrain Loss: 5.818 | Train PPL: 336.417\n",
      "\tVal Loss: 5.747 |  Val PPL: 313.306\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.7936506271362305\n",
      "Epoch: 87\n",
      "\tTrain Loss: 5.794 | Train PPL: 328.209\n",
      "\tVal Loss: 5.744 |  Val PPL: 312.401\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.8148274421691895\n",
      "Epoch: 88\n",
      "\tTrain Loss: 5.815 | Train PPL: 335.234\n",
      "\tVal Loss: 5.741 |  Val PPL: 311.472\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.786510467529297\n",
      "Epoch: 89\n",
      "\tTrain Loss: 5.787 | Train PPL: 325.874\n",
      "\tVal Loss: 5.739 |  Val PPL: 310.820\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.773014545440674\n",
      "Epoch: 90\n",
      "\tTrain Loss: 5.773 | Train PPL: 321.505\n",
      "\tVal Loss: 5.737 |  Val PPL: 310.285\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.824173450469971\n",
      "Epoch: 91\n",
      "\tTrain Loss: 5.824 | Train PPL: 338.381\n",
      "\tVal Loss: 5.736 |  Val PPL: 309.755\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.7996907234191895\n",
      "Epoch: 92\n",
      "\tTrain Loss: 5.800 | Train PPL: 330.197\n",
      "\tVal Loss: 5.733 |  Val PPL: 309.028\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.774622917175293\n",
      "Epoch: 93\n",
      "\tTrain Loss: 5.775 | Train PPL: 322.023\n",
      "\tVal Loss: 5.731 |  Val PPL: 308.256\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.75712776184082\n",
      "Epoch: 94\n",
      "\tTrain Loss: 5.757 | Train PPL: 316.438\n",
      "\tVal Loss: 5.728 |  Val PPL: 307.427\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.7975263595581055\n",
      "Epoch: 95\n",
      "\tTrain Loss: 5.798 | Train PPL: 329.484\n",
      "\tVal Loss: 5.726 |  Val PPL: 306.656\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.739374160766602\n",
      "Epoch: 96\n",
      "\tTrain Loss: 5.739 | Train PPL: 310.870\n",
      "\tVal Loss: 5.723 |  Val PPL: 305.826\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.77371072769165\n",
      "Epoch: 97\n",
      "\tTrain Loss: 5.774 | Train PPL: 321.729\n",
      "\tVal Loss: 5.720 |  Val PPL: 305.030\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.778921604156494\n",
      "Epoch: 98\n",
      "\tTrain Loss: 5.779 | Train PPL: 323.410\n",
      "\tVal Loss: 5.718 |  Val PPL: 304.180\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.7578206062316895\n",
      "Epoch: 99\n",
      "\tTrain Loss: 5.758 | Train PPL: 316.657\n",
      "\tVal Loss: 5.715 |  Val PPL: 303.315\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.7577314376831055\n",
      "Epoch: 100\n",
      "\tTrain Loss: 5.758 | Train PPL: 316.629\n",
      "\tVal Loss: 5.712 |  Val PPL: 302.381\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.744300365447998\n",
      "Epoch: 101\n",
      "\tTrain Loss: 5.744 | Train PPL: 312.405\n",
      "\tVal Loss: 5.708 |  Val PPL: 301.413\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.76762056350708\n",
      "Epoch: 102\n",
      "\tTrain Loss: 5.768 | Train PPL: 319.776\n",
      "\tVal Loss: 5.705 |  Val PPL: 300.253\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.7400946617126465\n",
      "Epoch: 103\n",
      "\tTrain Loss: 5.740 | Train PPL: 311.094\n",
      "\tVal Loss: 5.701 |  Val PPL: 299.303\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.787534236907959\n",
      "Epoch: 104\n",
      "\tTrain Loss: 5.788 | Train PPL: 326.208\n",
      "\tVal Loss: 5.698 |  Val PPL: 298.391\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.74029541015625\n",
      "Epoch: 105\n",
      "\tTrain Loss: 5.740 | Train PPL: 311.156\n",
      "\tVal Loss: 5.695 |  Val PPL: 297.501\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.716168403625488\n",
      "Epoch: 106\n",
      "\tTrain Loss: 5.716 | Train PPL: 303.739\n",
      "\tVal Loss: 5.693 |  Val PPL: 296.856\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.75553560256958\n",
      "Epoch: 107\n",
      "\tTrain Loss: 5.756 | Train PPL: 315.935\n",
      "\tVal Loss: 5.691 |  Val PPL: 296.290\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.730469703674316\n",
      "Epoch: 108\n",
      "\tTrain Loss: 5.730 | Train PPL: 308.114\n",
      "\tVal Loss: 5.690 |  Val PPL: 295.882\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.703956127166748\n",
      "Epoch: 109\n",
      "\tTrain Loss: 5.704 | Train PPL: 300.052\n",
      "\tVal Loss: 5.689 |  Val PPL: 295.501\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.751628398895264\n",
      "Epoch: 110\n",
      "\tTrain Loss: 5.752 | Train PPL: 314.703\n",
      "\tVal Loss: 5.687 |  Val PPL: 295.142\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.739027500152588\n",
      "Epoch: 111\n",
      "\tTrain Loss: 5.739 | Train PPL: 310.762\n",
      "\tVal Loss: 5.686 |  Val PPL: 294.830\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.735543251037598\n",
      "Epoch: 112\n",
      "\tTrain Loss: 5.736 | Train PPL: 309.681\n",
      "\tVal Loss: 5.685 |  Val PPL: 294.507\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.703207015991211\n",
      "Epoch: 113\n",
      "\tTrain Loss: 5.703 | Train PPL: 299.827\n",
      "\tVal Loss: 5.684 |  Val PPL: 294.011\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.726051330566406\n",
      "Epoch: 114\n",
      "\tTrain Loss: 5.726 | Train PPL: 306.756\n",
      "\tVal Loss: 5.682 |  Val PPL: 293.507\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.704607963562012\n",
      "Epoch: 115\n",
      "\tTrain Loss: 5.705 | Train PPL: 300.248\n",
      "\tVal Loss: 5.680 |  Val PPL: 292.926\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.712568283081055\n",
      "Epoch: 116\n",
      "\tTrain Loss: 5.713 | Train PPL: 302.647\n",
      "\tVal Loss: 5.678 |  Val PPL: 292.368\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.71451473236084\n",
      "Epoch: 117\n",
      "\tTrain Loss: 5.715 | Train PPL: 303.237\n",
      "\tVal Loss: 5.676 |  Val PPL: 291.700\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.724329948425293\n",
      "Epoch: 118\n",
      "\tTrain Loss: 5.724 | Train PPL: 306.228\n",
      "\tVal Loss: 5.673 |  Val PPL: 291.021\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.720368385314941\n",
      "Epoch: 119\n",
      "\tTrain Loss: 5.720 | Train PPL: 305.017\n",
      "\tVal Loss: 5.671 |  Val PPL: 290.340\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.707295894622803\n",
      "Epoch: 120\n",
      "\tTrain Loss: 5.707 | Train PPL: 301.056\n",
      "\tVal Loss: 5.669 |  Val PPL: 289.664\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.740185737609863\n",
      "Epoch: 121\n",
      "\tTrain Loss: 5.740 | Train PPL: 311.122\n",
      "\tVal Loss: 5.666 |  Val PPL: 288.872\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.716982841491699\n",
      "Epoch: 122\n",
      "\tTrain Loss: 5.717 | Train PPL: 303.986\n",
      "\tVal Loss: 5.664 |  Val PPL: 288.170\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.702706336975098\n",
      "Epoch: 123\n",
      "\tTrain Loss: 5.703 | Train PPL: 299.677\n",
      "\tVal Loss: 5.661 |  Val PPL: 287.577\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.721072196960449\n",
      "Epoch: 124\n",
      "\tTrain Loss: 5.721 | Train PPL: 305.232\n",
      "\tVal Loss: 5.659 |  Val PPL: 286.984\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.691295623779297\n",
      "Epoch: 125\n",
      "\tTrain Loss: 5.691 | Train PPL: 296.277\n",
      "\tVal Loss: 5.658 |  Val PPL: 286.454\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.673789024353027\n",
      "Epoch: 126\n",
      "\tTrain Loss: 5.674 | Train PPL: 291.136\n",
      "\tVal Loss: 5.656 |  Val PPL: 286.121\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.6704864501953125\n",
      "Epoch: 127\n",
      "\tTrain Loss: 5.670 | Train PPL: 290.176\n",
      "\tVal Loss: 5.655 |  Val PPL: 285.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.696836471557617\n",
      "Epoch: 128\n",
      "\tTrain Loss: 5.697 | Train PPL: 297.923\n",
      "\tVal Loss: 5.653 |  Val PPL: 285.204\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.693231582641602\n",
      "Epoch: 129\n",
      "\tTrain Loss: 5.693 | Train PPL: 296.851\n",
      "\tVal Loss: 5.652 |  Val PPL: 284.730\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.678958415985107\n",
      "Epoch: 130\n",
      "\tTrain Loss: 5.679 | Train PPL: 292.644\n",
      "\tVal Loss: 5.650 |  Val PPL: 284.293\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.687742233276367\n",
      "Epoch: 131\n",
      "\tTrain Loss: 5.688 | Train PPL: 295.226\n",
      "\tVal Loss: 5.649 |  Val PPL: 283.988\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.667987823486328\n",
      "Epoch: 132\n",
      "\tTrain Loss: 5.668 | Train PPL: 289.452\n",
      "\tVal Loss: 5.647 |  Val PPL: 283.505\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.675848960876465\n",
      "Epoch: 133\n",
      "\tTrain Loss: 5.676 | Train PPL: 291.736\n",
      "\tVal Loss: 5.645 |  Val PPL: 283.009\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.683475971221924\n",
      "Epoch: 134\n",
      "\tTrain Loss: 5.683 | Train PPL: 293.969\n",
      "\tVal Loss: 5.644 |  Val PPL: 282.536\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.681666851043701\n",
      "Epoch: 135\n",
      "\tTrain Loss: 5.682 | Train PPL: 293.438\n",
      "\tVal Loss: 5.642 |  Val PPL: 282.005\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.656906604766846\n",
      "Epoch: 136\n",
      "\tTrain Loss: 5.657 | Train PPL: 286.262\n",
      "\tVal Loss: 5.640 |  Val PPL: 281.505\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.684568405151367\n",
      "Epoch: 137\n",
      "\tTrain Loss: 5.685 | Train PPL: 294.291\n",
      "\tVal Loss: 5.638 |  Val PPL: 280.988\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.674370765686035\n",
      "Epoch: 138\n",
      "\tTrain Loss: 5.674 | Train PPL: 291.305\n",
      "\tVal Loss: 5.636 |  Val PPL: 280.471\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.673686504364014\n",
      "Epoch: 139\n",
      "\tTrain Loss: 5.674 | Train PPL: 291.106\n",
      "\tVal Loss: 5.634 |  Val PPL: 279.813\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.68532657623291\n",
      "Epoch: 140\n",
      "\tTrain Loss: 5.685 | Train PPL: 294.514\n",
      "\tVal Loss: 5.632 |  Val PPL: 279.162\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.672305583953857\n",
      "Epoch: 141\n",
      "\tTrain Loss: 5.672 | Train PPL: 290.704\n",
      "\tVal Loss: 5.630 |  Val PPL: 278.598\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.672482967376709\n",
      "Epoch: 142\n",
      "\tTrain Loss: 5.672 | Train PPL: 290.756\n",
      "\tVal Loss: 5.629 |  Val PPL: 278.267\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.689413070678711\n",
      "Epoch: 143\n",
      "\tTrain Loss: 5.689 | Train PPL: 295.720\n",
      "\tVal Loss: 5.628 |  Val PPL: 277.986\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.616026401519775\n",
      "Epoch: 144\n",
      "\tTrain Loss: 5.616 | Train PPL: 274.795\n",
      "\tVal Loss: 5.627 |  Val PPL: 277.770\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.6719794273376465\n",
      "Epoch: 145\n",
      "\tTrain Loss: 5.672 | Train PPL: 290.609\n",
      "\tVal Loss: 5.626 |  Val PPL: 277.612\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.6575517654418945\n",
      "Epoch: 146\n",
      "\tTrain Loss: 5.658 | Train PPL: 286.446\n",
      "\tVal Loss: 5.625 |  Val PPL: 277.318\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.661191463470459\n",
      "Epoch: 147\n",
      "\tTrain Loss: 5.661 | Train PPL: 287.491\n",
      "\tVal Loss: 5.624 |  Val PPL: 277.054\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.650740146636963\n",
      "Epoch: 148\n",
      "\tTrain Loss: 5.651 | Train PPL: 284.502\n",
      "\tVal Loss: 5.623 |  Val PPL: 276.668\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.678402900695801\n",
      "Epoch: 149\n",
      "\tTrain Loss: 5.678 | Train PPL: 292.482\n",
      "\tVal Loss: 5.621 |  Val PPL: 276.207\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.633571624755859\n",
      "Epoch: 150\n",
      "\tTrain Loss: 5.634 | Train PPL: 279.659\n",
      "\tVal Loss: 5.619 |  Val PPL: 275.715\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.6597418785095215\n",
      "Epoch: 151\n",
      "\tTrain Loss: 5.660 | Train PPL: 287.075\n",
      "\tVal Loss: 5.618 |  Val PPL: 275.316\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.648829936981201\n",
      "Epoch: 152\n",
      "\tTrain Loss: 5.649 | Train PPL: 283.959\n",
      "\tVal Loss: 5.616 |  Val PPL: 274.864\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.644231796264648\n",
      "Epoch: 153\n",
      "\tTrain Loss: 5.644 | Train PPL: 282.656\n",
      "\tVal Loss: 5.614 |  Val PPL: 274.362\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.665994167327881\n",
      "Epoch: 154\n",
      "\tTrain Loss: 5.666 | Train PPL: 288.875\n",
      "\tVal Loss: 5.613 |  Val PPL: 273.959\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.660885810852051\n",
      "Epoch: 155\n",
      "\tTrain Loss: 5.661 | Train PPL: 287.403\n",
      "\tVal Loss: 5.612 |  Val PPL: 273.748\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.665185451507568\n",
      "Epoch: 156\n",
      "\tTrain Loss: 5.665 | Train PPL: 288.642\n",
      "\tVal Loss: 5.611 |  Val PPL: 273.473\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.672633647918701\n",
      "Epoch: 157\n",
      "\tTrain Loss: 5.673 | Train PPL: 290.799\n",
      "\tVal Loss: 5.610 |  Val PPL: 273.173\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.625540733337402\n",
      "Epoch: 158\n",
      "\tTrain Loss: 5.626 | Train PPL: 277.422\n",
      "\tVal Loss: 5.609 |  Val PPL: 272.811\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.6419267654418945\n",
      "Epoch: 159\n",
      "\tTrain Loss: 5.642 | Train PPL: 282.006\n",
      "\tVal Loss: 5.608 |  Val PPL: 272.526\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.627494812011719\n",
      "Epoch: 160\n",
      "\tTrain Loss: 5.627 | Train PPL: 277.965\n",
      "\tVal Loss: 5.607 |  Val PPL: 272.343\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.634074687957764\n",
      "Epoch: 161\n",
      "\tTrain Loss: 5.634 | Train PPL: 279.800\n",
      "\tVal Loss: 5.607 |  Val PPL: 272.292\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.635233402252197\n",
      "Epoch: 162\n",
      "\tTrain Loss: 5.635 | Train PPL: 280.124\n",
      "\tVal Loss: 5.606 |  Val PPL: 272.177\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.633294105529785\n",
      "Epoch: 163\n",
      "\tTrain Loss: 5.633 | Train PPL: 279.582\n",
      "\tVal Loss: 5.606 |  Val PPL: 271.997\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.631241798400879\n",
      "Epoch: 164\n",
      "\tTrain Loss: 5.631 | Train PPL: 279.008\n",
      "\tVal Loss: 5.605 |  Val PPL: 271.741\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.6336541175842285\n",
      "Epoch: 165\n",
      "\tTrain Loss: 5.634 | Train PPL: 279.682\n",
      "\tVal Loss: 5.603 |  Val PPL: 271.288\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.6249613761901855\n",
      "Epoch: 166\n",
      "\tTrain Loss: 5.625 | Train PPL: 277.262\n",
      "\tVal Loss: 5.601 |  Val PPL: 270.773\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.615026473999023\n",
      "Epoch: 167\n",
      "\tTrain Loss: 5.615 | Train PPL: 274.521\n",
      "\tVal Loss: 5.599 |  Val PPL: 270.150\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.610534191131592\n",
      "Epoch: 168\n",
      "\tTrain Loss: 5.611 | Train PPL: 273.290\n",
      "\tVal Loss: 5.597 |  Val PPL: 269.490\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.651932716369629\n",
      "Epoch: 169\n",
      "\tTrain Loss: 5.652 | Train PPL: 284.841\n",
      "\tVal Loss: 5.594 |  Val PPL: 268.873\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.6427998542785645\n",
      "Epoch: 170\n",
      "\tTrain Loss: 5.643 | Train PPL: 282.252\n",
      "\tVal Loss: 5.593 |  Val PPL: 268.415\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.622353553771973\n",
      "Epoch: 171\n",
      "\tTrain Loss: 5.622 | Train PPL: 276.539\n",
      "\tVal Loss: 5.591 |  Val PPL: 268.018\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.612821578979492\n",
      "Epoch: 172\n",
      "\tTrain Loss: 5.613 | Train PPL: 273.916\n",
      "\tVal Loss: 5.590 |  Val PPL: 267.709\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.60562801361084\n",
      "Epoch: 173\n",
      "\tTrain Loss: 5.606 | Train PPL: 271.953\n",
      "\tVal Loss: 5.589 |  Val PPL: 267.497\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.615810394287109\n",
      "Epoch: 174\n",
      "\tTrain Loss: 5.616 | Train PPL: 274.736\n",
      "\tVal Loss: 5.588 |  Val PPL: 267.274\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.621612548828125\n",
      "Epoch: 175\n",
      "\tTrain Loss: 5.622 | Train PPL: 276.335\n",
      "\tVal Loss: 5.588 |  Val PPL: 267.080\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.61857271194458\n",
      "Epoch: 176\n",
      "\tTrain Loss: 5.619 | Train PPL: 275.496\n",
      "\tVal Loss: 5.587 |  Val PPL: 266.895\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.6042985916137695\n",
      "Epoch: 177\n",
      "\tTrain Loss: 5.604 | Train PPL: 271.591\n",
      "\tVal Loss: 5.586 |  Val PPL: 266.790\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.623607635498047\n",
      "Epoch: 178\n",
      "\tTrain Loss: 5.624 | Train PPL: 276.886\n",
      "\tVal Loss: 5.586 |  Val PPL: 266.651\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.609775066375732\n",
      "Epoch: 179\n",
      "\tTrain Loss: 5.610 | Train PPL: 273.083\n",
      "\tVal Loss: 5.586 |  Val PPL: 266.562\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.598695755004883\n",
      "Epoch: 180\n",
      "\tTrain Loss: 5.599 | Train PPL: 270.074\n",
      "\tVal Loss: 5.585 |  Val PPL: 266.399\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.607591152191162\n",
      "Epoch: 181\n",
      "\tTrain Loss: 5.608 | Train PPL: 272.487\n",
      "\tVal Loss: 5.584 |  Val PPL: 266.256\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.5996294021606445\n",
      "Epoch: 182\n",
      "\tTrain Loss: 5.600 | Train PPL: 270.326\n",
      "\tVal Loss: 5.584 |  Val PPL: 266.019\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.598452568054199\n",
      "Epoch: 183\n",
      "\tTrain Loss: 5.598 | Train PPL: 270.008\n",
      "\tVal Loss: 5.582 |  Val PPL: 265.600\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.5955376625061035\n",
      "Epoch: 184\n",
      "\tTrain Loss: 5.596 | Train PPL: 269.222\n",
      "\tVal Loss: 5.580 |  Val PPL: 265.162\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.615974426269531\n",
      "Epoch: 185\n",
      "\tTrain Loss: 5.616 | Train PPL: 274.781\n",
      "\tVal Loss: 5.579 |  Val PPL: 264.754\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.595363140106201\n",
      "Epoch: 186\n",
      "\tTrain Loss: 5.595 | Train PPL: 269.175\n",
      "\tVal Loss: 5.577 |  Val PPL: 264.367\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.580871105194092\n",
      "Epoch: 187\n",
      "\tTrain Loss: 5.581 | Train PPL: 265.303\n",
      "\tVal Loss: 5.576 |  Val PPL: 264.090\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.61515474319458\n",
      "Epoch: 188\n",
      "\tTrain Loss: 5.615 | Train PPL: 274.556\n",
      "\tVal Loss: 5.575 |  Val PPL: 263.819\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.579325199127197\n",
      "Epoch: 189\n",
      "\tTrain Loss: 5.579 | Train PPL: 264.893\n",
      "\tVal Loss: 5.574 |  Val PPL: 263.584\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.600061416625977\n",
      "Epoch: 190\n",
      "\tTrain Loss: 5.600 | Train PPL: 270.443\n",
      "\tVal Loss: 5.573 |  Val PPL: 263.321\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.610433578491211\n",
      "Epoch: 191\n",
      "\tTrain Loss: 5.610 | Train PPL: 273.263\n",
      "\tVal Loss: 5.573 |  Val PPL: 263.122\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.5732269287109375\n",
      "Epoch: 192\n",
      "\tTrain Loss: 5.573 | Train PPL: 263.282\n",
      "\tVal Loss: 5.572 |  Val PPL: 262.905\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.584270000457764\n",
      "Epoch: 193\n",
      "\tTrain Loss: 5.584 | Train PPL: 266.206\n",
      "\tVal Loss: 5.570 |  Val PPL: 262.562\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.582476615905762\n",
      "Epoch: 194\n",
      "\tTrain Loss: 5.582 | Train PPL: 265.729\n",
      "\tVal Loss: 5.569 |  Val PPL: 262.259\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.579376697540283\n",
      "Epoch: 195\n",
      "\tTrain Loss: 5.579 | Train PPL: 264.906\n",
      "\tVal Loss: 5.568 |  Val PPL: 261.990\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.5862717628479\n",
      "Epoch: 196\n",
      "\tTrain Loss: 5.586 | Train PPL: 266.739\n",
      "\tVal Loss: 5.567 |  Val PPL: 261.719\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.60192346572876\n",
      "Epoch: 197\n",
      "\tTrain Loss: 5.602 | Train PPL: 270.947\n",
      "\tVal Loss: 5.566 |  Val PPL: 261.385\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.566139221191406\n",
      "Epoch: 198\n",
      "\tTrain Loss: 5.566 | Train PPL: 261.423\n",
      "\tVal Loss: 5.565 |  Val PPL: 261.142\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.585114479064941\n",
      "Epoch: 199\n",
      "\tTrain Loss: 5.585 | Train PPL: 266.431\n",
      "\tVal Loss: 5.564 |  Val PPL: 260.802\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.570913314819336\n",
      "Epoch: 200\n",
      "\tTrain Loss: 5.571 | Train PPL: 262.674\n",
      "\tVal Loss: 5.563 |  Val PPL: 260.479\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.568360328674316\n",
      "Epoch: 201\n",
      "\tTrain Loss: 5.568 | Train PPL: 262.004\n",
      "\tVal Loss: 5.561 |  Val PPL: 260.187\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.581659317016602\n",
      "Epoch: 202\n",
      "\tTrain Loss: 5.582 | Train PPL: 265.512\n",
      "\tVal Loss: 5.560 |  Val PPL: 259.888\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.572030067443848\n",
      "Epoch: 203\n",
      "\tTrain Loss: 5.572 | Train PPL: 262.967\n",
      "\tVal Loss: 5.559 |  Val PPL: 259.575\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.5678391456604\n",
      "Epoch: 204\n",
      "\tTrain Loss: 5.568 | Train PPL: 261.868\n",
      "\tVal Loss: 5.558 |  Val PPL: 259.317\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.566442489624023\n",
      "Epoch: 205\n",
      "\tTrain Loss: 5.566 | Train PPL: 261.502\n",
      "\tVal Loss: 5.557 |  Val PPL: 259.089\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.54778528213501\n",
      "Epoch: 206\n",
      "\tTrain Loss: 5.548 | Train PPL: 256.668\n",
      "\tVal Loss: 5.556 |  Val PPL: 258.771\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.584862232208252\n",
      "Epoch: 207\n",
      "\tTrain Loss: 5.585 | Train PPL: 266.364\n",
      "\tVal Loss: 5.555 |  Val PPL: 258.443\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.571859359741211\n",
      "Epoch: 208\n",
      "\tTrain Loss: 5.572 | Train PPL: 262.923\n",
      "\tVal Loss: 5.553 |  Val PPL: 258.066\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.560220241546631\n",
      "Epoch: 209\n",
      "\tTrain Loss: 5.560 | Train PPL: 259.880\n",
      "\tVal Loss: 5.552 |  Val PPL: 257.759\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.576597213745117\n",
      "Epoch: 210\n",
      "\tTrain Loss: 5.577 | Train PPL: 264.171\n",
      "\tVal Loss: 5.551 |  Val PPL: 257.401\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.576784610748291\n",
      "Epoch: 211\n",
      "\tTrain Loss: 5.577 | Train PPL: 264.221\n",
      "\tVal Loss: 5.549 |  Val PPL: 257.027\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.570681095123291\n",
      "Epoch: 212\n",
      "\tTrain Loss: 5.571 | Train PPL: 262.613\n",
      "\tVal Loss: 5.548 |  Val PPL: 256.612\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.549761772155762\n",
      "Epoch: 213\n",
      "\tTrain Loss: 5.550 | Train PPL: 257.176\n",
      "\tVal Loss: 5.546 |  Val PPL: 256.097\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.570682048797607\n",
      "Epoch: 214\n",
      "\tTrain Loss: 5.571 | Train PPL: 262.613\n",
      "\tVal Loss: 5.544 |  Val PPL: 255.655\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.559605121612549\n",
      "Epoch: 215\n",
      "\tTrain Loss: 5.560 | Train PPL: 259.720\n",
      "\tVal Loss: 5.543 |  Val PPL: 255.321\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.562943935394287\n",
      "Epoch: 216\n",
      "\tTrain Loss: 5.563 | Train PPL: 260.589\n",
      "\tVal Loss: 5.541 |  Val PPL: 255.036\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.562041282653809\n",
      "Epoch: 217\n",
      "\tTrain Loss: 5.562 | Train PPL: 260.354\n",
      "\tVal Loss: 5.540 |  Val PPL: 254.654\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.549561500549316\n",
      "Epoch: 218\n",
      "\tTrain Loss: 5.550 | Train PPL: 257.125\n",
      "\tVal Loss: 5.539 |  Val PPL: 254.300\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.560012340545654\n",
      "Epoch: 219\n",
      "\tTrain Loss: 5.560 | Train PPL: 259.826\n",
      "\tVal Loss: 5.537 |  Val PPL: 253.923\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.557897567749023\n",
      "Epoch: 220\n",
      "\tTrain Loss: 5.558 | Train PPL: 259.277\n",
      "\tVal Loss: 5.535 |  Val PPL: 253.529\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.546750545501709\n",
      "Epoch: 221\n",
      "\tTrain Loss: 5.547 | Train PPL: 256.403\n",
      "\tVal Loss: 5.534 |  Val PPL: 253.125\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.564197540283203\n",
      "Epoch: 222\n",
      "\tTrain Loss: 5.564 | Train PPL: 260.916\n",
      "\tVal Loss: 5.532 |  Val PPL: 252.682\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.557502746582031\n",
      "Epoch: 223\n",
      "\tTrain Loss: 5.558 | Train PPL: 259.175\n",
      "\tVal Loss: 5.531 |  Val PPL: 252.375\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.558588027954102\n",
      "Epoch: 224\n",
      "\tTrain Loss: 5.559 | Train PPL: 259.456\n",
      "\tVal Loss: 5.530 |  Val PPL: 252.050\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.553784370422363\n",
      "Epoch: 225\n",
      "\tTrain Loss: 5.554 | Train PPL: 258.213\n",
      "\tVal Loss: 5.529 |  Val PPL: 251.791\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.530436992645264\n",
      "Epoch: 226\n",
      "\tTrain Loss: 5.530 | Train PPL: 252.254\n",
      "\tVal Loss: 5.528 |  Val PPL: 251.576\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.543544292449951\n",
      "Epoch: 227\n",
      "\tTrain Loss: 5.544 | Train PPL: 255.582\n",
      "\tVal Loss: 5.527 |  Val PPL: 251.360\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.554638862609863\n",
      "Epoch: 228\n",
      "\tTrain Loss: 5.555 | Train PPL: 258.434\n",
      "\tVal Loss: 5.526 |  Val PPL: 251.136\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.536832809448242\n",
      "Epoch: 229\n",
      "\tTrain Loss: 5.537 | Train PPL: 253.873\n",
      "\tVal Loss: 5.525 |  Val PPL: 250.949\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.549473285675049\n",
      "Epoch: 230\n",
      "\tTrain Loss: 5.549 | Train PPL: 257.102\n",
      "\tVal Loss: 5.525 |  Val PPL: 250.819\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.55973482131958\n",
      "Epoch: 231\n",
      "\tTrain Loss: 5.560 | Train PPL: 259.754\n",
      "\tVal Loss: 5.524 |  Val PPL: 250.618\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.536448955535889\n",
      "Epoch: 232\n",
      "\tTrain Loss: 5.536 | Train PPL: 253.775\n",
      "\tVal Loss: 5.523 |  Val PPL: 250.439\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.5575480461120605\n",
      "Epoch: 233\n",
      "\tTrain Loss: 5.558 | Train PPL: 259.187\n",
      "\tVal Loss: 5.523 |  Val PPL: 250.352\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.549015045166016\n",
      "Epoch: 234\n",
      "\tTrain Loss: 5.549 | Train PPL: 256.984\n",
      "\tVal Loss: 5.522 |  Val PPL: 250.218\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.526223659515381\n",
      "Epoch: 235\n",
      "\tTrain Loss: 5.526 | Train PPL: 251.194\n",
      "\tVal Loss: 5.522 |  Val PPL: 250.144\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.519839286804199\n",
      "Epoch: 236\n",
      "\tTrain Loss: 5.520 | Train PPL: 249.595\n",
      "\tVal Loss: 5.522 |  Val PPL: 250.036\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.540629863739014\n",
      "Epoch: 237\n",
      "\tTrain Loss: 5.541 | Train PPL: 254.838\n",
      "\tVal Loss: 5.522 |  Val PPL: 250.038\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.526173114776611\n",
      "Epoch: 238\n",
      "\tTrain Loss: 5.526 | Train PPL: 251.181\n",
      "\tVal Loss: 5.521 |  Val PPL: 249.966\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.539719104766846\n",
      "Epoch: 239\n",
      "\tTrain Loss: 5.540 | Train PPL: 254.606\n",
      "\tVal Loss: 5.521 |  Val PPL: 249.822\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.5483598709106445\n",
      "Epoch: 240\n",
      "\tTrain Loss: 5.548 | Train PPL: 256.816\n",
      "\tVal Loss: 5.520 |  Val PPL: 249.667\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.527502536773682\n",
      "Epoch: 241\n",
      "\tTrain Loss: 5.528 | Train PPL: 251.515\n",
      "\tVal Loss: 5.519 |  Val PPL: 249.439\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.534597396850586\n",
      "Epoch: 242\n",
      "\tTrain Loss: 5.535 | Train PPL: 253.306\n",
      "\tVal Loss: 5.518 |  Val PPL: 249.193\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.528611660003662\n",
      "Epoch: 243\n",
      "\tTrain Loss: 5.529 | Train PPL: 251.794\n",
      "\tVal Loss: 5.517 |  Val PPL: 248.884\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.5388593673706055\n",
      "Epoch: 244\n",
      "\tTrain Loss: 5.539 | Train PPL: 254.388\n",
      "\tVal Loss: 5.516 |  Val PPL: 248.538\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.497803211212158\n",
      "Epoch: 245\n",
      "\tTrain Loss: 5.498 | Train PPL: 244.155\n",
      "\tVal Loss: 5.514 |  Val PPL: 248.175\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.529202938079834\n",
      "Epoch: 246\n",
      "\tTrain Loss: 5.529 | Train PPL: 251.943\n",
      "\tVal Loss: 5.513 |  Val PPL: 247.829\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.527124404907227\n",
      "Epoch: 247\n",
      "\tTrain Loss: 5.527 | Train PPL: 251.420\n",
      "\tVal Loss: 5.511 |  Val PPL: 247.492\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.506683826446533\n",
      "Epoch: 248\n",
      "\tTrain Loss: 5.507 | Train PPL: 246.333\n",
      "\tVal Loss: 5.510 |  Val PPL: 247.236\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.539315223693848\n",
      "Epoch: 249\n",
      "\tTrain Loss: 5.539 | Train PPL: 254.504\n",
      "\tVal Loss: 5.509 |  Val PPL: 246.938\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.524726867675781\n",
      "Epoch: 250\n",
      "\tTrain Loss: 5.525 | Train PPL: 250.818\n",
      "\tVal Loss: 5.508 |  Val PPL: 246.615\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.506466865539551\n",
      "Epoch: 251\n",
      "\tTrain Loss: 5.506 | Train PPL: 246.279\n",
      "\tVal Loss: 5.506 |  Val PPL: 246.231\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.527596473693848\n",
      "Epoch: 252\n",
      "\tTrain Loss: 5.528 | Train PPL: 251.539\n",
      "\tVal Loss: 5.505 |  Val PPL: 245.815\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.514622211456299\n",
      "Epoch: 253\n",
      "\tTrain Loss: 5.515 | Train PPL: 248.296\n",
      "\tVal Loss: 5.504 |  Val PPL: 245.561\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.515097141265869\n",
      "Epoch: 254\n",
      "\tTrain Loss: 5.515 | Train PPL: 248.414\n",
      "\tVal Loss: 5.502 |  Val PPL: 245.232\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.502381801605225\n",
      "Epoch: 255\n",
      "\tTrain Loss: 5.502 | Train PPL: 245.275\n",
      "\tVal Loss: 5.501 |  Val PPL: 244.910\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.519957065582275\n",
      "Epoch: 256\n",
      "\tTrain Loss: 5.520 | Train PPL: 249.624\n",
      "\tVal Loss: 5.500 |  Val PPL: 244.681\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.509315490722656\n",
      "Epoch: 257\n",
      "\tTrain Loss: 5.509 | Train PPL: 246.982\n",
      "\tVal Loss: 5.499 |  Val PPL: 244.491\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.506475448608398\n",
      "Epoch: 258\n",
      "\tTrain Loss: 5.506 | Train PPL: 246.282\n",
      "\tVal Loss: 5.498 |  Val PPL: 244.304\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.516599655151367\n",
      "Epoch: 259\n",
      "\tTrain Loss: 5.517 | Train PPL: 248.788\n",
      "\tVal Loss: 5.497 |  Val PPL: 244.061\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.546040058135986\n",
      "Epoch: 260\n",
      "\tTrain Loss: 5.546 | Train PPL: 256.221\n",
      "\tVal Loss: 5.496 |  Val PPL: 243.702\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.508338451385498\n",
      "Epoch: 261\n",
      "\tTrain Loss: 5.508 | Train PPL: 246.741\n",
      "\tVal Loss: 5.494 |  Val PPL: 243.265\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.511491298675537\n",
      "Epoch: 262\n",
      "\tTrain Loss: 5.511 | Train PPL: 247.520\n",
      "\tVal Loss: 5.492 |  Val PPL: 242.777\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.5136566162109375\n",
      "Epoch: 263\n",
      "\tTrain Loss: 5.514 | Train PPL: 248.057\n",
      "\tVal Loss: 5.490 |  Val PPL: 242.267\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.4973554611206055\n",
      "Epoch: 264\n",
      "\tTrain Loss: 5.497 | Train PPL: 244.046\n",
      "\tVal Loss: 5.488 |  Val PPL: 241.744\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.491879940032959\n",
      "Epoch: 265\n",
      "\tTrain Loss: 5.492 | Train PPL: 242.713\n",
      "\tVal Loss: 5.486 |  Val PPL: 241.270\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.52243185043335\n",
      "Epoch: 266\n",
      "\tTrain Loss: 5.522 | Train PPL: 250.243\n",
      "\tVal Loss: 5.484 |  Val PPL: 240.851\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.496475696563721\n",
      "Epoch: 267\n",
      "\tTrain Loss: 5.496 | Train PPL: 243.831\n",
      "\tVal Loss: 5.483 |  Val PPL: 240.449\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.4938788414001465\n",
      "Epoch: 268\n",
      "\tTrain Loss: 5.494 | Train PPL: 243.199\n",
      "\tVal Loss: 5.481 |  Val PPL: 240.101\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.492668628692627\n",
      "Epoch: 269\n",
      "\tTrain Loss: 5.493 | Train PPL: 242.905\n",
      "\tVal Loss: 5.480 |  Val PPL: 239.792\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.486818313598633\n",
      "Epoch: 270\n",
      "\tTrain Loss: 5.487 | Train PPL: 241.488\n",
      "\tVal Loss: 5.478 |  Val PPL: 239.380\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.523738861083984\n",
      "Epoch: 271\n",
      "\tTrain Loss: 5.524 | Train PPL: 250.570\n",
      "\tVal Loss: 5.477 |  Val PPL: 239.083\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.485261917114258\n",
      "Epoch: 272\n",
      "\tTrain Loss: 5.485 | Train PPL: 241.112\n",
      "\tVal Loss: 5.475 |  Val PPL: 238.766\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.486385822296143\n",
      "Epoch: 273\n",
      "\tTrain Loss: 5.486 | Train PPL: 241.383\n",
      "\tVal Loss: 5.474 |  Val PPL: 238.423\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.467623710632324\n",
      "Epoch: 274\n",
      "\tTrain Loss: 5.468 | Train PPL: 236.897\n",
      "\tVal Loss: 5.473 |  Val PPL: 238.108\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.495426177978516\n",
      "Epoch: 275\n",
      "\tTrain Loss: 5.495 | Train PPL: 243.575\n",
      "\tVal Loss: 5.471 |  Val PPL: 237.758\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.488901138305664\n",
      "Epoch: 276\n",
      "\tTrain Loss: 5.489 | Train PPL: 241.991\n",
      "\tVal Loss: 5.470 |  Val PPL: 237.435\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.481683254241943\n",
      "Epoch: 277\n",
      "\tTrain Loss: 5.482 | Train PPL: 240.251\n",
      "\tVal Loss: 5.468 |  Val PPL: 237.097\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.478532791137695\n",
      "Epoch: 278\n",
      "\tTrain Loss: 5.479 | Train PPL: 239.495\n",
      "\tVal Loss: 5.467 |  Val PPL: 236.794\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.486869812011719\n",
      "Epoch: 279\n",
      "\tTrain Loss: 5.487 | Train PPL: 241.500\n",
      "\tVal Loss: 5.466 |  Val PPL: 236.517\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.5043840408325195\n",
      "Epoch: 280\n",
      "\tTrain Loss: 5.504 | Train PPL: 245.767\n",
      "\tVal Loss: 5.465 |  Val PPL: 236.186\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.4875168800354\n",
      "Epoch: 281\n",
      "\tTrain Loss: 5.488 | Train PPL: 241.656\n",
      "\tVal Loss: 5.463 |  Val PPL: 235.832\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.496484279632568\n",
      "Epoch: 282\n",
      "\tTrain Loss: 5.496 | Train PPL: 243.833\n",
      "\tVal Loss: 5.462 |  Val PPL: 235.567\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.4888081550598145\n",
      "Epoch: 283\n",
      "\tTrain Loss: 5.489 | Train PPL: 241.969\n",
      "\tVal Loss: 5.461 |  Val PPL: 235.334\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.496241092681885\n",
      "Epoch: 284\n",
      "\tTrain Loss: 5.496 | Train PPL: 243.774\n",
      "\tVal Loss: 5.460 |  Val PPL: 235.105\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.488930702209473\n",
      "Epoch: 285\n",
      "\tTrain Loss: 5.489 | Train PPL: 241.998\n",
      "\tVal Loss: 5.459 |  Val PPL: 234.824\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.493241786956787\n",
      "Epoch: 286\n",
      "\tTrain Loss: 5.493 | Train PPL: 243.044\n",
      "\tVal Loss: 5.458 |  Val PPL: 234.573\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.484571933746338\n",
      "Epoch: 287\n",
      "\tTrain Loss: 5.485 | Train PPL: 240.946\n",
      "\tVal Loss: 5.457 |  Val PPL: 234.381\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.452620983123779\n",
      "Epoch: 288\n",
      "\tTrain Loss: 5.453 | Train PPL: 233.369\n",
      "\tVal Loss: 5.456 |  Val PPL: 234.132\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.485023021697998\n",
      "Epoch: 289\n",
      "\tTrain Loss: 5.485 | Train PPL: 241.054\n",
      "\tVal Loss: 5.454 |  Val PPL: 233.799\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.483567714691162\n",
      "Epoch: 290\n",
      "\tTrain Loss: 5.484 | Train PPL: 240.704\n",
      "\tVal Loss: 5.453 |  Val PPL: 233.442\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.4903340339660645\n",
      "Epoch: 291\n",
      "\tTrain Loss: 5.490 | Train PPL: 242.338\n",
      "\tVal Loss: 5.451 |  Val PPL: 233.085\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.489339828491211\n",
      "Epoch: 292\n",
      "\tTrain Loss: 5.489 | Train PPL: 242.097\n",
      "\tVal Loss: 5.450 |  Val PPL: 232.783\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.468448162078857\n",
      "Epoch: 293\n",
      "\tTrain Loss: 5.468 | Train PPL: 237.092\n",
      "\tVal Loss: 5.449 |  Val PPL: 232.484\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.483613014221191\n",
      "Epoch: 294\n",
      "\tTrain Loss: 5.484 | Train PPL: 240.715\n",
      "\tVal Loss: 5.448 |  Val PPL: 232.240\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.470729827880859\n",
      "Epoch: 295\n",
      "\tTrain Loss: 5.471 | Train PPL: 237.634\n",
      "\tVal Loss: 5.447 |  Val PPL: 232.004\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.455904960632324\n",
      "Epoch: 296\n",
      "\tTrain Loss: 5.456 | Train PPL: 234.137\n",
      "\tVal Loss: 5.446 |  Val PPL: 231.759\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.454638957977295\n",
      "Epoch: 297\n",
      "\tTrain Loss: 5.455 | Train PPL: 233.840\n",
      "\tVal Loss: 5.444 |  Val PPL: 231.458\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.481749057769775\n",
      "Epoch: 298\n",
      "\tTrain Loss: 5.482 | Train PPL: 240.267\n",
      "\tVal Loss: 5.443 |  Val PPL: 231.106\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.465841293334961\n",
      "Epoch: 299\n",
      "\tTrain Loss: 5.466 | Train PPL: 236.475\n",
      "\tVal Loss: 5.441 |  Val PPL: 230.693\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.478461265563965\n",
      "Epoch: 300\n",
      "\tTrain Loss: 5.478 | Train PPL: 239.478\n",
      "\tVal Loss: 5.439 |  Val PPL: 230.311\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.457529067993164\n",
      "Epoch: 301\n",
      "\tTrain Loss: 5.458 | Train PPL: 234.517\n",
      "\tVal Loss: 5.438 |  Val PPL: 229.923\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.457499980926514\n",
      "Epoch: 302\n",
      "\tTrain Loss: 5.457 | Train PPL: 234.510\n",
      "\tVal Loss: 5.436 |  Val PPL: 229.582\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.45207405090332\n",
      "Epoch: 303\n",
      "\tTrain Loss: 5.452 | Train PPL: 233.241\n",
      "\tVal Loss: 5.435 |  Val PPL: 229.267\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.458646297454834\n",
      "Epoch: 304\n",
      "\tTrain Loss: 5.459 | Train PPL: 234.779\n",
      "\tVal Loss: 5.433 |  Val PPL: 228.881\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.467524528503418\n",
      "Epoch: 305\n",
      "\tTrain Loss: 5.468 | Train PPL: 236.873\n",
      "\tVal Loss: 5.432 |  Val PPL: 228.530\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.449694633483887\n",
      "Epoch: 306\n",
      "\tTrain Loss: 5.450 | Train PPL: 232.687\n",
      "\tVal Loss: 5.430 |  Val PPL: 228.142\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.456584930419922\n",
      "Epoch: 307\n",
      "\tTrain Loss: 5.457 | Train PPL: 234.296\n",
      "\tVal Loss: 5.429 |  Val PPL: 227.831\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.445042610168457\n",
      "Epoch: 308\n",
      "\tTrain Loss: 5.445 | Train PPL: 231.607\n",
      "\tVal Loss: 5.427 |  Val PPL: 227.492\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.455294132232666\n",
      "Epoch: 309\n",
      "\tTrain Loss: 5.455 | Train PPL: 233.994\n",
      "\tVal Loss: 5.425 |  Val PPL: 227.091\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.44597053527832\n",
      "Epoch: 310\n",
      "\tTrain Loss: 5.446 | Train PPL: 231.822\n",
      "\tVal Loss: 5.424 |  Val PPL: 226.749\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.459836483001709\n",
      "Epoch: 311\n",
      "\tTrain Loss: 5.460 | Train PPL: 235.059\n",
      "\tVal Loss: 5.422 |  Val PPL: 226.399\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.448625087738037\n",
      "Epoch: 312\n",
      "\tTrain Loss: 5.449 | Train PPL: 232.438\n",
      "\tVal Loss: 5.420 |  Val PPL: 225.990\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.439023494720459\n",
      "Epoch: 313\n",
      "\tTrain Loss: 5.439 | Train PPL: 230.217\n",
      "\tVal Loss: 5.419 |  Val PPL: 225.686\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.45683479309082\n",
      "Epoch: 314\n",
      "\tTrain Loss: 5.457 | Train PPL: 234.354\n",
      "\tVal Loss: 5.418 |  Val PPL: 225.404\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.459264755249023\n",
      "Epoch: 315\n",
      "\tTrain Loss: 5.459 | Train PPL: 234.925\n",
      "\tVal Loss: 5.417 |  Val PPL: 225.103\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.434228897094727\n",
      "Epoch: 316\n",
      "\tTrain Loss: 5.434 | Train PPL: 229.116\n",
      "\tVal Loss: 5.415 |  Val PPL: 224.820\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.451111793518066\n",
      "Epoch: 317\n",
      "\tTrain Loss: 5.451 | Train PPL: 233.017\n",
      "\tVal Loss: 5.414 |  Val PPL: 224.575\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.432849407196045\n",
      "Epoch: 318\n",
      "\tTrain Loss: 5.433 | Train PPL: 228.800\n",
      "\tVal Loss: 5.413 |  Val PPL: 224.331\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.428040981292725\n",
      "Epoch: 319\n",
      "\tTrain Loss: 5.428 | Train PPL: 227.703\n",
      "\tVal Loss: 5.412 |  Val PPL: 224.110\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.444448947906494\n",
      "Epoch: 320\n",
      "\tTrain Loss: 5.444 | Train PPL: 231.470\n",
      "\tVal Loss: 5.411 |  Val PPL: 223.912\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.471446514129639\n",
      "Epoch: 321\n",
      "\tTrain Loss: 5.471 | Train PPL: 237.804\n",
      "\tVal Loss: 5.410 |  Val PPL: 223.731\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.467513084411621\n",
      "Epoch: 322\n",
      "\tTrain Loss: 5.468 | Train PPL: 236.870\n",
      "\tVal Loss: 5.409 |  Val PPL: 223.483\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.452578067779541\n",
      "Epoch: 323\n",
      "\tTrain Loss: 5.453 | Train PPL: 233.359\n",
      "\tVal Loss: 5.408 |  Val PPL: 223.167\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.462069988250732\n",
      "Epoch: 324\n",
      "\tTrain Loss: 5.462 | Train PPL: 235.585\n",
      "\tVal Loss: 5.406 |  Val PPL: 222.812\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.444180965423584\n",
      "Epoch: 325\n",
      "\tTrain Loss: 5.444 | Train PPL: 231.408\n",
      "\tVal Loss: 5.405 |  Val PPL: 222.459\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.455191135406494\n",
      "Epoch: 326\n",
      "\tTrain Loss: 5.455 | Train PPL: 233.970\n",
      "\tVal Loss: 5.403 |  Val PPL: 222.060\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.4447808265686035\n",
      "Epoch: 327\n",
      "\tTrain Loss: 5.445 | Train PPL: 231.547\n",
      "\tVal Loss: 5.401 |  Val PPL: 221.713\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.431354522705078\n",
      "Epoch: 328\n",
      "\tTrain Loss: 5.431 | Train PPL: 228.458\n",
      "\tVal Loss: 5.400 |  Val PPL: 221.341\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.454100608825684\n",
      "Epoch: 329\n",
      "\tTrain Loss: 5.454 | Train PPL: 233.715\n",
      "\tVal Loss: 5.398 |  Val PPL: 220.977\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.434072494506836\n",
      "Epoch: 330\n",
      "\tTrain Loss: 5.434 | Train PPL: 229.080\n",
      "\tVal Loss: 5.397 |  Val PPL: 220.665\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.419550895690918\n",
      "Epoch: 331\n",
      "\tTrain Loss: 5.420 | Train PPL: 225.778\n",
      "\tVal Loss: 5.395 |  Val PPL: 220.362\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.43499231338501\n",
      "Epoch: 332\n",
      "\tTrain Loss: 5.435 | Train PPL: 229.291\n",
      "\tVal Loss: 5.394 |  Val PPL: 220.146\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.437760353088379\n",
      "Epoch: 333\n",
      "\tTrain Loss: 5.438 | Train PPL: 229.927\n",
      "\tVal Loss: 5.393 |  Val PPL: 219.842\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.430817127227783\n",
      "Epoch: 334\n",
      "\tTrain Loss: 5.431 | Train PPL: 228.336\n",
      "\tVal Loss: 5.391 |  Val PPL: 219.496\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.4597978591918945\n",
      "Epoch: 335\n",
      "\tTrain Loss: 5.460 | Train PPL: 235.050\n",
      "\tVal Loss: 5.390 |  Val PPL: 219.173\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.424025535583496\n",
      "Epoch: 336\n",
      "\tTrain Loss: 5.424 | Train PPL: 226.790\n",
      "\tVal Loss: 5.389 |  Val PPL: 218.903\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.419221878051758\n",
      "Epoch: 337\n",
      "\tTrain Loss: 5.419 | Train PPL: 225.703\n",
      "\tVal Loss: 5.387 |  Val PPL: 218.585\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.441494941711426\n",
      "Epoch: 338\n",
      "\tTrain Loss: 5.441 | Train PPL: 230.787\n",
      "\tVal Loss: 5.386 |  Val PPL: 218.262\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.411707401275635\n",
      "Epoch: 339\n",
      "\tTrain Loss: 5.412 | Train PPL: 224.014\n",
      "\tVal Loss: 5.384 |  Val PPL: 217.966\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.432034015655518\n",
      "Epoch: 340\n",
      "\tTrain Loss: 5.432 | Train PPL: 228.614\n",
      "\tVal Loss: 5.383 |  Val PPL: 217.727\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.444519519805908\n",
      "Epoch: 341\n",
      "\tTrain Loss: 5.445 | Train PPL: 231.486\n",
      "\tVal Loss: 5.382 |  Val PPL: 217.444\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.413888454437256\n",
      "Epoch: 342\n",
      "\tTrain Loss: 5.414 | Train PPL: 224.503\n",
      "\tVal Loss: 5.381 |  Val PPL: 217.198\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.447227478027344\n",
      "Epoch: 343\n",
      "\tTrain Loss: 5.447 | Train PPL: 232.114\n",
      "\tVal Loss: 5.379 |  Val PPL: 216.890\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.434699058532715\n",
      "Epoch: 344\n",
      "\tTrain Loss: 5.435 | Train PPL: 229.224\n",
      "\tVal Loss: 5.378 |  Val PPL: 216.579\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.42738676071167\n",
      "Epoch: 345\n",
      "\tTrain Loss: 5.427 | Train PPL: 227.554\n",
      "\tVal Loss: 5.377 |  Val PPL: 216.283\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.4056620597839355\n",
      "Epoch: 346\n",
      "\tTrain Loss: 5.406 | Train PPL: 222.664\n",
      "\tVal Loss: 5.375 |  Val PPL: 216.041\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.434452056884766\n",
      "Epoch: 347\n",
      "\tTrain Loss: 5.434 | Train PPL: 229.167\n",
      "\tVal Loss: 5.375 |  Val PPL: 215.834\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.418704986572266\n",
      "Epoch: 348\n",
      "\tTrain Loss: 5.419 | Train PPL: 225.587\n",
      "\tVal Loss: 5.373 |  Val PPL: 215.535\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.40467643737793\n",
      "Epoch: 349\n",
      "\tTrain Loss: 5.405 | Train PPL: 222.444\n",
      "\tVal Loss: 5.372 |  Val PPL: 215.248\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.430654525756836\n",
      "Epoch: 350\n",
      "\tTrain Loss: 5.431 | Train PPL: 228.299\n",
      "\tVal Loss: 5.370 |  Val PPL: 214.969\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.409846305847168\n",
      "Epoch: 351\n",
      "\tTrain Loss: 5.410 | Train PPL: 223.597\n",
      "\tVal Loss: 5.369 |  Val PPL: 214.732\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.40338134765625\n",
      "Epoch: 352\n",
      "\tTrain Loss: 5.403 | Train PPL: 222.156\n",
      "\tVal Loss: 5.368 |  Val PPL: 214.437\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.400325775146484\n",
      "Epoch: 353\n",
      "\tTrain Loss: 5.400 | Train PPL: 221.479\n",
      "\tVal Loss: 5.367 |  Val PPL: 214.151\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.4317498207092285\n",
      "Epoch: 354\n",
      "\tTrain Loss: 5.432 | Train PPL: 228.549\n",
      "\tVal Loss: 5.365 |  Val PPL: 213.784\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.401294708251953\n",
      "Epoch: 355\n",
      "\tTrain Loss: 5.401 | Train PPL: 221.693\n",
      "\tVal Loss: 5.363 |  Val PPL: 213.450\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.425127029418945\n",
      "Epoch: 356\n",
      "\tTrain Loss: 5.425 | Train PPL: 227.040\n",
      "\tVal Loss: 5.362 |  Val PPL: 213.158\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.403728008270264\n",
      "Epoch: 357\n",
      "\tTrain Loss: 5.404 | Train PPL: 222.233\n",
      "\tVal Loss: 5.360 |  Val PPL: 212.830\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.4178080558776855\n",
      "Epoch: 358\n",
      "\tTrain Loss: 5.418 | Train PPL: 225.385\n",
      "\tVal Loss: 5.359 |  Val PPL: 212.564\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.384718894958496\n",
      "Epoch: 359\n",
      "\tTrain Loss: 5.385 | Train PPL: 218.049\n",
      "\tVal Loss: 5.358 |  Val PPL: 212.285\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.414505481719971\n",
      "Epoch: 360\n",
      "\tTrain Loss: 5.415 | Train PPL: 224.641\n",
      "\tVal Loss: 5.357 |  Val PPL: 212.115\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.401684761047363\n",
      "Epoch: 361\n",
      "\tTrain Loss: 5.402 | Train PPL: 221.780\n",
      "\tVal Loss: 5.357 |  Val PPL: 212.002\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.384969234466553\n",
      "Epoch: 362\n",
      "\tTrain Loss: 5.385 | Train PPL: 218.103\n",
      "\tVal Loss: 5.356 |  Val PPL: 211.936\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.407337188720703\n",
      "Epoch: 363\n",
      "\tTrain Loss: 5.407 | Train PPL: 223.037\n",
      "\tVal Loss: 5.356 |  Val PPL: 211.803\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.393899440765381\n",
      "Epoch: 364\n",
      "\tTrain Loss: 5.394 | Train PPL: 220.060\n",
      "\tVal Loss: 5.355 |  Val PPL: 211.614\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.414055347442627\n",
      "Epoch: 365\n",
      "\tTrain Loss: 5.414 | Train PPL: 224.540\n",
      "\tVal Loss: 5.354 |  Val PPL: 211.407\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.409005641937256\n",
      "Epoch: 366\n",
      "\tTrain Loss: 5.409 | Train PPL: 223.409\n",
      "\tVal Loss: 5.352 |  Val PPL: 211.103\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.40076208114624\n",
      "Epoch: 367\n",
      "\tTrain Loss: 5.401 | Train PPL: 221.575\n",
      "\tVal Loss: 5.351 |  Val PPL: 210.774\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.416985034942627\n",
      "Epoch: 368\n",
      "\tTrain Loss: 5.417 | Train PPL: 225.199\n",
      "\tVal Loss: 5.349 |  Val PPL: 210.456\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.3872480392456055\n",
      "Epoch: 369\n",
      "\tTrain Loss: 5.387 | Train PPL: 218.601\n",
      "\tVal Loss: 5.348 |  Val PPL: 210.195\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.392531394958496\n",
      "Epoch: 370\n",
      "\tTrain Loss: 5.393 | Train PPL: 219.759\n",
      "\tVal Loss: 5.347 |  Val PPL: 209.917\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.397730827331543\n",
      "Epoch: 371\n",
      "\tTrain Loss: 5.398 | Train PPL: 220.905\n",
      "\tVal Loss: 5.345 |  Val PPL: 209.624\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.403792858123779\n",
      "Epoch: 372\n",
      "\tTrain Loss: 5.404 | Train PPL: 222.248\n",
      "\tVal Loss: 5.344 |  Val PPL: 209.327\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.386266231536865\n",
      "Epoch: 373\n",
      "\tTrain Loss: 5.386 | Train PPL: 218.386\n",
      "\tVal Loss: 5.342 |  Val PPL: 209.025\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.39499568939209\n",
      "Epoch: 374\n",
      "\tTrain Loss: 5.395 | Train PPL: 220.301\n",
      "\tVal Loss: 5.341 |  Val PPL: 208.721\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.39963960647583\n",
      "Epoch: 375\n",
      "\tTrain Loss: 5.400 | Train PPL: 221.327\n",
      "\tVal Loss: 5.340 |  Val PPL: 208.502\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.393795967102051\n",
      "Epoch: 376\n",
      "\tTrain Loss: 5.394 | Train PPL: 220.037\n",
      "\tVal Loss: 5.339 |  Val PPL: 208.241\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.392212390899658\n",
      "Epoch: 377\n",
      "\tTrain Loss: 5.392 | Train PPL: 219.689\n",
      "\tVal Loss: 5.337 |  Val PPL: 207.911\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.3905816078186035\n",
      "Epoch: 378\n",
      "\tTrain Loss: 5.391 | Train PPL: 219.331\n",
      "\tVal Loss: 5.336 |  Val PPL: 207.612\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.3830976486206055\n",
      "Epoch: 379\n",
      "\tTrain Loss: 5.383 | Train PPL: 217.696\n",
      "\tVal Loss: 5.334 |  Val PPL: 207.287\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.381702899932861\n",
      "Epoch: 380\n",
      "\tTrain Loss: 5.382 | Train PPL: 217.392\n",
      "\tVal Loss: 5.332 |  Val PPL: 206.929\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.399261474609375\n",
      "Epoch: 381\n",
      "\tTrain Loss: 5.399 | Train PPL: 221.243\n",
      "\tVal Loss: 5.331 |  Val PPL: 206.554\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.382972240447998\n",
      "Epoch: 382\n",
      "\tTrain Loss: 5.383 | Train PPL: 217.668\n",
      "\tVal Loss: 5.329 |  Val PPL: 206.182\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.398411750793457\n",
      "Epoch: 383\n",
      "\tTrain Loss: 5.398 | Train PPL: 221.055\n",
      "\tVal Loss: 5.327 |  Val PPL: 205.737\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.389622688293457\n",
      "Epoch: 384\n",
      "\tTrain Loss: 5.390 | Train PPL: 219.121\n",
      "\tVal Loss: 5.324 |  Val PPL: 205.288\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.378507137298584\n",
      "Epoch: 385\n",
      "\tTrain Loss: 5.379 | Train PPL: 216.699\n",
      "\tVal Loss: 5.322 |  Val PPL: 204.895\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.365412712097168\n",
      "Epoch: 386\n",
      "\tTrain Loss: 5.365 | Train PPL: 213.879\n",
      "\tVal Loss: 5.321 |  Val PPL: 204.504\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.3634867668151855\n",
      "Epoch: 387\n",
      "\tTrain Loss: 5.363 | Train PPL: 213.468\n",
      "\tVal Loss: 5.319 |  Val PPL: 204.102\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.3730621337890625\n",
      "Epoch: 388\n",
      "\tTrain Loss: 5.373 | Train PPL: 215.522\n",
      "\tVal Loss: 5.318 |  Val PPL: 203.900\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.379811763763428\n",
      "Epoch: 389\n",
      "\tTrain Loss: 5.380 | Train PPL: 216.981\n",
      "\tVal Loss: 5.317 |  Val PPL: 203.736\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.387565612792969\n",
      "Epoch: 390\n",
      "\tTrain Loss: 5.388 | Train PPL: 218.670\n",
      "\tVal Loss: 5.316 |  Val PPL: 203.551\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.384592533111572\n",
      "Epoch: 391\n",
      "\tTrain Loss: 5.385 | Train PPL: 218.021\n",
      "\tVal Loss: 5.315 |  Val PPL: 203.331\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.369285583496094\n",
      "Epoch: 392\n",
      "\tTrain Loss: 5.369 | Train PPL: 214.709\n",
      "\tVal Loss: 5.313 |  Val PPL: 203.052\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.375393867492676\n",
      "Epoch: 393\n",
      "\tTrain Loss: 5.375 | Train PPL: 216.025\n",
      "\tVal Loss: 5.312 |  Val PPL: 202.801\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.3365349769592285\n",
      "Epoch: 394\n",
      "\tTrain Loss: 5.337 | Train PPL: 207.791\n",
      "\tVal Loss: 5.311 |  Val PPL: 202.604\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.356043338775635\n",
      "Epoch: 395\n",
      "\tTrain Loss: 5.356 | Train PPL: 211.885\n",
      "\tVal Loss: 5.310 |  Val PPL: 202.405\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.366961479187012\n",
      "Epoch: 396\n",
      "\tTrain Loss: 5.367 | Train PPL: 214.211\n",
      "\tVal Loss: 5.309 |  Val PPL: 202.234\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.3546624183654785\n",
      "Epoch: 397\n",
      "\tTrain Loss: 5.355 | Train PPL: 211.593\n",
      "\tVal Loss: 5.309 |  Val PPL: 202.146\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.379715919494629\n",
      "Epoch: 398\n",
      "\tTrain Loss: 5.380 | Train PPL: 216.961\n",
      "\tVal Loss: 5.308 |  Val PPL: 202.038\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.363735198974609\n",
      "Epoch: 399\n",
      "\tTrain Loss: 5.364 | Train PPL: 213.521\n",
      "\tVal Loss: 5.308 |  Val PPL: 201.999\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.361712455749512\n",
      "Epoch: 400\n",
      "\tTrain Loss: 5.362 | Train PPL: 213.090\n",
      "\tVal Loss: 5.308 |  Val PPL: 201.973\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.344448566436768\n",
      "Epoch: 401\n",
      "\tTrain Loss: 5.344 | Train PPL: 209.442\n",
      "\tVal Loss: 5.308 |  Val PPL: 201.865\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.374032020568848\n",
      "Epoch: 402\n",
      "\tTrain Loss: 5.374 | Train PPL: 215.731\n",
      "\tVal Loss: 5.307 |  Val PPL: 201.660\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.350528717041016\n",
      "Epoch: 403\n",
      "\tTrain Loss: 5.351 | Train PPL: 210.720\n",
      "\tVal Loss: 5.305 |  Val PPL: 201.343\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.370340824127197\n",
      "Epoch: 404\n",
      "\tTrain Loss: 5.370 | Train PPL: 214.936\n",
      "\tVal Loss: 5.303 |  Val PPL: 201.017\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.374513149261475\n",
      "Epoch: 405\n",
      "\tTrain Loss: 5.375 | Train PPL: 215.835\n",
      "\tVal Loss: 5.302 |  Val PPL: 200.644\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.342411518096924\n",
      "Epoch: 406\n",
      "\tTrain Loss: 5.342 | Train PPL: 209.016\n",
      "\tVal Loss: 5.300 |  Val PPL: 200.271\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.368952751159668\n",
      "Epoch: 407\n",
      "\tTrain Loss: 5.369 | Train PPL: 214.638\n",
      "\tVal Loss: 5.298 |  Val PPL: 199.946\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.363170623779297\n",
      "Epoch: 408\n",
      "\tTrain Loss: 5.363 | Train PPL: 213.400\n",
      "\tVal Loss: 5.296 |  Val PPL: 199.584\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.358970642089844\n",
      "Epoch: 409\n",
      "\tTrain Loss: 5.359 | Train PPL: 212.506\n",
      "\tVal Loss: 5.294 |  Val PPL: 199.139\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.3428192138671875\n",
      "Epoch: 410\n",
      "\tTrain Loss: 5.343 | Train PPL: 209.101\n",
      "\tVal Loss: 5.292 |  Val PPL: 198.697\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.368136882781982\n",
      "Epoch: 411\n",
      "\tTrain Loss: 5.368 | Train PPL: 214.463\n",
      "\tVal Loss: 5.290 |  Val PPL: 198.319\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.332739353179932\n",
      "Epoch: 412\n",
      "\tTrain Loss: 5.333 | Train PPL: 207.004\n",
      "\tVal Loss: 5.288 |  Val PPL: 197.990\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.365077018737793\n",
      "Epoch: 413\n",
      "\tTrain Loss: 5.365 | Train PPL: 213.808\n",
      "\tVal Loss: 5.287 |  Val PPL: 197.686\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.341446876525879\n",
      "Epoch: 414\n",
      "\tTrain Loss: 5.341 | Train PPL: 208.815\n",
      "\tVal Loss: 5.285 |  Val PPL: 197.379\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.351306438446045\n",
      "Epoch: 415\n",
      "\tTrain Loss: 5.351 | Train PPL: 210.884\n",
      "\tVal Loss: 5.284 |  Val PPL: 197.122\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.328817367553711\n",
      "Epoch: 416\n",
      "\tTrain Loss: 5.329 | Train PPL: 206.194\n",
      "\tVal Loss: 5.283 |  Val PPL: 196.866\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.356090545654297\n",
      "Epoch: 417\n",
      "\tTrain Loss: 5.356 | Train PPL: 211.895\n",
      "\tVal Loss: 5.282 |  Val PPL: 196.709\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.36742639541626\n",
      "Epoch: 418\n",
      "\tTrain Loss: 5.367 | Train PPL: 214.311\n",
      "\tVal Loss: 5.280 |  Val PPL: 196.464\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.334312438964844\n",
      "Epoch: 419\n",
      "\tTrain Loss: 5.334 | Train PPL: 207.330\n",
      "\tVal Loss: 5.279 |  Val PPL: 196.259\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.326773166656494\n",
      "Epoch: 420\n",
      "\tTrain Loss: 5.327 | Train PPL: 205.773\n",
      "\tVal Loss: 5.278 |  Val PPL: 196.055\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.3237504959106445\n",
      "Epoch: 421\n",
      "\tTrain Loss: 5.324 | Train PPL: 205.152\n",
      "\tVal Loss: 5.277 |  Val PPL: 195.797\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.33917760848999\n",
      "Epoch: 422\n",
      "\tTrain Loss: 5.339 | Train PPL: 208.341\n",
      "\tVal Loss: 5.276 |  Val PPL: 195.570\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.351135730743408\n",
      "Epoch: 423\n",
      "\tTrain Loss: 5.351 | Train PPL: 210.848\n",
      "\tVal Loss: 5.274 |  Val PPL: 195.274\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.325414180755615\n",
      "Epoch: 424\n",
      "\tTrain Loss: 5.325 | Train PPL: 205.493\n",
      "\tVal Loss: 5.273 |  Val PPL: 194.934\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.328425884246826\n",
      "Epoch: 425\n",
      "\tTrain Loss: 5.328 | Train PPL: 206.113\n",
      "\tVal Loss: 5.271 |  Val PPL: 194.607\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.302851676940918\n",
      "Epoch: 426\n",
      "\tTrain Loss: 5.303 | Train PPL: 200.909\n",
      "\tVal Loss: 5.269 |  Val PPL: 194.286\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.3341965675354\n",
      "Epoch: 427\n",
      "\tTrain Loss: 5.334 | Train PPL: 207.306\n",
      "\tVal Loss: 5.268 |  Val PPL: 193.937\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.336071014404297\n",
      "Epoch: 428\n",
      "\tTrain Loss: 5.336 | Train PPL: 207.695\n",
      "\tVal Loss: 5.266 |  Val PPL: 193.606\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.3520355224609375\n",
      "Epoch: 429\n",
      "\tTrain Loss: 5.352 | Train PPL: 211.037\n",
      "\tVal Loss: 5.265 |  Val PPL: 193.411\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.339902877807617\n",
      "Epoch: 430\n",
      "\tTrain Loss: 5.340 | Train PPL: 208.492\n",
      "\tVal Loss: 5.264 |  Val PPL: 193.305\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.335355281829834\n",
      "Epoch: 431\n",
      "\tTrain Loss: 5.335 | Train PPL: 207.546\n",
      "\tVal Loss: 5.264 |  Val PPL: 193.159\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.3310017585754395\n",
      "Epoch: 432\n",
      "\tTrain Loss: 5.331 | Train PPL: 206.645\n",
      "\tVal Loss: 5.262 |  Val PPL: 192.958\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.310038089752197\n",
      "Epoch: 433\n",
      "\tTrain Loss: 5.310 | Train PPL: 202.358\n",
      "\tVal Loss: 5.261 |  Val PPL: 192.741\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.3297319412231445\n",
      "Epoch: 434\n",
      "\tTrain Loss: 5.330 | Train PPL: 206.383\n",
      "\tVal Loss: 5.260 |  Val PPL: 192.397\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.299446105957031\n",
      "Epoch: 435\n",
      "\tTrain Loss: 5.299 | Train PPL: 200.226\n",
      "\tVal Loss: 5.257 |  Val PPL: 191.971\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.303853511810303\n",
      "Epoch: 436\n",
      "\tTrain Loss: 5.304 | Train PPL: 201.110\n",
      "\tVal Loss: 5.255 |  Val PPL: 191.514\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.324178695678711\n",
      "Epoch: 437\n",
      "\tTrain Loss: 5.324 | Train PPL: 205.240\n",
      "\tVal Loss: 5.253 |  Val PPL: 191.117\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.315384864807129\n",
      "Epoch: 438\n",
      "\tTrain Loss: 5.315 | Train PPL: 203.443\n",
      "\tVal Loss: 5.251 |  Val PPL: 190.742\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.316125869750977\n",
      "Epoch: 439\n",
      "\tTrain Loss: 5.316 | Train PPL: 203.594\n",
      "\tVal Loss: 5.249 |  Val PPL: 190.351\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.321181774139404\n",
      "Epoch: 440\n",
      "\tTrain Loss: 5.321 | Train PPL: 204.626\n",
      "\tVal Loss: 5.247 |  Val PPL: 190.003\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.301972389221191\n",
      "Epoch: 441\n",
      "\tTrain Loss: 5.302 | Train PPL: 200.732\n",
      "\tVal Loss: 5.245 |  Val PPL: 189.673\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.3244147300720215\n",
      "Epoch: 442\n",
      "\tTrain Loss: 5.324 | Train PPL: 205.288\n",
      "\tVal Loss: 5.244 |  Val PPL: 189.405\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.280993938446045\n",
      "Epoch: 443\n",
      "\tTrain Loss: 5.281 | Train PPL: 196.565\n",
      "\tVal Loss: 5.242 |  Val PPL: 189.117\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.310586452484131\n",
      "Epoch: 444\n",
      "\tTrain Loss: 5.311 | Train PPL: 202.469\n",
      "\tVal Loss: 5.241 |  Val PPL: 188.831\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.307788372039795\n",
      "Epoch: 445\n",
      "\tTrain Loss: 5.308 | Train PPL: 201.903\n",
      "\tVal Loss: 5.239 |  Val PPL: 188.555\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.296299457550049\n",
      "Epoch: 446\n",
      "\tTrain Loss: 5.296 | Train PPL: 199.597\n",
      "\tVal Loss: 5.238 |  Val PPL: 188.255\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.304590225219727\n",
      "Epoch: 447\n",
      "\tTrain Loss: 5.305 | Train PPL: 201.259\n",
      "\tVal Loss: 5.236 |  Val PPL: 187.977\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.298155784606934\n",
      "Epoch: 448\n",
      "\tTrain Loss: 5.298 | Train PPL: 199.968\n",
      "\tVal Loss: 5.235 |  Val PPL: 187.637\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.311568260192871\n",
      "Epoch: 449\n",
      "\tTrain Loss: 5.312 | Train PPL: 202.668\n",
      "\tVal Loss: 5.233 |  Val PPL: 187.307\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.295121669769287\n",
      "Epoch: 450\n",
      "\tTrain Loss: 5.295 | Train PPL: 199.362\n",
      "\tVal Loss: 5.231 |  Val PPL: 187.018\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.312882423400879\n",
      "Epoch: 451\n",
      "\tTrain Loss: 5.313 | Train PPL: 202.934\n",
      "\tVal Loss: 5.230 |  Val PPL: 186.722\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.3198418617248535\n",
      "Epoch: 452\n",
      "\tTrain Loss: 5.320 | Train PPL: 204.352\n",
      "\tVal Loss: 5.228 |  Val PPL: 186.386\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.302545070648193\n",
      "Epoch: 453\n",
      "\tTrain Loss: 5.303 | Train PPL: 200.847\n",
      "\tVal Loss: 5.226 |  Val PPL: 186.134\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.298456192016602\n",
      "Epoch: 454\n",
      "\tTrain Loss: 5.298 | Train PPL: 200.028\n",
      "\tVal Loss: 5.225 |  Val PPL: 185.929\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.31026029586792\n",
      "Epoch: 455\n",
      "\tTrain Loss: 5.310 | Train PPL: 202.403\n",
      "\tVal Loss: 5.224 |  Val PPL: 185.716\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.309506893157959\n",
      "Epoch: 456\n",
      "\tTrain Loss: 5.310 | Train PPL: 202.250\n",
      "\tVal Loss: 5.223 |  Val PPL: 185.559\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.299350738525391\n",
      "Epoch: 457\n",
      "\tTrain Loss: 5.299 | Train PPL: 200.207\n",
      "\tVal Loss: 5.222 |  Val PPL: 185.329\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.3012800216674805\n",
      "Epoch: 458\n",
      "\tTrain Loss: 5.301 | Train PPL: 200.593\n",
      "\tVal Loss: 5.221 |  Val PPL: 185.053\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.295958518981934\n",
      "Epoch: 459\n",
      "\tTrain Loss: 5.296 | Train PPL: 199.529\n",
      "\tVal Loss: 5.219 |  Val PPL: 184.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.279888153076172\n",
      "Epoch: 460\n",
      "\tTrain Loss: 5.280 | Train PPL: 196.348\n",
      "\tVal Loss: 5.217 |  Val PPL: 184.347\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.282407760620117\n",
      "Epoch: 461\n",
      "\tTrain Loss: 5.282 | Train PPL: 196.843\n",
      "\tVal Loss: 5.215 |  Val PPL: 184.056\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.283109188079834\n",
      "Epoch: 462\n",
      "\tTrain Loss: 5.283 | Train PPL: 196.981\n",
      "\tVal Loss: 5.214 |  Val PPL: 183.774\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.2701334953308105\n",
      "Epoch: 463\n",
      "\tTrain Loss: 5.270 | Train PPL: 194.442\n",
      "\tVal Loss: 5.212 |  Val PPL: 183.468\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.294407367706299\n",
      "Epoch: 464\n",
      "\tTrain Loss: 5.294 | Train PPL: 199.220\n",
      "\tVal Loss: 5.210 |  Val PPL: 183.158\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.278996467590332\n",
      "Epoch: 465\n",
      "\tTrain Loss: 5.279 | Train PPL: 196.173\n",
      "\tVal Loss: 5.208 |  Val PPL: 182.800\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.2915239334106445\n",
      "Epoch: 466\n",
      "\tTrain Loss: 5.292 | Train PPL: 198.646\n",
      "\tVal Loss: 5.207 |  Val PPL: 182.517\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.293422698974609\n",
      "Epoch: 467\n",
      "\tTrain Loss: 5.293 | Train PPL: 199.023\n",
      "\tVal Loss: 5.206 |  Val PPL: 182.281\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.275091648101807\n",
      "Epoch: 468\n",
      "\tTrain Loss: 5.275 | Train PPL: 195.408\n",
      "\tVal Loss: 5.204 |  Val PPL: 182.049\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.29788875579834\n",
      "Epoch: 469\n",
      "\tTrain Loss: 5.298 | Train PPL: 199.914\n",
      "\tVal Loss: 5.203 |  Val PPL: 181.814\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.3005690574646\n",
      "Epoch: 470\n",
      "\tTrain Loss: 5.301 | Train PPL: 200.451\n",
      "\tVal Loss: 5.202 |  Val PPL: 181.571\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.274494647979736\n",
      "Epoch: 471\n",
      "\tTrain Loss: 5.274 | Train PPL: 195.292\n",
      "\tVal Loss: 5.200 |  Val PPL: 181.274\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.2907915115356445\n",
      "Epoch: 472\n",
      "\tTrain Loss: 5.291 | Train PPL: 198.500\n",
      "\tVal Loss: 5.199 |  Val PPL: 181.003\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.264382839202881\n",
      "Epoch: 473\n",
      "\tTrain Loss: 5.264 | Train PPL: 193.327\n",
      "\tVal Loss: 5.197 |  Val PPL: 180.791\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.281045913696289\n",
      "Epoch: 474\n",
      "\tTrain Loss: 5.281 | Train PPL: 196.575\n",
      "\tVal Loss: 5.196 |  Val PPL: 180.543\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.275030612945557\n",
      "Epoch: 475\n",
      "\tTrain Loss: 5.275 | Train PPL: 195.396\n",
      "\tVal Loss: 5.194 |  Val PPL: 180.277\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.275739669799805\n",
      "Epoch: 476\n",
      "\tTrain Loss: 5.276 | Train PPL: 195.535\n",
      "\tVal Loss: 5.193 |  Val PPL: 179.984\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.2737812995910645\n",
      "Epoch: 477\n",
      "\tTrain Loss: 5.274 | Train PPL: 195.152\n",
      "\tVal Loss: 5.191 |  Val PPL: 179.618\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.271430015563965\n",
      "Epoch: 478\n",
      "\tTrain Loss: 5.271 | Train PPL: 194.694\n",
      "\tVal Loss: 5.189 |  Val PPL: 179.239\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.2540154457092285\n",
      "Epoch: 479\n",
      "\tTrain Loss: 5.254 | Train PPL: 191.333\n",
      "\tVal Loss: 5.187 |  Val PPL: 178.850\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.278854846954346\n",
      "Epoch: 480\n",
      "\tTrain Loss: 5.279 | Train PPL: 196.145\n",
      "\tVal Loss: 5.184 |  Val PPL: 178.466\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.251797199249268\n",
      "Epoch: 481\n",
      "\tTrain Loss: 5.252 | Train PPL: 190.909\n",
      "\tVal Loss: 5.182 |  Val PPL: 178.073\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.2689433097839355\n",
      "Epoch: 482\n",
      "\tTrain Loss: 5.269 | Train PPL: 194.211\n",
      "\tVal Loss: 5.180 |  Val PPL: 177.708\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.2599406242370605\n",
      "Epoch: 483\n",
      "\tTrain Loss: 5.260 | Train PPL: 192.470\n",
      "\tVal Loss: 5.178 |  Val PPL: 177.376\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.268895149230957\n",
      "Epoch: 484\n",
      "\tTrain Loss: 5.269 | Train PPL: 194.201\n",
      "\tVal Loss: 5.177 |  Val PPL: 177.105\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.263558387756348\n",
      "Epoch: 485\n",
      "\tTrain Loss: 5.264 | Train PPL: 193.168\n",
      "\tVal Loss: 5.175 |  Val PPL: 176.840\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.25714635848999\n",
      "Epoch: 486\n",
      "\tTrain Loss: 5.257 | Train PPL: 191.933\n",
      "\tVal Loss: 5.174 |  Val PPL: 176.539\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.274855613708496\n",
      "Epoch: 487\n",
      "\tTrain Loss: 5.275 | Train PPL: 195.362\n",
      "\tVal Loss: 5.172 |  Val PPL: 176.235\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.258179187774658\n",
      "Epoch: 488\n",
      "\tTrain Loss: 5.258 | Train PPL: 192.131\n",
      "\tVal Loss: 5.170 |  Val PPL: 175.905\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.249176025390625\n",
      "Epoch: 489\n",
      "\tTrain Loss: 5.249 | Train PPL: 190.409\n",
      "\tVal Loss: 5.168 |  Val PPL: 175.598\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.256490230560303\n",
      "Epoch: 490\n",
      "\tTrain Loss: 5.256 | Train PPL: 191.807\n",
      "\tVal Loss: 5.167 |  Val PPL: 175.347\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.246089458465576\n",
      "Epoch: 491\n",
      "\tTrain Loss: 5.246 | Train PPL: 189.823\n",
      "\tVal Loss: 5.165 |  Val PPL: 175.097\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.250491142272949\n",
      "Epoch: 492\n",
      "\tTrain Loss: 5.250 | Train PPL: 190.660\n",
      "\tVal Loss: 5.164 |  Val PPL: 174.925\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.246151447296143\n",
      "Epoch: 493\n",
      "\tTrain Loss: 5.246 | Train PPL: 189.834\n",
      "\tVal Loss: 5.164 |  Val PPL: 174.785\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.253772258758545\n",
      "Epoch: 494\n",
      "\tTrain Loss: 5.254 | Train PPL: 191.286\n",
      "\tVal Loss: 5.162 |  Val PPL: 174.572\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.246156215667725\n",
      "Epoch: 495\n",
      "\tTrain Loss: 5.246 | Train PPL: 189.835\n",
      "\tVal Loss: 5.161 |  Val PPL: 174.289\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.244221210479736\n",
      "Epoch: 496\n",
      "\tTrain Loss: 5.244 | Train PPL: 189.468\n",
      "\tVal Loss: 5.159 |  Val PPL: 174.011\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.235442638397217\n",
      "Epoch: 497\n",
      "\tTrain Loss: 5.235 | Train PPL: 187.812\n",
      "\tVal Loss: 5.157 |  Val PPL: 173.689\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.2561774253845215\n",
      "Epoch: 498\n",
      "\tTrain Loss: 5.256 | Train PPL: 191.747\n",
      "\tVal Loss: 5.155 |  Val PPL: 173.319\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.253560543060303\n",
      "Epoch: 499\n",
      "\tTrain Loss: 5.254 | Train PPL: 191.246\n",
      "\tVal Loss: 5.153 |  Val PPL: 172.876\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.241225242614746\n",
      "Epoch: 500\n",
      "\tTrain Loss: 5.241 | Train PPL: 188.901\n",
      "\tVal Loss: 5.150 |  Val PPL: 172.452\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.245038032531738\n",
      "Epoch: 501\n",
      "\tTrain Loss: 5.245 | Train PPL: 189.623\n",
      "\tVal Loss: 5.148 |  Val PPL: 172.043\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.239123821258545\n",
      "Epoch: 502\n",
      "\tTrain Loss: 5.239 | Train PPL: 188.505\n",
      "\tVal Loss: 5.145 |  Val PPL: 171.626\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.230683326721191\n",
      "Epoch: 503\n",
      "\tTrain Loss: 5.231 | Train PPL: 186.920\n",
      "\tVal Loss: 5.143 |  Val PPL: 171.277\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.226215839385986\n",
      "Epoch: 504\n",
      "\tTrain Loss: 5.226 | Train PPL: 186.087\n",
      "\tVal Loss: 5.142 |  Val PPL: 171.013\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.239016532897949\n",
      "Epoch: 505\n",
      "\tTrain Loss: 5.239 | Train PPL: 188.485\n",
      "\tVal Loss: 5.141 |  Val PPL: 170.806\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.250593662261963\n",
      "Epoch: 506\n",
      "\tTrain Loss: 5.251 | Train PPL: 190.679\n",
      "\tVal Loss: 5.139 |  Val PPL: 170.599\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.246266841888428\n",
      "Epoch: 507\n",
      "\tTrain Loss: 5.246 | Train PPL: 189.856\n",
      "\tVal Loss: 5.138 |  Val PPL: 170.383\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.2359442710876465\n",
      "Epoch: 508\n",
      "\tTrain Loss: 5.236 | Train PPL: 187.906\n",
      "\tVal Loss: 5.137 |  Val PPL: 170.181\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.212290287017822\n",
      "Epoch: 509\n",
      "\tTrain Loss: 5.212 | Train PPL: 183.514\n",
      "\tVal Loss: 5.136 |  Val PPL: 170.004\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.234610080718994\n",
      "Epoch: 510\n",
      "\tTrain Loss: 5.235 | Train PPL: 187.656\n",
      "\tVal Loss: 5.135 |  Val PPL: 169.856\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.213411331176758\n",
      "Epoch: 511\n",
      "\tTrain Loss: 5.213 | Train PPL: 183.720\n",
      "\tVal Loss: 5.134 |  Val PPL: 169.726\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.2364912033081055\n",
      "Epoch: 512\n",
      "\tTrain Loss: 5.236 | Train PPL: 188.009\n",
      "\tVal Loss: 5.133 |  Val PPL: 169.558\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.216885566711426\n",
      "Epoch: 513\n",
      "\tTrain Loss: 5.217 | Train PPL: 184.359\n",
      "\tVal Loss: 5.132 |  Val PPL: 169.330\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.221139430999756\n",
      "Epoch: 514\n",
      "\tTrain Loss: 5.221 | Train PPL: 185.145\n",
      "\tVal Loss: 5.130 |  Val PPL: 169.084\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.207755088806152\n",
      "Epoch: 515\n",
      "\tTrain Loss: 5.208 | Train PPL: 182.683\n",
      "\tVal Loss: 5.129 |  Val PPL: 168.800\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.21467399597168\n",
      "Epoch: 516\n",
      "\tTrain Loss: 5.215 | Train PPL: 183.952\n",
      "\tVal Loss: 5.127 |  Val PPL: 168.556\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.2183756828308105\n",
      "Epoch: 517\n",
      "\tTrain Loss: 5.218 | Train PPL: 184.634\n",
      "\tVal Loss: 5.126 |  Val PPL: 168.375\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.240636348724365\n",
      "Epoch: 518\n",
      "\tTrain Loss: 5.241 | Train PPL: 188.790\n",
      "\tVal Loss: 5.125 |  Val PPL: 168.174\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.2443084716796875\n",
      "Epoch: 519\n",
      "\tTrain Loss: 5.244 | Train PPL: 189.485\n",
      "\tVal Loss: 5.124 |  Val PPL: 167.927\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.230937957763672\n",
      "Epoch: 520\n",
      "\tTrain Loss: 5.231 | Train PPL: 186.968\n",
      "\tVal Loss: 5.122 |  Val PPL: 167.675\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.217483997344971\n",
      "Epoch: 521\n",
      "\tTrain Loss: 5.217 | Train PPL: 184.469\n",
      "\tVal Loss: 5.120 |  Val PPL: 167.366\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.226178169250488\n",
      "Epoch: 522\n",
      "\tTrain Loss: 5.226 | Train PPL: 186.080\n",
      "\tVal Loss: 5.118 |  Val PPL: 167.053\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.1941094398498535\n",
      "Epoch: 523\n",
      "\tTrain Loss: 5.194 | Train PPL: 180.208\n",
      "\tVal Loss: 5.116 |  Val PPL: 166.714\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.209571838378906\n",
      "Epoch: 524\n",
      "\tTrain Loss: 5.210 | Train PPL: 183.016\n",
      "\tVal Loss: 5.114 |  Val PPL: 166.366\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.211941242218018\n",
      "Epoch: 525\n",
      "\tTrain Loss: 5.212 | Train PPL: 183.450\n",
      "\tVal Loss: 5.112 |  Val PPL: 166.007\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.217864036560059\n",
      "Epoch: 526\n",
      "\tTrain Loss: 5.218 | Train PPL: 184.540\n",
      "\tVal Loss: 5.110 |  Val PPL: 165.691\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.214663505554199\n",
      "Epoch: 527\n",
      "\tTrain Loss: 5.215 | Train PPL: 183.950\n",
      "\tVal Loss: 5.108 |  Val PPL: 165.357\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.185233116149902\n",
      "Epoch: 528\n",
      "\tTrain Loss: 5.185 | Train PPL: 178.615\n",
      "\tVal Loss: 5.106 |  Val PPL: 165.070\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.197420120239258\n",
      "Epoch: 529\n",
      "\tTrain Loss: 5.197 | Train PPL: 180.805\n",
      "\tVal Loss: 5.105 |  Val PPL: 164.791\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.189559459686279\n",
      "Epoch: 530\n",
      "\tTrain Loss: 5.190 | Train PPL: 179.390\n",
      "\tVal Loss: 5.103 |  Val PPL: 164.524\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.201505661010742\n",
      "Epoch: 531\n",
      "\tTrain Loss: 5.202 | Train PPL: 181.545\n",
      "\tVal Loss: 5.102 |  Val PPL: 164.272\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.190521717071533\n",
      "Epoch: 532\n",
      "\tTrain Loss: 5.191 | Train PPL: 179.562\n",
      "\tVal Loss: 5.100 |  Val PPL: 163.955\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.226409435272217\n",
      "Epoch: 533\n",
      "\tTrain Loss: 5.226 | Train PPL: 186.123\n",
      "\tVal Loss: 5.098 |  Val PPL: 163.623\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.185942649841309\n",
      "Epoch: 534\n",
      "\tTrain Loss: 5.186 | Train PPL: 178.742\n",
      "\tVal Loss: 5.096 |  Val PPL: 163.331\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.189655303955078\n",
      "Epoch: 535\n",
      "\tTrain Loss: 5.190 | Train PPL: 179.407\n",
      "\tVal Loss: 5.094 |  Val PPL: 163.062\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.206979751586914\n",
      "Epoch: 536\n",
      "\tTrain Loss: 5.207 | Train PPL: 182.542\n",
      "\tVal Loss: 5.092 |  Val PPL: 162.793\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.189616680145264\n",
      "Epoch: 537\n",
      "\tTrain Loss: 5.190 | Train PPL: 179.400\n",
      "\tVal Loss: 5.091 |  Val PPL: 162.607\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.2013325691223145\n",
      "Epoch: 538\n",
      "\tTrain Loss: 5.201 | Train PPL: 181.514\n",
      "\tVal Loss: 5.090 |  Val PPL: 162.449\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.21238899230957\n",
      "Epoch: 539\n",
      "\tTrain Loss: 5.212 | Train PPL: 183.532\n",
      "\tVal Loss: 5.090 |  Val PPL: 162.360\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.2006378173828125\n",
      "Epoch: 540\n",
      "\tTrain Loss: 5.201 | Train PPL: 181.388\n",
      "\tVal Loss: 5.089 |  Val PPL: 162.255\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.197134494781494\n",
      "Epoch: 541\n",
      "\tTrain Loss: 5.197 | Train PPL: 180.754\n",
      "\tVal Loss: 5.088 |  Val PPL: 162.049\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.179687976837158\n",
      "Epoch: 542\n",
      "\tTrain Loss: 5.180 | Train PPL: 177.627\n",
      "\tVal Loss: 5.087 |  Val PPL: 161.824\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.210972309112549\n",
      "Epoch: 543\n",
      "\tTrain Loss: 5.211 | Train PPL: 183.272\n",
      "\tVal Loss: 5.084 |  Val PPL: 161.494\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.184830665588379\n",
      "Epoch: 544\n",
      "\tTrain Loss: 5.185 | Train PPL: 178.543\n",
      "\tVal Loss: 5.083 |  Val PPL: 161.213\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.191900730133057\n",
      "Epoch: 545\n",
      "\tTrain Loss: 5.192 | Train PPL: 179.810\n",
      "\tVal Loss: 5.081 |  Val PPL: 160.893\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.172494411468506\n",
      "Epoch: 546\n",
      "\tTrain Loss: 5.172 | Train PPL: 176.354\n",
      "\tVal Loss: 5.079 |  Val PPL: 160.605\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.186993598937988\n",
      "Epoch: 547\n",
      "\tTrain Loss: 5.187 | Train PPL: 178.930\n",
      "\tVal Loss: 5.077 |  Val PPL: 160.276\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.1798996925354\n",
      "Epoch: 548\n",
      "\tTrain Loss: 5.180 | Train PPL: 177.665\n",
      "\tVal Loss: 5.075 |  Val PPL: 159.974\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.1777544021606445\n",
      "Epoch: 549\n",
      "\tTrain Loss: 5.178 | Train PPL: 177.284\n",
      "\tVal Loss: 5.073 |  Val PPL: 159.672\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.1694865226745605\n",
      "Epoch: 550\n",
      "\tTrain Loss: 5.169 | Train PPL: 175.825\n",
      "\tVal Loss: 5.071 |  Val PPL: 159.343\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.165027618408203\n",
      "Epoch: 551\n",
      "\tTrain Loss: 5.165 | Train PPL: 175.042\n",
      "\tVal Loss: 5.069 |  Val PPL: 159.014\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.16365385055542\n",
      "Epoch: 552\n",
      "\tTrain Loss: 5.164 | Train PPL: 174.802\n",
      "\tVal Loss: 5.067 |  Val PPL: 158.652\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.170359134674072\n",
      "Epoch: 553\n",
      "\tTrain Loss: 5.170 | Train PPL: 175.978\n",
      "\tVal Loss: 5.064 |  Val PPL: 158.250\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.17276668548584\n",
      "Epoch: 554\n",
      "\tTrain Loss: 5.173 | Train PPL: 176.402\n",
      "\tVal Loss: 5.061 |  Val PPL: 157.814\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.170605182647705\n",
      "Epoch: 555\n",
      "\tTrain Loss: 5.171 | Train PPL: 176.021\n",
      "\tVal Loss: 5.059 |  Val PPL: 157.361\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.17959451675415\n",
      "Epoch: 556\n",
      "\tTrain Loss: 5.180 | Train PPL: 177.611\n",
      "\tVal Loss: 5.056 |  Val PPL: 157.005\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.163578987121582\n",
      "Epoch: 557\n",
      "\tTrain Loss: 5.164 | Train PPL: 174.789\n",
      "\tVal Loss: 5.054 |  Val PPL: 156.572\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.165402412414551\n",
      "Epoch: 558\n",
      "\tTrain Loss: 5.165 | Train PPL: 175.108\n",
      "\tVal Loss: 5.051 |  Val PPL: 156.142\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.166832447052002\n",
      "Epoch: 559\n",
      "\tTrain Loss: 5.167 | Train PPL: 175.358\n",
      "\tVal Loss: 5.048 |  Val PPL: 155.725\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.155200481414795\n",
      "Epoch: 560\n",
      "\tTrain Loss: 5.155 | Train PPL: 173.331\n",
      "\tVal Loss: 5.046 |  Val PPL: 155.364\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.176570892333984\n",
      "Epoch: 561\n",
      "\tTrain Loss: 5.177 | Train PPL: 177.075\n",
      "\tVal Loss: 5.043 |  Val PPL: 155.003\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.1617913246154785\n",
      "Epoch: 562\n",
      "\tTrain Loss: 5.162 | Train PPL: 174.477\n",
      "\tVal Loss: 5.041 |  Val PPL: 154.690\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.148750305175781\n",
      "Epoch: 563\n",
      "\tTrain Loss: 5.149 | Train PPL: 172.216\n",
      "\tVal Loss: 5.040 |  Val PPL: 154.437\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.154243469238281\n",
      "Epoch: 564\n",
      "\tTrain Loss: 5.154 | Train PPL: 173.165\n",
      "\tVal Loss: 5.039 |  Val PPL: 154.305\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.15602445602417\n",
      "Epoch: 565\n",
      "\tTrain Loss: 5.156 | Train PPL: 173.473\n",
      "\tVal Loss: 5.039 |  Val PPL: 154.252\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.1598801612854\n",
      "Epoch: 566\n",
      "\tTrain Loss: 5.160 | Train PPL: 174.144\n",
      "\tVal Loss: 5.038 |  Val PPL: 154.221\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.175234317779541\n",
      "Epoch: 567\n",
      "\tTrain Loss: 5.175 | Train PPL: 176.838\n",
      "\tVal Loss: 5.038 |  Val PPL: 154.150\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.125878810882568\n",
      "Epoch: 568\n",
      "\tTrain Loss: 5.126 | Train PPL: 168.322\n",
      "\tVal Loss: 5.037 |  Val PPL: 153.954\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.146548748016357\n",
      "Epoch: 569\n",
      "\tTrain Loss: 5.147 | Train PPL: 171.837\n",
      "\tVal Loss: 5.036 |  Val PPL: 153.789\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.153301239013672\n",
      "Epoch: 570\n",
      "\tTrain Loss: 5.153 | Train PPL: 173.002\n",
      "\tVal Loss: 5.034 |  Val PPL: 153.541\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.147447109222412\n",
      "Epoch: 571\n",
      "\tTrain Loss: 5.147 | Train PPL: 171.992\n",
      "\tVal Loss: 5.032 |  Val PPL: 153.270\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.165772914886475\n",
      "Epoch: 572\n",
      "\tTrain Loss: 5.166 | Train PPL: 175.173\n",
      "\tVal Loss: 5.030 |  Val PPL: 152.926\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.120877265930176\n",
      "Epoch: 573\n",
      "\tTrain Loss: 5.121 | Train PPL: 167.482\n",
      "\tVal Loss: 5.027 |  Val PPL: 152.524\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.154178619384766\n",
      "Epoch: 574\n",
      "\tTrain Loss: 5.154 | Train PPL: 173.154\n",
      "\tVal Loss: 5.025 |  Val PPL: 152.173\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.161358833312988\n",
      "Epoch: 575\n",
      "\tTrain Loss: 5.161 | Train PPL: 174.401\n",
      "\tVal Loss: 5.023 |  Val PPL: 151.849\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.148883819580078\n",
      "Epoch: 576\n",
      "\tTrain Loss: 5.149 | Train PPL: 172.239\n",
      "\tVal Loss: 5.021 |  Val PPL: 151.628\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.139052391052246\n",
      "Epoch: 577\n",
      "\tTrain Loss: 5.139 | Train PPL: 170.554\n",
      "\tVal Loss: 5.021 |  Val PPL: 151.519\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.136994361877441\n",
      "Epoch: 578\n",
      "\tTrain Loss: 5.137 | Train PPL: 170.203\n",
      "\tVal Loss: 5.020 |  Val PPL: 151.463\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.134833812713623\n",
      "Epoch: 579\n",
      "\tTrain Loss: 5.135 | Train PPL: 169.836\n",
      "\tVal Loss: 5.020 |  Val PPL: 151.420\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.136207580566406\n",
      "Epoch: 580\n",
      "\tTrain Loss: 5.136 | Train PPL: 170.070\n",
      "\tVal Loss: 5.019 |  Val PPL: 151.282\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.138993263244629\n",
      "Epoch: 581\n",
      "\tTrain Loss: 5.139 | Train PPL: 170.544\n",
      "\tVal Loss: 5.017 |  Val PPL: 150.979\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.145946979522705\n",
      "Epoch: 582\n",
      "\tTrain Loss: 5.146 | Train PPL: 171.734\n",
      "\tVal Loss: 5.015 |  Val PPL: 150.715\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.115852355957031\n",
      "Epoch: 583\n",
      "\tTrain Loss: 5.116 | Train PPL: 166.643\n",
      "\tVal Loss: 5.014 |  Val PPL: 150.470\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.13186502456665\n",
      "Epoch: 584\n",
      "\tTrain Loss: 5.132 | Train PPL: 169.333\n",
      "\tVal Loss: 5.012 |  Val PPL: 150.244\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.135497570037842\n",
      "Epoch: 585\n",
      "\tTrain Loss: 5.135 | Train PPL: 169.949\n",
      "\tVal Loss: 5.010 |  Val PPL: 149.979\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.120896816253662\n",
      "Epoch: 586\n",
      "\tTrain Loss: 5.121 | Train PPL: 167.486\n",
      "\tVal Loss: 5.008 |  Val PPL: 149.669\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.106138706207275\n",
      "Epoch: 587\n",
      "\tTrain Loss: 5.106 | Train PPL: 165.032\n",
      "\tVal Loss: 5.006 |  Val PPL: 149.272\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.1486406326293945\n",
      "Epoch: 588\n",
      "\tTrain Loss: 5.149 | Train PPL: 172.197\n",
      "\tVal Loss: 5.003 |  Val PPL: 148.840\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.118814468383789\n",
      "Epoch: 589\n",
      "\tTrain Loss: 5.119 | Train PPL: 167.137\n",
      "\tVal Loss: 5.000 |  Val PPL: 148.439\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.120490550994873\n",
      "Epoch: 590\n",
      "\tTrain Loss: 5.120 | Train PPL: 167.417\n",
      "\tVal Loss: 4.998 |  Val PPL: 148.137\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.111213684082031\n",
      "Epoch: 591\n",
      "\tTrain Loss: 5.111 | Train PPL: 165.872\n",
      "\tVal Loss: 4.997 |  Val PPL: 147.983\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.121363639831543\n",
      "Epoch: 592\n",
      "\tTrain Loss: 5.121 | Train PPL: 167.564\n",
      "\tVal Loss: 4.996 |  Val PPL: 147.827\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.129574298858643\n",
      "Epoch: 593\n",
      "\tTrain Loss: 5.130 | Train PPL: 168.945\n",
      "\tVal Loss: 4.995 |  Val PPL: 147.688\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.125918865203857\n",
      "Epoch: 594\n",
      "\tTrain Loss: 5.126 | Train PPL: 168.329\n",
      "\tVal Loss: 4.994 |  Val PPL: 147.493\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.120353698730469\n",
      "Epoch: 595\n",
      "\tTrain Loss: 5.120 | Train PPL: 167.395\n",
      "\tVal Loss: 4.992 |  Val PPL: 147.285\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.086887836456299\n",
      "Epoch: 596\n",
      "\tTrain Loss: 5.087 | Train PPL: 161.885\n",
      "\tVal Loss: 4.992 |  Val PPL: 147.210\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.115411758422852\n",
      "Epoch: 597\n",
      "\tTrain Loss: 5.115 | Train PPL: 166.569\n",
      "\tVal Loss: 4.991 |  Val PPL: 147.109\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.116170883178711\n",
      "Epoch: 598\n",
      "\tTrain Loss: 5.116 | Train PPL: 166.696\n",
      "\tVal Loss: 4.990 |  Val PPL: 146.944\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.123859405517578\n",
      "Epoch: 599\n",
      "\tTrain Loss: 5.124 | Train PPL: 167.982\n",
      "\tVal Loss: 4.989 |  Val PPL: 146.837\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.098602294921875\n",
      "Epoch: 600\n",
      "\tTrain Loss: 5.099 | Train PPL: 163.793\n",
      "\tVal Loss: 4.989 |  Val PPL: 146.751\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.113004684448242\n",
      "Epoch: 601\n",
      "\tTrain Loss: 5.113 | Train PPL: 166.169\n",
      "\tVal Loss: 4.988 |  Val PPL: 146.625\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.111539363861084\n",
      "Epoch: 602\n",
      "\tTrain Loss: 5.112 | Train PPL: 165.926\n",
      "\tVal Loss: 4.986 |  Val PPL: 146.405\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.093311309814453\n",
      "Epoch: 603\n",
      "\tTrain Loss: 5.093 | Train PPL: 162.928\n",
      "\tVal Loss: 4.985 |  Val PPL: 146.133\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.112597465515137\n",
      "Epoch: 604\n",
      "\tTrain Loss: 5.113 | Train PPL: 166.101\n",
      "\tVal Loss: 4.982 |  Val PPL: 145.797\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.080406665802002\n",
      "Epoch: 605\n",
      "\tTrain Loss: 5.080 | Train PPL: 160.839\n",
      "\tVal Loss: 4.980 |  Val PPL: 145.449\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.082353115081787\n",
      "Epoch: 606\n",
      "\tTrain Loss: 5.082 | Train PPL: 161.153\n",
      "\tVal Loss: 4.977 |  Val PPL: 145.042\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.0991010665893555\n",
      "Epoch: 607\n",
      "\tTrain Loss: 5.099 | Train PPL: 163.875\n",
      "\tVal Loss: 4.974 |  Val PPL: 144.659\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.117898464202881\n",
      "Epoch: 608\n",
      "\tTrain Loss: 5.118 | Train PPL: 166.984\n",
      "\tVal Loss: 4.972 |  Val PPL: 144.334\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.10087251663208\n",
      "Epoch: 609\n",
      "\tTrain Loss: 5.101 | Train PPL: 164.165\n",
      "\tVal Loss: 4.971 |  Val PPL: 144.123\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.091916084289551\n",
      "Epoch: 610\n",
      "\tTrain Loss: 5.092 | Train PPL: 162.701\n",
      "\tVal Loss: 4.970 |  Val PPL: 143.970\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.0802388191223145\n",
      "Epoch: 611\n",
      "\tTrain Loss: 5.080 | Train PPL: 160.812\n",
      "\tVal Loss: 4.969 |  Val PPL: 143.834\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.095046043395996\n",
      "Epoch: 612\n",
      "\tTrain Loss: 5.095 | Train PPL: 163.211\n",
      "\tVal Loss: 4.968 |  Val PPL: 143.679\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.098152160644531\n",
      "Epoch: 613\n",
      "\tTrain Loss: 5.098 | Train PPL: 163.719\n",
      "\tVal Loss: 4.966 |  Val PPL: 143.497\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.085770606994629\n",
      "Epoch: 614\n",
      "\tTrain Loss: 5.086 | Train PPL: 161.705\n",
      "\tVal Loss: 4.964 |  Val PPL: 143.208\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.102303981781006\n",
      "Epoch: 615\n",
      "\tTrain Loss: 5.102 | Train PPL: 164.400\n",
      "\tVal Loss: 4.962 |  Val PPL: 142.933\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.083039283752441\n",
      "Epoch: 616\n",
      "\tTrain Loss: 5.083 | Train PPL: 161.263\n",
      "\tVal Loss: 4.960 |  Val PPL: 142.653\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.087619304656982\n",
      "Epoch: 617\n",
      "\tTrain Loss: 5.088 | Train PPL: 162.004\n",
      "\tVal Loss: 4.958 |  Val PPL: 142.290\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.074331283569336\n",
      "Epoch: 618\n",
      "\tTrain Loss: 5.074 | Train PPL: 159.865\n",
      "\tVal Loss: 4.956 |  Val PPL: 141.969\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.077281475067139\n",
      "Epoch: 619\n",
      "\tTrain Loss: 5.077 | Train PPL: 160.338\n",
      "\tVal Loss: 4.953 |  Val PPL: 141.637\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.057556629180908\n",
      "Epoch: 620\n",
      "\tTrain Loss: 5.058 | Train PPL: 157.206\n",
      "\tVal Loss: 4.952 |  Val PPL: 141.410\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.0665998458862305\n",
      "Epoch: 621\n",
      "\tTrain Loss: 5.067 | Train PPL: 158.634\n",
      "\tVal Loss: 4.950 |  Val PPL: 141.204\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.090701580047607\n",
      "Epoch: 622\n",
      "\tTrain Loss: 5.091 | Train PPL: 162.504\n",
      "\tVal Loss: 4.950 |  Val PPL: 141.126\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.086778163909912\n",
      "Epoch: 623\n",
      "\tTrain Loss: 5.087 | Train PPL: 161.868\n",
      "\tVal Loss: 4.949 |  Val PPL: 141.025\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.089169502258301\n",
      "Epoch: 624\n",
      "\tTrain Loss: 5.089 | Train PPL: 162.255\n",
      "\tVal Loss: 4.948 |  Val PPL: 140.847\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.091103553771973\n",
      "Epoch: 625\n",
      "\tTrain Loss: 5.091 | Train PPL: 162.569\n",
      "\tVal Loss: 4.946 |  Val PPL: 140.552\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.060389995574951\n",
      "Epoch: 626\n",
      "\tTrain Loss: 5.060 | Train PPL: 157.652\n",
      "\tVal Loss: 4.943 |  Val PPL: 140.244\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.070098876953125\n",
      "Epoch: 627\n",
      "\tTrain Loss: 5.070 | Train PPL: 159.190\n",
      "\tVal Loss: 4.941 |  Val PPL: 139.950\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.053597450256348\n",
      "Epoch: 628\n",
      "\tTrain Loss: 5.054 | Train PPL: 156.585\n",
      "\tVal Loss: 4.939 |  Val PPL: 139.656\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.06648588180542\n",
      "Epoch: 629\n",
      "\tTrain Loss: 5.066 | Train PPL: 158.616\n",
      "\tVal Loss: 4.937 |  Val PPL: 139.404\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.053689956665039\n",
      "Epoch: 630\n",
      "\tTrain Loss: 5.054 | Train PPL: 156.599\n",
      "\tVal Loss: 4.936 |  Val PPL: 139.148\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.059683799743652\n",
      "Epoch: 631\n",
      "\tTrain Loss: 5.060 | Train PPL: 157.541\n",
      "\tVal Loss: 4.934 |  Val PPL: 138.903\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.040555477142334\n",
      "Epoch: 632\n",
      "\tTrain Loss: 5.041 | Train PPL: 154.556\n",
      "\tVal Loss: 4.931 |  Val PPL: 138.580\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.064661502838135\n",
      "Epoch: 633\n",
      "\tTrain Loss: 5.065 | Train PPL: 158.327\n",
      "\tVal Loss: 4.929 |  Val PPL: 138.241\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.087461948394775\n",
      "Epoch: 634\n",
      "\tTrain Loss: 5.087 | Train PPL: 161.978\n",
      "\tVal Loss: 4.927 |  Val PPL: 137.898\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.046014308929443\n",
      "Epoch: 635\n",
      "\tTrain Loss: 5.046 | Train PPL: 155.402\n",
      "\tVal Loss: 4.924 |  Val PPL: 137.539\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.0679850578308105\n",
      "Epoch: 636\n",
      "\tTrain Loss: 5.068 | Train PPL: 158.854\n",
      "\tVal Loss: 4.921 |  Val PPL: 137.158\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.071670055389404\n",
      "Epoch: 637\n",
      "\tTrain Loss: 5.072 | Train PPL: 159.440\n",
      "\tVal Loss: 4.919 |  Val PPL: 136.850\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.058489799499512\n",
      "Epoch: 638\n",
      "\tTrain Loss: 5.058 | Train PPL: 157.353\n",
      "\tVal Loss: 4.918 |  Val PPL: 136.673\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.052831172943115\n",
      "Epoch: 639\n",
      "\tTrain Loss: 5.053 | Train PPL: 156.465\n",
      "\tVal Loss: 4.917 |  Val PPL: 136.634\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.023228168487549\n",
      "Epoch: 640\n",
      "\tTrain Loss: 5.023 | Train PPL: 151.901\n",
      "\tVal Loss: 4.917 |  Val PPL: 136.651\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.04783296585083\n",
      "Epoch: 641\n",
      "\tTrain Loss: 5.048 | Train PPL: 155.685\n",
      "\tVal Loss: 4.918 |  Val PPL: 136.717\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.046020984649658\n",
      "Epoch: 642\n",
      "\tTrain Loss: 5.046 | Train PPL: 155.403\n",
      "\tVal Loss: 4.918 |  Val PPL: 136.772\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.073665618896484\n",
      "Epoch: 643\n",
      "\tTrain Loss: 5.074 | Train PPL: 159.759\n",
      "\tVal Loss: 4.918 |  Val PPL: 136.790\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.056084156036377\n",
      "Epoch: 644\n",
      "\tTrain Loss: 5.056 | Train PPL: 156.975\n",
      "\tVal Loss: 4.918 |  Val PPL: 136.727\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.0589118003845215\n",
      "Epoch: 645\n",
      "\tTrain Loss: 5.059 | Train PPL: 157.419\n",
      "\tVal Loss: 4.917 |  Val PPL: 136.645\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.032393455505371\n",
      "Epoch: 646\n",
      "\tTrain Loss: 5.032 | Train PPL: 153.299\n",
      "\tVal Loss: 4.916 |  Val PPL: 136.511\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.036691188812256\n",
      "Epoch: 647\n",
      "\tTrain Loss: 5.037 | Train PPL: 153.960\n",
      "\tVal Loss: 4.915 |  Val PPL: 136.299\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.043389797210693\n",
      "Epoch: 648\n",
      "\tTrain Loss: 5.043 | Train PPL: 154.995\n",
      "\tVal Loss: 4.913 |  Val PPL: 136.035\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.042614459991455\n",
      "Epoch: 649\n",
      "\tTrain Loss: 5.043 | Train PPL: 154.874\n",
      "\tVal Loss: 4.910 |  Val PPL: 135.686\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.016540050506592\n",
      "Epoch: 650\n",
      "\tTrain Loss: 5.017 | Train PPL: 150.888\n",
      "\tVal Loss: 4.907 |  Val PPL: 135.224\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.014387130737305\n",
      "Epoch: 651\n",
      "\tTrain Loss: 5.014 | Train PPL: 150.564\n",
      "\tVal Loss: 4.903 |  Val PPL: 134.660\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.0354323387146\n",
      "Epoch: 652\n",
      "\tTrain Loss: 5.035 | Train PPL: 153.766\n",
      "\tVal Loss: 4.899 |  Val PPL: 134.136\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.029914855957031\n",
      "Epoch: 653\n",
      "\tTrain Loss: 5.030 | Train PPL: 152.920\n",
      "\tVal Loss: 4.896 |  Val PPL: 133.720\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.043021202087402\n",
      "Epoch: 654\n",
      "\tTrain Loss: 5.043 | Train PPL: 154.937\n",
      "\tVal Loss: 4.893 |  Val PPL: 133.389\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.035576343536377\n",
      "Epoch: 655\n",
      "\tTrain Loss: 5.036 | Train PPL: 153.788\n",
      "\tVal Loss: 4.892 |  Val PPL: 133.181\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.0421624183654785\n",
      "Epoch: 656\n",
      "\tTrain Loss: 5.042 | Train PPL: 154.804\n",
      "\tVal Loss: 4.891 |  Val PPL: 133.022\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.0005998611450195\n",
      "Epoch: 657\n",
      "\tTrain Loss: 5.001 | Train PPL: 148.502\n",
      "\tVal Loss: 4.890 |  Val PPL: 132.894\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.038790702819824\n",
      "Epoch: 658\n",
      "\tTrain Loss: 5.039 | Train PPL: 154.283\n",
      "\tVal Loss: 4.888 |  Val PPL: 132.752\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.025139331817627\n",
      "Epoch: 659\n",
      "\tTrain Loss: 5.025 | Train PPL: 152.191\n",
      "\tVal Loss: 4.888 |  Val PPL: 132.651\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.022751331329346\n",
      "Epoch: 660\n",
      "\tTrain Loss: 5.023 | Train PPL: 151.828\n",
      "\tVal Loss: 4.887 |  Val PPL: 132.616\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.997736930847168\n",
      "Epoch: 661\n",
      "\tTrain Loss: 4.998 | Train PPL: 148.078\n",
      "\tVal Loss: 4.887 |  Val PPL: 132.586\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.032468795776367\n",
      "Epoch: 662\n",
      "\tTrain Loss: 5.032 | Train PPL: 153.311\n",
      "\tVal Loss: 4.886 |  Val PPL: 132.480\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.010648250579834\n",
      "Epoch: 663\n",
      "\tTrain Loss: 5.011 | Train PPL: 150.002\n",
      "\tVal Loss: 4.885 |  Val PPL: 132.279\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.027970314025879\n",
      "Epoch: 664\n",
      "\tTrain Loss: 5.028 | Train PPL: 152.623\n",
      "\tVal Loss: 4.883 |  Val PPL: 132.077\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.0075788497924805\n",
      "Epoch: 665\n",
      "\tTrain Loss: 5.008 | Train PPL: 149.542\n",
      "\tVal Loss: 4.882 |  Val PPL: 131.867\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.0274834632873535\n",
      "Epoch: 666\n",
      "\tTrain Loss: 5.027 | Train PPL: 152.549\n",
      "\tVal Loss: 4.880 |  Val PPL: 131.644\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.9889020919799805\n",
      "Epoch: 667\n",
      "\tTrain Loss: 4.989 | Train PPL: 146.775\n",
      "\tVal Loss: 4.879 |  Val PPL: 131.511\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.019533634185791\n",
      "Epoch: 668\n",
      "\tTrain Loss: 5.020 | Train PPL: 151.341\n",
      "\tVal Loss: 4.878 |  Val PPL: 131.312\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.002366065979004\n",
      "Epoch: 669\n",
      "\tTrain Loss: 5.002 | Train PPL: 148.765\n",
      "\tVal Loss: 4.876 |  Val PPL: 131.142\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.017688274383545\n",
      "Epoch: 670\n",
      "\tTrain Loss: 5.018 | Train PPL: 151.062\n",
      "\tVal Loss: 4.875 |  Val PPL: 130.938\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.006646156311035\n",
      "Epoch: 671\n",
      "\tTrain Loss: 5.007 | Train PPL: 149.403\n",
      "\tVal Loss: 4.873 |  Val PPL: 130.703\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.984801769256592\n",
      "Epoch: 672\n",
      "\tTrain Loss: 4.985 | Train PPL: 146.175\n",
      "\tVal Loss: 4.871 |  Val PPL: 130.497\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.988110542297363\n",
      "Epoch: 673\n",
      "\tTrain Loss: 4.988 | Train PPL: 146.659\n",
      "\tVal Loss: 4.870 |  Val PPL: 130.355\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.00397253036499\n",
      "Epoch: 674\n",
      "\tTrain Loss: 5.004 | Train PPL: 149.004\n",
      "\tVal Loss: 4.868 |  Val PPL: 130.044\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.996044158935547\n",
      "Epoch: 675\n",
      "\tTrain Loss: 4.996 | Train PPL: 147.827\n",
      "\tVal Loss: 4.865 |  Val PPL: 129.691\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.001662731170654\n",
      "Epoch: 676\n",
      "\tTrain Loss: 5.002 | Train PPL: 148.660\n",
      "\tVal Loss: 4.863 |  Val PPL: 129.356\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.976659297943115\n",
      "Epoch: 677\n",
      "\tTrain Loss: 4.977 | Train PPL: 144.989\n",
      "\tVal Loss: 4.860 |  Val PPL: 128.968\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.001331329345703\n",
      "Epoch: 678\n",
      "\tTrain Loss: 5.001 | Train PPL: 148.611\n",
      "\tVal Loss: 4.857 |  Val PPL: 128.698\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.001286506652832\n",
      "Epoch: 679\n",
      "\tTrain Loss: 5.001 | Train PPL: 148.604\n",
      "\tVal Loss: 4.855 |  Val PPL: 128.347\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.001168727874756\n",
      "Epoch: 680\n",
      "\tTrain Loss: 5.001 | Train PPL: 148.587\n",
      "\tVal Loss: 4.852 |  Val PPL: 127.981\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.981166362762451\n",
      "Epoch: 681\n",
      "\tTrain Loss: 4.981 | Train PPL: 145.644\n",
      "\tVal Loss: 4.849 |  Val PPL: 127.595\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.9998884201049805\n",
      "Epoch: 682\n",
      "\tTrain Loss: 5.000 | Train PPL: 148.397\n",
      "\tVal Loss: 4.846 |  Val PPL: 127.291\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.985706329345703\n",
      "Epoch: 683\n",
      "\tTrain Loss: 4.986 | Train PPL: 146.307\n",
      "\tVal Loss: 4.844 |  Val PPL: 126.984\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.971739768981934\n",
      "Epoch: 684\n",
      "\tTrain Loss: 4.972 | Train PPL: 144.278\n",
      "\tVal Loss: 4.842 |  Val PPL: 126.695\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.9715962409973145\n",
      "Epoch: 685\n",
      "\tTrain Loss: 4.972 | Train PPL: 144.257\n",
      "\tVal Loss: 4.840 |  Val PPL: 126.473\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.9898810386657715\n",
      "Epoch: 686\n",
      "\tTrain Loss: 4.990 | Train PPL: 146.919\n",
      "\tVal Loss: 4.837 |  Val PPL: 126.145\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 5.004866123199463\n",
      "Epoch: 687\n",
      "\tTrain Loss: 5.005 | Train PPL: 149.137\n",
      "\tVal Loss: 4.834 |  Val PPL: 125.757\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.980727672576904\n",
      "Epoch: 688\n",
      "\tTrain Loss: 4.981 | Train PPL: 145.580\n",
      "\tVal Loss: 4.831 |  Val PPL: 125.347\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.98445463180542\n",
      "Epoch: 689\n",
      "\tTrain Loss: 4.984 | Train PPL: 146.124\n",
      "\tVal Loss: 4.828 |  Val PPL: 124.971\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.931788921356201\n",
      "Epoch: 690\n",
      "\tTrain Loss: 4.932 | Train PPL: 138.627\n",
      "\tVal Loss: 4.826 |  Val PPL: 124.655\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.988802909851074\n",
      "Epoch: 691\n",
      "\tTrain Loss: 4.989 | Train PPL: 146.761\n",
      "\tVal Loss: 4.824 |  Val PPL: 124.416\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.962096691131592\n",
      "Epoch: 692\n",
      "\tTrain Loss: 4.962 | Train PPL: 142.893\n",
      "\tVal Loss: 4.822 |  Val PPL: 124.259\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.955712795257568\n",
      "Epoch: 693\n",
      "\tTrain Loss: 4.956 | Train PPL: 141.984\n",
      "\tVal Loss: 4.821 |  Val PPL: 124.042\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.977590084075928\n",
      "Epoch: 694\n",
      "\tTrain Loss: 4.978 | Train PPL: 145.124\n",
      "\tVal Loss: 4.819 |  Val PPL: 123.827\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.9587483406066895\n",
      "Epoch: 695\n",
      "\tTrain Loss: 4.959 | Train PPL: 142.415\n",
      "\tVal Loss: 4.817 |  Val PPL: 123.586\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.95229434967041\n",
      "Epoch: 696\n",
      "\tTrain Loss: 4.952 | Train PPL: 141.499\n",
      "\tVal Loss: 4.815 |  Val PPL: 123.310\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.941556453704834\n",
      "Epoch: 697\n",
      "\tTrain Loss: 4.942 | Train PPL: 139.988\n",
      "\tVal Loss: 4.811 |  Val PPL: 122.883\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.947833061218262\n",
      "Epoch: 698\n",
      "\tTrain Loss: 4.948 | Train PPL: 140.869\n",
      "\tVal Loss: 4.808 |  Val PPL: 122.513\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.944280624389648\n",
      "Epoch: 699\n",
      "\tTrain Loss: 4.944 | Train PPL: 140.370\n",
      "\tVal Loss: 4.805 |  Val PPL: 122.133\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.947545051574707\n",
      "Epoch: 700\n",
      "\tTrain Loss: 4.948 | Train PPL: 140.829\n",
      "\tVal Loss: 4.802 |  Val PPL: 121.794\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.942592144012451\n",
      "Epoch: 701\n",
      "\tTrain Loss: 4.943 | Train PPL: 140.133\n",
      "\tVal Loss: 4.800 |  Val PPL: 121.475\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.949793815612793\n",
      "Epoch: 702\n",
      "\tTrain Loss: 4.950 | Train PPL: 141.146\n",
      "\tVal Loss: 4.797 |  Val PPL: 121.141\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.957164764404297\n",
      "Epoch: 703\n",
      "\tTrain Loss: 4.957 | Train PPL: 142.190\n",
      "\tVal Loss: 4.794 |  Val PPL: 120.764\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.921997547149658\n",
      "Epoch: 704\n",
      "\tTrain Loss: 4.922 | Train PPL: 137.277\n",
      "\tVal Loss: 4.791 |  Val PPL: 120.452\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.942997932434082\n",
      "Epoch: 705\n",
      "\tTrain Loss: 4.943 | Train PPL: 140.190\n",
      "\tVal Loss: 4.788 |  Val PPL: 120.097\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.944380760192871\n",
      "Epoch: 706\n",
      "\tTrain Loss: 4.944 | Train PPL: 140.384\n",
      "\tVal Loss: 4.786 |  Val PPL: 119.787\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.912703037261963\n",
      "Epoch: 707\n",
      "\tTrain Loss: 4.913 | Train PPL: 136.007\n",
      "\tVal Loss: 4.783 |  Val PPL: 119.432\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.914967060089111\n",
      "Epoch: 708\n",
      "\tTrain Loss: 4.915 | Train PPL: 136.315\n",
      "\tVal Loss: 4.780 |  Val PPL: 119.062\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.923610687255859\n",
      "Epoch: 709\n",
      "\tTrain Loss: 4.924 | Train PPL: 137.498\n",
      "\tVal Loss: 4.776 |  Val PPL: 118.677\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.936431407928467\n",
      "Epoch: 710\n",
      "\tTrain Loss: 4.936 | Train PPL: 139.272\n",
      "\tVal Loss: 4.773 |  Val PPL: 118.283\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.917365074157715\n",
      "Epoch: 711\n",
      "\tTrain Loss: 4.917 | Train PPL: 136.642\n",
      "\tVal Loss: 4.770 |  Val PPL: 117.920\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.922784805297852\n",
      "Epoch: 712\n",
      "\tTrain Loss: 4.923 | Train PPL: 137.385\n",
      "\tVal Loss: 4.768 |  Val PPL: 117.719\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.927074432373047\n",
      "Epoch: 713\n",
      "\tTrain Loss: 4.927 | Train PPL: 137.975\n",
      "\tVal Loss: 4.767 |  Val PPL: 117.536\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.912750244140625\n",
      "Epoch: 714\n",
      "\tTrain Loss: 4.913 | Train PPL: 136.013\n",
      "\tVal Loss: 4.765 |  Val PPL: 117.356\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.909470558166504\n",
      "Epoch: 715\n",
      "\tTrain Loss: 4.909 | Train PPL: 135.568\n",
      "\tVal Loss: 4.764 |  Val PPL: 117.172\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.90864896774292\n",
      "Epoch: 716\n",
      "\tTrain Loss: 4.909 | Train PPL: 135.456\n",
      "\tVal Loss: 4.762 |  Val PPL: 117.018\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.919108867645264\n",
      "Epoch: 717\n",
      "\tTrain Loss: 4.919 | Train PPL: 136.881\n",
      "\tVal Loss: 4.761 |  Val PPL: 116.884\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.900210380554199\n",
      "Epoch: 718\n",
      "\tTrain Loss: 4.900 | Train PPL: 134.318\n",
      "\tVal Loss: 4.760 |  Val PPL: 116.712\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.904354095458984\n",
      "Epoch: 719\n",
      "\tTrain Loss: 4.904 | Train PPL: 134.876\n",
      "\tVal Loss: 4.757 |  Val PPL: 116.444\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.9014739990234375\n",
      "Epoch: 720\n",
      "\tTrain Loss: 4.901 | Train PPL: 134.488\n",
      "\tVal Loss: 4.755 |  Val PPL: 116.174\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.8956427574157715\n",
      "Epoch: 721\n",
      "\tTrain Loss: 4.896 | Train PPL: 133.706\n",
      "\tVal Loss: 4.753 |  Val PPL: 115.912\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.903192520141602\n",
      "Epoch: 722\n",
      "\tTrain Loss: 4.903 | Train PPL: 134.719\n",
      "\tVal Loss: 4.751 |  Val PPL: 115.674\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.899905681610107\n",
      "Epoch: 723\n",
      "\tTrain Loss: 4.900 | Train PPL: 134.277\n",
      "\tVal Loss: 4.749 |  Val PPL: 115.451\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.886709690093994\n",
      "Epoch: 724\n",
      "\tTrain Loss: 4.887 | Train PPL: 132.517\n",
      "\tVal Loss: 4.747 |  Val PPL: 115.219\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.881089687347412\n",
      "Epoch: 725\n",
      "\tTrain Loss: 4.881 | Train PPL: 131.774\n",
      "\tVal Loss: 4.745 |  Val PPL: 114.994\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.868720531463623\n",
      "Epoch: 726\n",
      "\tTrain Loss: 4.869 | Train PPL: 130.154\n",
      "\tVal Loss: 4.743 |  Val PPL: 114.728\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.888734817504883\n",
      "Epoch: 727\n",
      "\tTrain Loss: 4.889 | Train PPL: 132.785\n",
      "\tVal Loss: 4.740 |  Val PPL: 114.480\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.873570442199707\n",
      "Epoch: 728\n",
      "\tTrain Loss: 4.874 | Train PPL: 130.787\n",
      "\tVal Loss: 4.738 |  Val PPL: 114.227\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.866908073425293\n",
      "Epoch: 729\n",
      "\tTrain Loss: 4.867 | Train PPL: 129.919\n",
      "\tVal Loss: 4.736 |  Val PPL: 113.999\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.886926651000977\n",
      "Epoch: 730\n",
      "\tTrain Loss: 4.887 | Train PPL: 132.546\n",
      "\tVal Loss: 4.735 |  Val PPL: 113.817\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.889444351196289\n",
      "Epoch: 731\n",
      "\tTrain Loss: 4.889 | Train PPL: 132.880\n",
      "\tVal Loss: 4.733 |  Val PPL: 113.625\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.881350040435791\n",
      "Epoch: 732\n",
      "\tTrain Loss: 4.881 | Train PPL: 131.808\n",
      "\tVal Loss: 4.731 |  Val PPL: 113.418\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.879868507385254\n",
      "Epoch: 733\n",
      "\tTrain Loss: 4.880 | Train PPL: 131.613\n",
      "\tVal Loss: 4.729 |  Val PPL: 113.201\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.877110481262207\n",
      "Epoch: 734\n",
      "\tTrain Loss: 4.877 | Train PPL: 131.251\n",
      "\tVal Loss: 4.728 |  Val PPL: 113.021\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.87354850769043\n",
      "Epoch: 735\n",
      "\tTrain Loss: 4.874 | Train PPL: 130.784\n",
      "\tVal Loss: 4.727 |  Val PPL: 112.911\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.8762736320495605\n",
      "Epoch: 736\n",
      "\tTrain Loss: 4.876 | Train PPL: 131.141\n",
      "\tVal Loss: 4.725 |  Val PPL: 112.718\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.858048439025879\n",
      "Epoch: 737\n",
      "\tTrain Loss: 4.858 | Train PPL: 128.773\n",
      "\tVal Loss: 4.723 |  Val PPL: 112.491\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.860057353973389\n",
      "Epoch: 738\n",
      "\tTrain Loss: 4.860 | Train PPL: 129.032\n",
      "\tVal Loss: 4.721 |  Val PPL: 112.274\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.8821563720703125\n",
      "Epoch: 739\n",
      "\tTrain Loss: 4.882 | Train PPL: 131.915\n",
      "\tVal Loss: 4.720 |  Val PPL: 112.118\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.8739333152771\n",
      "Epoch: 740\n",
      "\tTrain Loss: 4.874 | Train PPL: 130.835\n",
      "\tVal Loss: 4.718 |  Val PPL: 111.956\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.8712873458862305\n",
      "Epoch: 741\n",
      "\tTrain Loss: 4.871 | Train PPL: 130.489\n",
      "\tVal Loss: 4.716 |  Val PPL: 111.704\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.872142791748047\n",
      "Epoch: 742\n",
      "\tTrain Loss: 4.872 | Train PPL: 130.600\n",
      "\tVal Loss: 4.714 |  Val PPL: 111.457\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.8434929847717285\n",
      "Epoch: 743\n",
      "\tTrain Loss: 4.843 | Train PPL: 126.912\n",
      "\tVal Loss: 4.710 |  Val PPL: 111.106\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.866067886352539\n",
      "Epoch: 744\n",
      "\tTrain Loss: 4.866 | Train PPL: 129.809\n",
      "\tVal Loss: 4.707 |  Val PPL: 110.759\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.84019136428833\n",
      "Epoch: 745\n",
      "\tTrain Loss: 4.840 | Train PPL: 126.494\n",
      "\tVal Loss: 4.704 |  Val PPL: 110.366\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.829174518585205\n",
      "Epoch: 746\n",
      "\tTrain Loss: 4.829 | Train PPL: 125.108\n",
      "\tVal Loss: 4.701 |  Val PPL: 110.042\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.837029933929443\n",
      "Epoch: 747\n",
      "\tTrain Loss: 4.837 | Train PPL: 126.094\n",
      "\tVal Loss: 4.699 |  Val PPL: 109.797\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.848153114318848\n",
      "Epoch: 748\n",
      "\tTrain Loss: 4.848 | Train PPL: 127.505\n",
      "\tVal Loss: 4.697 |  Val PPL: 109.625\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.8472700119018555\n",
      "Epoch: 749\n",
      "\tTrain Loss: 4.847 | Train PPL: 127.392\n",
      "\tVal Loss: 4.695 |  Val PPL: 109.433\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.830504894256592\n",
      "Epoch: 750\n",
      "\tTrain Loss: 4.831 | Train PPL: 125.274\n",
      "\tVal Loss: 4.694 |  Val PPL: 109.242\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.838049411773682\n",
      "Epoch: 751\n",
      "\tTrain Loss: 4.838 | Train PPL: 126.223\n",
      "\tVal Loss: 4.692 |  Val PPL: 109.030\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.844171047210693\n",
      "Epoch: 752\n",
      "\tTrain Loss: 4.844 | Train PPL: 126.998\n",
      "\tVal Loss: 4.691 |  Val PPL: 108.961\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.824059009552002\n",
      "Epoch: 753\n",
      "\tTrain Loss: 4.824 | Train PPL: 124.469\n",
      "\tVal Loss: 4.692 |  Val PPL: 109.064\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.813563346862793\n",
      "Epoch: 754\n",
      "\tTrain Loss: 4.814 | Train PPL: 123.170\n",
      "\tVal Loss: 4.691 |  Val PPL: 108.976\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.834057807922363\n",
      "Epoch: 755\n",
      "\tTrain Loss: 4.834 | Train PPL: 125.720\n",
      "\tVal Loss: 4.689 |  Val PPL: 108.781\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.805524826049805\n",
      "Epoch: 756\n",
      "\tTrain Loss: 4.806 | Train PPL: 122.184\n",
      "\tVal Loss: 4.687 |  Val PPL: 108.514\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.813209533691406\n",
      "Epoch: 757\n",
      "\tTrain Loss: 4.813 | Train PPL: 123.126\n",
      "\tVal Loss: 4.684 |  Val PPL: 108.227\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.818034648895264\n",
      "Epoch: 758\n",
      "\tTrain Loss: 4.818 | Train PPL: 123.722\n",
      "\tVal Loss: 4.682 |  Val PPL: 108.029\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.815694332122803\n",
      "Epoch: 759\n",
      "\tTrain Loss: 4.816 | Train PPL: 123.432\n",
      "\tVal Loss: 4.680 |  Val PPL: 107.717\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.812869071960449\n",
      "Epoch: 760\n",
      "\tTrain Loss: 4.813 | Train PPL: 123.084\n",
      "\tVal Loss: 4.677 |  Val PPL: 107.418\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.796438217163086\n",
      "Epoch: 761\n",
      "\tTrain Loss: 4.796 | Train PPL: 121.078\n",
      "\tVal Loss: 4.675 |  Val PPL: 107.225\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.811861991882324\n",
      "Epoch: 762\n",
      "\tTrain Loss: 4.812 | Train PPL: 122.960\n",
      "\tVal Loss: 4.674 |  Val PPL: 107.088\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.803532123565674\n",
      "Epoch: 763\n",
      "\tTrain Loss: 4.804 | Train PPL: 121.940\n",
      "\tVal Loss: 4.675 |  Val PPL: 107.230\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.804561614990234\n",
      "Epoch: 764\n",
      "\tTrain Loss: 4.805 | Train PPL: 122.066\n",
      "\tVal Loss: 4.677 |  Val PPL: 107.399\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.814636707305908\n",
      "Epoch: 765\n",
      "\tTrain Loss: 4.815 | Train PPL: 123.302\n",
      "\tVal Loss: 4.675 |  Val PPL: 107.262\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.789859771728516\n",
      "Epoch: 766\n",
      "\tTrain Loss: 4.790 | Train PPL: 120.285\n",
      "\tVal Loss: 4.671 |  Val PPL: 106.818\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.812591075897217\n",
      "Epoch: 767\n",
      "\tTrain Loss: 4.813 | Train PPL: 123.050\n",
      "\tVal Loss: 4.663 |  Val PPL: 105.986\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.801445484161377\n",
      "Epoch: 768\n",
      "\tTrain Loss: 4.801 | Train PPL: 121.686\n",
      "\tVal Loss: 4.656 |  Val PPL: 105.197\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.795750617980957\n",
      "Epoch: 769\n",
      "\tTrain Loss: 4.796 | Train PPL: 120.995\n",
      "\tVal Loss: 4.651 |  Val PPL: 104.701\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.792983531951904\n",
      "Epoch: 770\n",
      "\tTrain Loss: 4.793 | Train PPL: 120.661\n",
      "\tVal Loss: 4.649 |  Val PPL: 104.505\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.801065444946289\n",
      "Epoch: 771\n",
      "\tTrain Loss: 4.801 | Train PPL: 121.640\n",
      "\tVal Loss: 4.650 |  Val PPL: 104.575\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.756410121917725\n",
      "Epoch: 772\n",
      "\tTrain Loss: 4.756 | Train PPL: 116.328\n",
      "\tVal Loss: 4.653 |  Val PPL: 104.889\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.796659469604492\n",
      "Epoch: 773\n",
      "\tTrain Loss: 4.797 | Train PPL: 121.105\n",
      "\tVal Loss: 4.655 |  Val PPL: 105.095\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.798437118530273\n",
      "Epoch: 774\n",
      "\tTrain Loss: 4.798 | Train PPL: 121.321\n",
      "\tVal Loss: 4.654 |  Val PPL: 105.052\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.8007001876831055\n",
      "Epoch: 775\n",
      "\tTrain Loss: 4.801 | Train PPL: 121.596\n",
      "\tVal Loss: 4.649 |  Val PPL: 104.515\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.792027950286865\n",
      "Epoch: 776\n",
      "\tTrain Loss: 4.792 | Train PPL: 120.546\n",
      "\tVal Loss: 4.642 |  Val PPL: 103.773\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.7999162673950195\n",
      "Epoch: 777\n",
      "\tTrain Loss: 4.800 | Train PPL: 121.500\n",
      "\tVal Loss: 4.637 |  Val PPL: 103.237\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.782510757446289\n",
      "Epoch: 778\n",
      "\tTrain Loss: 4.783 | Train PPL: 119.404\n",
      "\tVal Loss: 4.635 |  Val PPL: 103.021\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.777853965759277\n",
      "Epoch: 779\n",
      "\tTrain Loss: 4.778 | Train PPL: 118.849\n",
      "\tVal Loss: 4.633 |  Val PPL: 102.790\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.765670299530029\n",
      "Epoch: 780\n",
      "\tTrain Loss: 4.766 | Train PPL: 117.410\n",
      "\tVal Loss: 4.632 |  Val PPL: 102.762\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.791927337646484\n",
      "Epoch: 781\n",
      "\tTrain Loss: 4.792 | Train PPL: 120.533\n",
      "\tVal Loss: 4.633 |  Val PPL: 102.821\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.785953044891357\n",
      "Epoch: 782\n",
      "\tTrain Loss: 4.786 | Train PPL: 119.815\n",
      "\tVal Loss: 4.634 |  Val PPL: 102.943\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.7824273109436035\n",
      "Epoch: 783\n",
      "\tTrain Loss: 4.782 | Train PPL: 119.394\n",
      "\tVal Loss: 4.634 |  Val PPL: 102.939\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.782472133636475\n",
      "Epoch: 784\n",
      "\tTrain Loss: 4.782 | Train PPL: 119.399\n",
      "\tVal Loss: 4.628 |  Val PPL: 102.329\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.747506618499756\n",
      "Epoch: 785\n",
      "\tTrain Loss: 4.748 | Train PPL: 115.296\n",
      "\tVal Loss: 4.622 |  Val PPL: 101.706\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.760764122009277\n",
      "Epoch: 786\n",
      "\tTrain Loss: 4.761 | Train PPL: 116.835\n",
      "\tVal Loss: 4.619 |  Val PPL: 101.360\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.760611057281494\n",
      "Epoch: 787\n",
      "\tTrain Loss: 4.761 | Train PPL: 116.817\n",
      "\tVal Loss: 4.618 |  Val PPL: 101.336\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.742588996887207\n",
      "Epoch: 788\n",
      "\tTrain Loss: 4.743 | Train PPL: 114.731\n",
      "\tVal Loss: 4.620 |  Val PPL: 101.517\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.7720513343811035\n",
      "Epoch: 789\n",
      "\tTrain Loss: 4.772 | Train PPL: 118.161\n",
      "\tVal Loss: 4.624 |  Val PPL: 101.862\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.7760467529296875\n",
      "Epoch: 790\n",
      "\tTrain Loss: 4.776 | Train PPL: 118.634\n",
      "\tVal Loss: 4.626 |  Val PPL: 102.070\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.760595321655273\n",
      "Epoch: 791\n",
      "\tTrain Loss: 4.761 | Train PPL: 116.815\n",
      "\tVal Loss: 4.627 |  Val PPL: 102.167\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.7866058349609375\n",
      "Epoch: 792\n",
      "\tTrain Loss: 4.787 | Train PPL: 119.894\n",
      "\tVal Loss: 4.623 |  Val PPL: 101.810\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.751482009887695\n",
      "Epoch: 793\n",
      "\tTrain Loss: 4.751 | Train PPL: 115.756\n",
      "\tVal Loss: 4.614 |  Val PPL: 100.928\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.741279602050781\n",
      "Epoch: 794\n",
      "\tTrain Loss: 4.741 | Train PPL: 114.581\n",
      "\tVal Loss: 4.609 |  Val PPL: 100.343\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.74766206741333\n",
      "Epoch: 795\n",
      "\tTrain Loss: 4.748 | Train PPL: 115.314\n",
      "\tVal Loss: 4.606 |  Val PPL: 100.095\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.740670680999756\n",
      "Epoch: 796\n",
      "\tTrain Loss: 4.741 | Train PPL: 114.511\n",
      "\tVal Loss: 4.606 |  Val PPL: 100.064\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.757953643798828\n",
      "Epoch: 797\n",
      "\tTrain Loss: 4.758 | Train PPL: 116.507\n",
      "\tVal Loss: 4.607 |  Val PPL: 100.147\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.743999481201172\n",
      "Epoch: 798\n",
      "\tTrain Loss: 4.744 | Train PPL: 114.893\n",
      "\tVal Loss: 4.608 |  Val PPL: 100.319\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.752357482910156\n",
      "Epoch: 799\n",
      "\tTrain Loss: 4.752 | Train PPL: 115.857\n",
      "\tVal Loss: 4.602 |  Val PPL:  99.685\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.723828315734863\n",
      "Epoch: 800\n",
      "\tTrain Loss: 4.724 | Train PPL: 112.598\n",
      "\tVal Loss: 4.597 |  Val PPL:  99.182\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.727665901184082\n",
      "Epoch: 801\n",
      "\tTrain Loss: 4.728 | Train PPL: 113.031\n",
      "\tVal Loss: 4.593 |  Val PPL:  98.816\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.721070289611816\n",
      "Epoch: 802\n",
      "\tTrain Loss: 4.721 | Train PPL: 112.288\n",
      "\tVal Loss: 4.592 |  Val PPL:  98.686\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.748326778411865\n",
      "Epoch: 803\n",
      "\tTrain Loss: 4.748 | Train PPL: 115.391\n",
      "\tVal Loss: 4.592 |  Val PPL:  98.697\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.716728687286377\n",
      "Epoch: 804\n",
      "\tTrain Loss: 4.717 | Train PPL: 111.802\n",
      "\tVal Loss: 4.592 |  Val PPL:  98.713\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.767055988311768\n",
      "Epoch: 805\n",
      "\tTrain Loss: 4.767 | Train PPL: 117.573\n",
      "\tVal Loss: 4.592 |  Val PPL:  98.724\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.7318949699401855\n",
      "Epoch: 806\n",
      "\tTrain Loss: 4.732 | Train PPL: 113.510\n",
      "\tVal Loss: 4.591 |  Val PPL:  98.620\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.75094747543335\n",
      "Epoch: 807\n",
      "\tTrain Loss: 4.751 | Train PPL: 115.694\n",
      "\tVal Loss: 4.590 |  Val PPL:  98.519\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.741680145263672\n",
      "Epoch: 808\n",
      "\tTrain Loss: 4.742 | Train PPL: 114.627\n",
      "\tVal Loss: 4.588 |  Val PPL:  98.341\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.714191436767578\n",
      "Epoch: 809\n",
      "\tTrain Loss: 4.714 | Train PPL: 111.519\n",
      "\tVal Loss: 4.586 |  Val PPL:  98.115\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.711623191833496\n",
      "Epoch: 810\n",
      "\tTrain Loss: 4.712 | Train PPL: 111.233\n",
      "\tVal Loss: 4.584 |  Val PPL:  97.890\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.7232537269592285\n",
      "Epoch: 811\n",
      "\tTrain Loss: 4.723 | Train PPL: 112.534\n",
      "\tVal Loss: 4.581 |  Val PPL:  97.567\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.727941513061523\n",
      "Epoch: 812\n",
      "\tTrain Loss: 4.728 | Train PPL: 113.063\n",
      "\tVal Loss: 4.576 |  Val PPL:  97.089\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.703678607940674\n",
      "Epoch: 813\n",
      "\tTrain Loss: 4.704 | Train PPL: 110.352\n",
      "\tVal Loss: 4.570 |  Val PPL:  96.576\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.693831443786621\n",
      "Epoch: 814\n",
      "\tTrain Loss: 4.694 | Train PPL: 109.271\n",
      "\tVal Loss: 4.568 |  Val PPL:  96.368\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.727080821990967\n",
      "Epoch: 815\n",
      "\tTrain Loss: 4.727 | Train PPL: 112.965\n",
      "\tVal Loss: 4.567 |  Val PPL:  96.217\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.69580602645874\n",
      "Epoch: 816\n",
      "\tTrain Loss: 4.696 | Train PPL: 109.487\n",
      "\tVal Loss: 4.565 |  Val PPL:  96.022\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.71990966796875\n",
      "Epoch: 817\n",
      "\tTrain Loss: 4.720 | Train PPL: 112.158\n",
      "\tVal Loss: 4.562 |  Val PPL:  95.805\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.690208435058594\n",
      "Epoch: 818\n",
      "\tTrain Loss: 4.690 | Train PPL: 108.876\n",
      "\tVal Loss: 4.556 |  Val PPL:  95.231\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.728161334991455\n",
      "Epoch: 819\n",
      "\tTrain Loss: 4.728 | Train PPL: 113.087\n",
      "\tVal Loss: 4.551 |  Val PPL:  94.731\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.702584743499756\n",
      "Epoch: 820\n",
      "\tTrain Loss: 4.703 | Train PPL: 110.232\n",
      "\tVal Loss: 4.548 |  Val PPL:  94.478\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.700099468231201\n",
      "Epoch: 821\n",
      "\tTrain Loss: 4.700 | Train PPL: 109.958\n",
      "\tVal Loss: 4.547 |  Val PPL:  94.303\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.689098834991455\n",
      "Epoch: 822\n",
      "\tTrain Loss: 4.689 | Train PPL: 108.755\n",
      "\tVal Loss: 4.548 |  Val PPL:  94.402\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.673762798309326\n",
      "Epoch: 823\n",
      "\tTrain Loss: 4.674 | Train PPL: 107.100\n",
      "\tVal Loss: 4.550 |  Val PPL:  94.656\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.6921706199646\n",
      "Epoch: 824\n",
      "\tTrain Loss: 4.692 | Train PPL: 109.090\n",
      "\tVal Loss: 4.555 |  Val PPL:  95.095\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.715541362762451\n",
      "Epoch: 825\n",
      "\tTrain Loss: 4.716 | Train PPL: 111.669\n",
      "\tVal Loss: 4.558 |  Val PPL:  95.438\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.700859069824219\n",
      "Epoch: 826\n",
      "\tTrain Loss: 4.701 | Train PPL: 110.042\n",
      "\tVal Loss: 4.556 |  Val PPL:  95.228\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.717174530029297\n",
      "Epoch: 827\n",
      "\tTrain Loss: 4.717 | Train PPL: 111.852\n",
      "\tVal Loss: 4.549 |  Val PPL:  94.523\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.686864852905273\n",
      "Epoch: 828\n",
      "\tTrain Loss: 4.687 | Train PPL: 108.512\n",
      "\tVal Loss: 4.542 |  Val PPL:  93.867\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.678287982940674\n",
      "Epoch: 829\n",
      "\tTrain Loss: 4.678 | Train PPL: 107.586\n",
      "\tVal Loss: 4.537 |  Val PPL:  93.380\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.69144344329834\n",
      "Epoch: 830\n",
      "\tTrain Loss: 4.691 | Train PPL: 109.010\n",
      "\tVal Loss: 4.533 |  Val PPL:  93.044\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.684690952301025\n",
      "Epoch: 831\n",
      "\tTrain Loss: 4.685 | Train PPL: 108.277\n",
      "\tVal Loss: 4.533 |  Val PPL:  93.028\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.689191818237305\n",
      "Epoch: 832\n",
      "\tTrain Loss: 4.689 | Train PPL: 108.765\n",
      "\tVal Loss: 4.534 |  Val PPL:  93.166\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.696133613586426\n",
      "Epoch: 833\n",
      "\tTrain Loss: 4.696 | Train PPL: 109.523\n",
      "\tVal Loss: 4.536 |  Val PPL:  93.324\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.69887638092041\n",
      "Epoch: 834\n",
      "\tTrain Loss: 4.699 | Train PPL: 109.824\n",
      "\tVal Loss: 4.533 |  Val PPL:  93.000\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.690097808837891\n",
      "Epoch: 835\n",
      "\tTrain Loss: 4.690 | Train PPL: 108.864\n",
      "\tVal Loss: 4.530 |  Val PPL:  92.734\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.658964157104492\n",
      "Epoch: 836\n",
      "\tTrain Loss: 4.659 | Train PPL: 105.527\n",
      "\tVal Loss: 4.526 |  Val PPL:  92.420\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.675446510314941\n",
      "Epoch: 837\n",
      "\tTrain Loss: 4.675 | Train PPL: 107.280\n",
      "\tVal Loss: 4.523 |  Val PPL:  92.137\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.6907477378845215\n",
      "Epoch: 838\n",
      "\tTrain Loss: 4.691 | Train PPL: 108.935\n",
      "\tVal Loss: 4.521 |  Val PPL:  91.967\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.65352725982666\n",
      "Epoch: 839\n",
      "\tTrain Loss: 4.654 | Train PPL: 104.955\n",
      "\tVal Loss: 4.522 |  Val PPL:  92.060\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.657744884490967\n",
      "Epoch: 840\n",
      "\tTrain Loss: 4.658 | Train PPL: 105.398\n",
      "\tVal Loss: 4.524 |  Val PPL:  92.180\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.677573204040527\n",
      "Epoch: 841\n",
      "\tTrain Loss: 4.678 | Train PPL: 107.509\n",
      "\tVal Loss: 4.524 |  Val PPL:  92.227\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.6753621101379395\n",
      "Epoch: 842\n",
      "\tTrain Loss: 4.675 | Train PPL: 107.271\n",
      "\tVal Loss: 4.521 |  Val PPL:  91.933\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.660302639007568\n",
      "Epoch: 843\n",
      "\tTrain Loss: 4.660 | Train PPL: 105.668\n",
      "\tVal Loss: 4.516 |  Val PPL:  91.463\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.66725492477417\n",
      "Epoch: 844\n",
      "\tTrain Loss: 4.667 | Train PPL: 106.405\n",
      "\tVal Loss: 4.510 |  Val PPL:  90.954\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.636675834655762\n",
      "Epoch: 845\n",
      "\tTrain Loss: 4.637 | Train PPL: 103.201\n",
      "\tVal Loss: 4.506 |  Val PPL:  90.571\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.678358554840088\n",
      "Epoch: 846\n",
      "\tTrain Loss: 4.678 | Train PPL: 107.593\n",
      "\tVal Loss: 4.504 |  Val PPL:  90.369\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.6572041511535645\n",
      "Epoch: 847\n",
      "\tTrain Loss: 4.657 | Train PPL: 105.341\n",
      "\tVal Loss: 4.502 |  Val PPL:  90.178\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.650864124298096\n",
      "Epoch: 848\n",
      "\tTrain Loss: 4.651 | Train PPL: 104.675\n",
      "\tVal Loss: 4.501 |  Val PPL:  90.123\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.669536590576172\n",
      "Epoch: 849\n",
      "\tTrain Loss: 4.670 | Train PPL: 106.648\n",
      "\tVal Loss: 4.500 |  Val PPL:  89.978\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.686655521392822\n",
      "Epoch: 850\n",
      "\tTrain Loss: 4.687 | Train PPL: 108.490\n",
      "\tVal Loss: 4.497 |  Val PPL:  89.725\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.680481433868408\n",
      "Epoch: 851\n",
      "\tTrain Loss: 4.680 | Train PPL: 107.822\n",
      "\tVal Loss: 4.496 |  Val PPL:  89.655\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.646534442901611\n",
      "Epoch: 852\n",
      "\tTrain Loss: 4.647 | Train PPL: 104.223\n",
      "\tVal Loss: 4.496 |  Val PPL:  89.663\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.657929420471191\n",
      "Epoch: 853\n",
      "\tTrain Loss: 4.658 | Train PPL: 105.418\n",
      "\tVal Loss: 4.496 |  Val PPL:  89.615\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.64872407913208\n",
      "Epoch: 854\n",
      "\tTrain Loss: 4.649 | Train PPL: 104.452\n",
      "\tVal Loss: 4.494 |  Val PPL:  89.486\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.667093276977539\n",
      "Epoch: 855\n",
      "\tTrain Loss: 4.667 | Train PPL: 106.388\n",
      "\tVal Loss: 4.492 |  Val PPL:  89.306\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.644837379455566\n",
      "Epoch: 856\n",
      "\tTrain Loss: 4.645 | Train PPL: 104.046\n",
      "\tVal Loss: 4.491 |  Val PPL:  89.168\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.6735100746154785\n",
      "Epoch: 857\n",
      "\tTrain Loss: 4.674 | Train PPL: 107.073\n",
      "\tVal Loss: 4.489 |  Val PPL:  89.005\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.644041061401367\n",
      "Epoch: 858\n",
      "\tTrain Loss: 4.644 | Train PPL: 103.964\n",
      "\tVal Loss: 4.488 |  Val PPL:  88.956\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.625918388366699\n",
      "Epoch: 859\n",
      "\tTrain Loss: 4.626 | Train PPL: 102.096\n",
      "\tVal Loss: 4.488 |  Val PPL:  88.933\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.661610126495361\n",
      "Epoch: 860\n",
      "\tTrain Loss: 4.662 | Train PPL: 105.806\n",
      "\tVal Loss: 4.485 |  Val PPL:  88.658\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.644741535186768\n",
      "Epoch: 861\n",
      "\tTrain Loss: 4.645 | Train PPL: 104.036\n",
      "\tVal Loss: 4.482 |  Val PPL:  88.415\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.645367622375488\n",
      "Epoch: 862\n",
      "\tTrain Loss: 4.645 | Train PPL: 104.102\n",
      "\tVal Loss: 4.477 |  Val PPL:  87.986\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.613413333892822\n",
      "Epoch: 863\n",
      "\tTrain Loss: 4.613 | Train PPL: 100.828\n",
      "\tVal Loss: 4.473 |  Val PPL:  87.635\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.619783878326416\n",
      "Epoch: 864\n",
      "\tTrain Loss: 4.620 | Train PPL: 101.472\n",
      "\tVal Loss: 4.471 |  Val PPL:  87.459\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.65425443649292\n",
      "Epoch: 865\n",
      "\tTrain Loss: 4.654 | Train PPL: 105.031\n",
      "\tVal Loss: 4.470 |  Val PPL:  87.353\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.656719207763672\n",
      "Epoch: 866\n",
      "\tTrain Loss: 4.657 | Train PPL: 105.290\n",
      "\tVal Loss: 4.469 |  Val PPL:  87.283\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.628389358520508\n",
      "Epoch: 867\n",
      "\tTrain Loss: 4.628 | Train PPL: 102.349\n",
      "\tVal Loss: 4.471 |  Val PPL:  87.419\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.63294792175293\n",
      "Epoch: 868\n",
      "\tTrain Loss: 4.633 | Train PPL: 102.817\n",
      "\tVal Loss: 4.471 |  Val PPL:  87.467\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.632272243499756\n",
      "Epoch: 869\n",
      "\tTrain Loss: 4.632 | Train PPL: 102.747\n",
      "\tVal Loss: 4.467 |  Val PPL:  87.088\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.611785411834717\n",
      "Epoch: 870\n",
      "\tTrain Loss: 4.612 | Train PPL: 100.664\n",
      "\tVal Loss: 4.459 |  Val PPL:  86.380\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.62042236328125\n",
      "Epoch: 871\n",
      "\tTrain Loss: 4.620 | Train PPL: 101.537\n",
      "\tVal Loss: 4.453 |  Val PPL:  85.881\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.634243965148926\n",
      "Epoch: 872\n",
      "\tTrain Loss: 4.634 | Train PPL: 102.950\n",
      "\tVal Loss: 4.450 |  Val PPL:  85.666\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.6488037109375\n",
      "Epoch: 873\n",
      "\tTrain Loss: 4.649 | Train PPL: 104.460\n",
      "\tVal Loss: 4.451 |  Val PPL:  85.681\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.608150959014893\n",
      "Epoch: 874\n",
      "\tTrain Loss: 4.608 | Train PPL: 100.299\n",
      "\tVal Loss: 4.452 |  Val PPL:  85.826\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.611008167266846\n",
      "Epoch: 875\n",
      "\tTrain Loss: 4.611 | Train PPL: 100.586\n",
      "\tVal Loss: 4.455 |  Val PPL:  86.013\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.626788139343262\n",
      "Epoch: 876\n",
      "\tTrain Loss: 4.627 | Train PPL: 102.185\n",
      "\tVal Loss: 4.457 |  Val PPL:  86.214\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.620353698730469\n",
      "Epoch: 877\n",
      "\tTrain Loss: 4.620 | Train PPL: 101.530\n",
      "\tVal Loss: 4.455 |  Val PPL:  86.092\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.602938175201416\n",
      "Epoch: 878\n",
      "\tTrain Loss: 4.603 | Train PPL:  99.777\n",
      "\tVal Loss: 4.453 |  Val PPL:  85.892\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.584343433380127\n",
      "Epoch: 879\n",
      "\tTrain Loss: 4.584 | Train PPL:  97.939\n",
      "\tVal Loss: 4.447 |  Val PPL:  85.395\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.611987590789795\n",
      "Epoch: 880\n",
      "\tTrain Loss: 4.612 | Train PPL: 100.684\n",
      "\tVal Loss: 4.443 |  Val PPL:  85.014\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.611999988555908\n",
      "Epoch: 881\n",
      "\tTrain Loss: 4.612 | Train PPL: 100.685\n",
      "\tVal Loss: 4.440 |  Val PPL:  84.762\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.634565353393555\n",
      "Epoch: 882\n",
      "\tTrain Loss: 4.635 | Train PPL: 102.983\n",
      "\tVal Loss: 4.438 |  Val PPL:  84.594\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.601294040679932\n",
      "Epoch: 883\n",
      "\tTrain Loss: 4.601 | Train PPL:  99.613\n",
      "\tVal Loss: 4.439 |  Val PPL:  84.674\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.6091156005859375\n",
      "Epoch: 884\n",
      "\tTrain Loss: 4.609 | Train PPL: 100.395\n",
      "\tVal Loss: 4.440 |  Val PPL:  84.816\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.624825477600098\n",
      "Epoch: 885\n",
      "\tTrain Loss: 4.625 | Train PPL: 101.985\n",
      "\tVal Loss: 4.440 |  Val PPL:  84.777\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.59483528137207\n",
      "Epoch: 886\n",
      "\tTrain Loss: 4.595 | Train PPL:  98.972\n",
      "\tVal Loss: 4.439 |  Val PPL:  84.682\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.625787734985352\n",
      "Epoch: 887\n",
      "\tTrain Loss: 4.626 | Train PPL: 102.083\n",
      "\tVal Loss: 4.438 |  Val PPL:  84.635\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.601211071014404\n",
      "Epoch: 888\n",
      "\tTrain Loss: 4.601 | Train PPL:  99.605\n",
      "\tVal Loss: 4.438 |  Val PPL:  84.601\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.585104942321777\n",
      "Epoch: 889\n",
      "\tTrain Loss: 4.585 | Train PPL:  98.013\n",
      "\tVal Loss: 4.437 |  Val PPL:  84.526\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.603593349456787\n",
      "Epoch: 890\n",
      "\tTrain Loss: 4.604 | Train PPL:  99.842\n",
      "\tVal Loss: 4.435 |  Val PPL:  84.382\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.588978290557861\n",
      "Epoch: 891\n",
      "\tTrain Loss: 4.589 | Train PPL:  98.394\n",
      "\tVal Loss: 4.432 |  Val PPL:  84.135\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.620757102966309\n",
      "Epoch: 892\n",
      "\tTrain Loss: 4.621 | Train PPL: 101.571\n",
      "\tVal Loss: 4.430 |  Val PPL:  83.918\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.57928466796875\n",
      "Epoch: 893\n",
      "\tTrain Loss: 4.579 | Train PPL:  97.445\n",
      "\tVal Loss: 4.427 |  Val PPL:  83.690\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.592544078826904\n",
      "Epoch: 894\n",
      "\tTrain Loss: 4.593 | Train PPL:  98.745\n",
      "\tVal Loss: 4.424 |  Val PPL:  83.441\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.59013032913208\n",
      "Epoch: 895\n",
      "\tTrain Loss: 4.590 | Train PPL:  98.507\n",
      "\tVal Loss: 4.422 |  Val PPL:  83.263\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.590913772583008\n",
      "Epoch: 896\n",
      "\tTrain Loss: 4.591 | Train PPL:  98.584\n",
      "\tVal Loss: 4.422 |  Val PPL:  83.231\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.576474189758301\n",
      "Epoch: 897\n",
      "\tTrain Loss: 4.576 | Train PPL:  97.171\n",
      "\tVal Loss: 4.423 |  Val PPL:  83.376\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.599860668182373\n",
      "Epoch: 898\n",
      "\tTrain Loss: 4.600 | Train PPL:  99.470\n",
      "\tVal Loss: 4.425 |  Val PPL:  83.535\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.592019557952881\n",
      "Epoch: 899\n",
      "\tTrain Loss: 4.592 | Train PPL:  98.694\n",
      "\tVal Loss: 4.422 |  Val PPL:  83.237\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.593687534332275\n",
      "Epoch: 900\n",
      "\tTrain Loss: 4.594 | Train PPL:  98.858\n",
      "\tVal Loss: 4.416 |  Val PPL:  82.752\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.570455551147461\n",
      "Epoch: 901\n",
      "\tTrain Loss: 4.570 | Train PPL:  96.588\n",
      "\tVal Loss: 4.411 |  Val PPL:  82.374\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.5836591720581055\n",
      "Epoch: 902\n",
      "\tTrain Loss: 4.584 | Train PPL:  97.872\n",
      "\tVal Loss: 4.409 |  Val PPL:  82.177\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.569157600402832\n",
      "Epoch: 903\n",
      "\tTrain Loss: 4.569 | Train PPL:  96.463\n",
      "\tVal Loss: 4.406 |  Val PPL:  81.961\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.590031147003174\n",
      "Epoch: 904\n",
      "\tTrain Loss: 4.590 | Train PPL:  98.497\n",
      "\tVal Loss: 4.404 |  Val PPL:  81.807\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.580766677856445\n",
      "Epoch: 905\n",
      "\tTrain Loss: 4.581 | Train PPL:  97.589\n",
      "\tVal Loss: 4.403 |  Val PPL:  81.699\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.588813304901123\n",
      "Epoch: 906\n",
      "\tTrain Loss: 4.589 | Train PPL:  98.378\n",
      "\tVal Loss: 4.403 |  Val PPL:  81.707\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.552908897399902\n",
      "Epoch: 907\n",
      "\tTrain Loss: 4.553 | Train PPL:  94.908\n",
      "\tVal Loss: 4.400 |  Val PPL:  81.457\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.565027713775635\n",
      "Epoch: 908\n",
      "\tTrain Loss: 4.565 | Train PPL:  96.065\n",
      "\tVal Loss: 4.396 |  Val PPL:  81.101\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.574617862701416\n",
      "Epoch: 909\n",
      "\tTrain Loss: 4.575 | Train PPL:  96.991\n",
      "\tVal Loss: 4.392 |  Val PPL:  80.770\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.5958356857299805\n",
      "Epoch: 910\n",
      "\tTrain Loss: 4.596 | Train PPL:  99.071\n",
      "\tVal Loss: 4.389 |  Val PPL:  80.529\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.580265998840332\n",
      "Epoch: 911\n",
      "\tTrain Loss: 4.580 | Train PPL:  97.540\n",
      "\tVal Loss: 4.388 |  Val PPL:  80.473\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.599050521850586\n",
      "Epoch: 912\n",
      "\tTrain Loss: 4.599 | Train PPL:  99.390\n",
      "\tVal Loss: 4.389 |  Val PPL:  80.539\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.565495491027832\n",
      "Epoch: 913\n",
      "\tTrain Loss: 4.565 | Train PPL:  96.110\n",
      "\tVal Loss: 4.393 |  Val PPL:  80.858\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.573216915130615\n",
      "Epoch: 914\n",
      "\tTrain Loss: 4.573 | Train PPL:  96.855\n",
      "\tVal Loss: 4.397 |  Val PPL:  81.240\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.545344829559326\n",
      "Epoch: 915\n",
      "\tTrain Loss: 4.545 | Train PPL:  94.193\n",
      "\tVal Loss: 4.398 |  Val PPL:  81.291\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.571444988250732\n",
      "Epoch: 916\n",
      "\tTrain Loss: 4.571 | Train PPL:  96.684\n",
      "\tVal Loss: 4.393 |  Val PPL:  80.897\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.554530143737793\n",
      "Epoch: 917\n",
      "\tTrain Loss: 4.555 | Train PPL:  95.062\n",
      "\tVal Loss: 4.387 |  Val PPL:  80.432\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.540191650390625\n",
      "Epoch: 918\n",
      "\tTrain Loss: 4.540 | Train PPL:  93.709\n",
      "\tVal Loss: 4.384 |  Val PPL:  80.136\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.5813798904418945\n",
      "Epoch: 919\n",
      "\tTrain Loss: 4.581 | Train PPL:  97.649\n",
      "\tVal Loss: 4.381 |  Val PPL:  79.936\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.5381598472595215\n",
      "Epoch: 920\n",
      "\tTrain Loss: 4.538 | Train PPL:  93.519\n",
      "\tVal Loss: 4.380 |  Val PPL:  79.855\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.573920726776123\n",
      "Epoch: 921\n",
      "\tTrain Loss: 4.574 | Train PPL:  96.923\n",
      "\tVal Loss: 4.378 |  Val PPL:  79.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.552217960357666\n",
      "Epoch: 922\n",
      "\tTrain Loss: 4.552 | Train PPL:  94.843\n",
      "\tVal Loss: 4.375 |  Val PPL:  79.475\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.53303861618042\n",
      "Epoch: 923\n",
      "\tTrain Loss: 4.533 | Train PPL:  93.041\n",
      "\tVal Loss: 4.370 |  Val PPL:  79.042\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.569572448730469\n",
      "Epoch: 924\n",
      "\tTrain Loss: 4.570 | Train PPL:  96.503\n",
      "\tVal Loss: 4.365 |  Val PPL:  78.616\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.540676116943359\n",
      "Epoch: 925\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.754\n",
      "\tVal Loss: 4.361 |  Val PPL:  78.323\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.554806232452393\n",
      "Epoch: 926\n",
      "\tTrain Loss: 4.555 | Train PPL:  95.088\n",
      "\tVal Loss: 4.358 |  Val PPL:  78.120\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.536080360412598\n",
      "Epoch: 927\n",
      "\tTrain Loss: 4.536 | Train PPL:  93.324\n",
      "\tVal Loss: 4.356 |  Val PPL:  77.933\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.552313327789307\n",
      "Epoch: 928\n",
      "\tTrain Loss: 4.552 | Train PPL:  94.852\n",
      "\tVal Loss: 4.354 |  Val PPL:  77.780\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.540502071380615\n",
      "Epoch: 929\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.738\n",
      "\tVal Loss: 4.354 |  Val PPL:  77.752\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.546833515167236\n",
      "Epoch: 930\n",
      "\tTrain Loss: 4.547 | Train PPL:  94.333\n",
      "\tVal Loss: 4.355 |  Val PPL:  77.832\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.573213577270508\n",
      "Epoch: 931\n",
      "\tTrain Loss: 4.573 | Train PPL:  96.855\n",
      "\tVal Loss: 4.356 |  Val PPL:  77.961\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.545790195465088\n",
      "Epoch: 932\n",
      "\tTrain Loss: 4.546 | Train PPL:  94.235\n",
      "\tVal Loss: 4.357 |  Val PPL:  77.994\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.521570682525635\n",
      "Epoch: 933\n",
      "\tTrain Loss: 4.522 | Train PPL:  91.980\n",
      "\tVal Loss: 4.356 |  Val PPL:  77.962\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.534583568572998\n",
      "Epoch: 934\n",
      "\tTrain Loss: 4.535 | Train PPL:  93.185\n",
      "\tVal Loss: 4.354 |  Val PPL:  77.762\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.543701648712158\n",
      "Epoch: 935\n",
      "\tTrain Loss: 4.544 | Train PPL:  94.038\n",
      "\tVal Loss: 4.352 |  Val PPL:  77.653\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.5222673416137695\n",
      "Epoch: 936\n",
      "\tTrain Loss: 4.522 | Train PPL:  92.044\n",
      "\tVal Loss: 4.351 |  Val PPL:  77.566\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.529460430145264\n",
      "Epoch: 937\n",
      "\tTrain Loss: 4.529 | Train PPL:  92.709\n",
      "\tVal Loss: 4.350 |  Val PPL:  77.483\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.526189804077148\n",
      "Epoch: 938\n",
      "\tTrain Loss: 4.526 | Train PPL:  92.406\n",
      "\tVal Loss: 4.349 |  Val PPL:  77.400\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.523989677429199\n",
      "Epoch: 939\n",
      "\tTrain Loss: 4.524 | Train PPL:  92.203\n",
      "\tVal Loss: 4.344 |  Val PPL:  77.030\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.532375335693359\n",
      "Epoch: 940\n",
      "\tTrain Loss: 4.532 | Train PPL:  92.979\n",
      "\tVal Loss: 4.341 |  Val PPL:  76.822\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.523930549621582\n",
      "Epoch: 941\n",
      "\tTrain Loss: 4.524 | Train PPL:  92.197\n",
      "\tVal Loss: 4.340 |  Val PPL:  76.697\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.528059482574463\n",
      "Epoch: 942\n",
      "\tTrain Loss: 4.528 | Train PPL:  92.579\n",
      "\tVal Loss: 4.339 |  Val PPL:  76.648\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.5334391593933105\n",
      "Epoch: 943\n",
      "\tTrain Loss: 4.533 | Train PPL:  93.078\n",
      "\tVal Loss: 4.339 |  Val PPL:  76.644\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.503320693969727\n",
      "Epoch: 944\n",
      "\tTrain Loss: 4.503 | Train PPL:  90.317\n",
      "\tVal Loss: 4.343 |  Val PPL:  76.909\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.511524200439453\n",
      "Epoch: 945\n",
      "\tTrain Loss: 4.512 | Train PPL:  91.061\n",
      "\tVal Loss: 4.343 |  Val PPL:  76.943\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.5231523513793945\n",
      "Epoch: 946\n",
      "\tTrain Loss: 4.523 | Train PPL:  92.126\n",
      "\tVal Loss: 4.341 |  Val PPL:  76.770\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.499728679656982\n",
      "Epoch: 947\n",
      "\tTrain Loss: 4.500 | Train PPL:  89.993\n",
      "\tVal Loss: 4.336 |  Val PPL:  76.426\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.515293598175049\n",
      "Epoch: 948\n",
      "\tTrain Loss: 4.515 | Train PPL:  91.404\n",
      "\tVal Loss: 4.329 |  Val PPL:  75.876\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.5238871574401855\n",
      "Epoch: 949\n",
      "\tTrain Loss: 4.524 | Train PPL:  92.193\n",
      "\tVal Loss: 4.325 |  Val PPL:  75.570\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.512135028839111\n",
      "Epoch: 950\n",
      "\tTrain Loss: 4.512 | Train PPL:  91.116\n",
      "\tVal Loss: 4.322 |  Val PPL:  75.373\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.5239129066467285\n",
      "Epoch: 951\n",
      "\tTrain Loss: 4.524 | Train PPL:  92.196\n",
      "\tVal Loss: 4.321 |  Val PPL:  75.258\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.509528160095215\n",
      "Epoch: 952\n",
      "\tTrain Loss: 4.510 | Train PPL:  90.879\n",
      "\tVal Loss: 4.322 |  Val PPL:  75.377\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.5130391120910645\n",
      "Epoch: 953\n",
      "\tTrain Loss: 4.513 | Train PPL:  91.199\n",
      "\tVal Loss: 4.325 |  Val PPL:  75.533\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.53458309173584\n",
      "Epoch: 954\n",
      "\tTrain Loss: 4.535 | Train PPL:  93.185\n",
      "\tVal Loss: 4.325 |  Val PPL:  75.603\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.5135393142700195\n",
      "Epoch: 955\n",
      "\tTrain Loss: 4.514 | Train PPL:  91.244\n",
      "\tVal Loss: 4.324 |  Val PPL:  75.491\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.500535488128662\n",
      "Epoch: 956\n",
      "\tTrain Loss: 4.501 | Train PPL:  90.065\n",
      "\tVal Loss: 4.321 |  Val PPL:  75.264\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.498813152313232\n",
      "Epoch: 957\n",
      "\tTrain Loss: 4.499 | Train PPL:  89.910\n",
      "\tVal Loss: 4.320 |  Val PPL:  75.190\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.50917911529541\n",
      "Epoch: 958\n",
      "\tTrain Loss: 4.509 | Train PPL:  90.847\n",
      "\tVal Loss: 4.320 |  Val PPL:  75.154\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.52290678024292\n",
      "Epoch: 959\n",
      "\tTrain Loss: 4.523 | Train PPL:  92.103\n",
      "\tVal Loss: 4.319 |  Val PPL:  75.080\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.4955735206604\n",
      "Epoch: 960\n",
      "\tTrain Loss: 4.496 | Train PPL:  89.620\n",
      "\tVal Loss: 4.319 |  Val PPL:  75.122\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.505887031555176\n",
      "Epoch: 961\n",
      "\tTrain Loss: 4.506 | Train PPL:  90.549\n",
      "\tVal Loss: 4.321 |  Val PPL:  75.280\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.480538368225098\n",
      "Epoch: 962\n",
      "\tTrain Loss: 4.481 | Train PPL:  88.282\n",
      "\tVal Loss: 4.322 |  Val PPL:  75.366\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.499654293060303\n",
      "Epoch: 963\n",
      "\tTrain Loss: 4.500 | Train PPL:  89.986\n",
      "\tVal Loss: 4.320 |  Val PPL:  75.182\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.481071949005127\n",
      "Epoch: 964\n",
      "\tTrain Loss: 4.481 | Train PPL:  88.329\n",
      "\tVal Loss: 4.315 |  Val PPL:  74.814\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.4972968101501465\n",
      "Epoch: 965\n",
      "\tTrain Loss: 4.497 | Train PPL:  89.774\n",
      "\tVal Loss: 4.311 |  Val PPL:  74.493\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.496301651000977\n",
      "Epoch: 966\n",
      "\tTrain Loss: 4.496 | Train PPL:  89.685\n",
      "\tVal Loss: 4.307 |  Val PPL:  74.223\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.501308917999268\n",
      "Epoch: 967\n",
      "\tTrain Loss: 4.501 | Train PPL:  90.135\n",
      "\tVal Loss: 4.304 |  Val PPL:  73.985\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.507602691650391\n",
      "Epoch: 968\n",
      "\tTrain Loss: 4.508 | Train PPL:  90.704\n",
      "\tVal Loss: 4.300 |  Val PPL:  73.697\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.4766764640808105\n",
      "Epoch: 969\n",
      "\tTrain Loss: 4.477 | Train PPL:  87.942\n",
      "\tVal Loss: 4.297 |  Val PPL:  73.504\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.488698482513428\n",
      "Epoch: 970\n",
      "\tTrain Loss: 4.489 | Train PPL:  89.006\n",
      "\tVal Loss: 4.295 |  Val PPL:  73.366\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.505880355834961\n",
      "Epoch: 971\n",
      "\tTrain Loss: 4.506 | Train PPL:  90.548\n",
      "\tVal Loss: 4.295 |  Val PPL:  73.298\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.479465961456299\n",
      "Epoch: 972\n",
      "\tTrain Loss: 4.479 | Train PPL:  88.188\n",
      "\tVal Loss: 4.293 |  Val PPL:  73.195\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.483187198638916\n",
      "Epoch: 973\n",
      "\tTrain Loss: 4.483 | Train PPL:  88.516\n",
      "\tVal Loss: 4.291 |  Val PPL:  73.055\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.481490612030029\n",
      "Epoch: 974\n",
      "\tTrain Loss: 4.481 | Train PPL:  88.366\n",
      "\tVal Loss: 4.287 |  Val PPL:  72.778\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.4872283935546875\n",
      "Epoch: 975\n",
      "\tTrain Loss: 4.487 | Train PPL:  88.875\n",
      "\tVal Loss: 4.284 |  Val PPL:  72.564\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.487626075744629\n",
      "Epoch: 976\n",
      "\tTrain Loss: 4.488 | Train PPL:  88.910\n",
      "\tVal Loss: 4.282 |  Val PPL:  72.418\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.486715793609619\n",
      "Epoch: 977\n",
      "\tTrain Loss: 4.487 | Train PPL:  88.829\n",
      "\tVal Loss: 4.281 |  Val PPL:  72.324\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.465952396392822\n",
      "Epoch: 978\n",
      "\tTrain Loss: 4.466 | Train PPL:  87.004\n",
      "\tVal Loss: 4.280 |  Val PPL:  72.241\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.4798903465271\n",
      "Epoch: 979\n",
      "\tTrain Loss: 4.480 | Train PPL:  88.225\n",
      "\tVal Loss: 4.280 |  Val PPL:  72.220\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.492905616760254\n",
      "Epoch: 980\n",
      "\tTrain Loss: 4.493 | Train PPL:  89.381\n",
      "\tVal Loss: 4.279 |  Val PPL:  72.141\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.4796648025512695\n",
      "Epoch: 981\n",
      "\tTrain Loss: 4.480 | Train PPL:  88.205\n",
      "\tVal Loss: 4.277 |  Val PPL:  72.018\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.482024669647217\n",
      "Epoch: 982\n",
      "\tTrain Loss: 4.482 | Train PPL:  88.413\n",
      "\tVal Loss: 4.275 |  Val PPL:  71.878\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.513264179229736\n",
      "Epoch: 983\n",
      "\tTrain Loss: 4.513 | Train PPL:  91.219\n",
      "\tVal Loss: 4.274 |  Val PPL:  71.818\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.461921215057373\n",
      "Epoch: 984\n",
      "\tTrain Loss: 4.462 | Train PPL:  86.654\n",
      "\tVal Loss: 4.274 |  Val PPL:  71.796\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.4701313972473145\n",
      "Epoch: 985\n",
      "\tTrain Loss: 4.470 | Train PPL:  87.368\n",
      "\tVal Loss: 4.273 |  Val PPL:  71.719\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.487125396728516\n",
      "Epoch: 986\n",
      "\tTrain Loss: 4.487 | Train PPL:  88.866\n",
      "\tVal Loss: 4.271 |  Val PPL:  71.598\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.485017776489258\n",
      "Epoch: 987\n",
      "\tTrain Loss: 4.485 | Train PPL:  88.679\n",
      "\tVal Loss: 4.270 |  Val PPL:  71.556\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.47392463684082\n",
      "Epoch: 988\n",
      "\tTrain Loss: 4.474 | Train PPL:  87.700\n",
      "\tVal Loss: 4.269 |  Val PPL:  71.471\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.470602989196777\n",
      "Epoch: 989\n",
      "\tTrain Loss: 4.471 | Train PPL:  87.409\n",
      "\tVal Loss: 4.267 |  Val PPL:  71.301\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.465054035186768\n",
      "Epoch: 990\n",
      "\tTrain Loss: 4.465 | Train PPL:  86.926\n",
      "\tVal Loss: 4.263 |  Val PPL:  71.005\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.448457717895508\n",
      "Epoch: 991\n",
      "\tTrain Loss: 4.448 | Train PPL:  85.495\n",
      "\tVal Loss: 4.258 |  Val PPL:  70.703\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.449915409088135\n",
      "Epoch: 992\n",
      "\tTrain Loss: 4.450 | Train PPL:  85.620\n",
      "\tVal Loss: 4.256 |  Val PPL:  70.515\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.444584846496582\n",
      "Epoch: 993\n",
      "\tTrain Loss: 4.445 | Train PPL:  85.165\n",
      "\tVal Loss: 4.254 |  Val PPL:  70.391\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.44487190246582\n",
      "Epoch: 994\n",
      "\tTrain Loss: 4.445 | Train PPL:  85.189\n",
      "\tVal Loss: 4.254 |  Val PPL:  70.364\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.454202651977539\n",
      "Epoch: 995\n",
      "\tTrain Loss: 4.454 | Train PPL:  85.988\n",
      "\tVal Loss: 4.255 |  Val PPL:  70.436\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.4587883949279785\n",
      "Epoch: 996\n",
      "\tTrain Loss: 4.459 | Train PPL:  86.383\n",
      "\tVal Loss: 4.256 |  Val PPL:  70.528\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.4148383140563965\n",
      "Epoch: 997\n",
      "\tTrain Loss: 4.415 | Train PPL:  82.668\n",
      "\tVal Loss: 4.255 |  Val PPL:  70.433\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.449522495269775\n",
      "Epoch: 998\n",
      "\tTrain Loss: 4.450 | Train PPL:  85.586\n",
      "\tVal Loss: 4.253 |  Val PPL:  70.291\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.456477165222168\n",
      "Epoch: 999\n",
      "\tTrain Loss: 4.456 | Train PPL:  86.183\n",
      "\tVal Loss: 4.249 |  Val PPL:  70.069\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.452964782714844\n",
      "Epoch: 1000\n",
      "\tTrain Loss: 4.453 | Train PPL:  85.881\n",
      "\tVal Loss: 4.245 |  Val PPL:  69.754\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.4577202796936035\n",
      "Epoch: 1001\n",
      "\tTrain Loss: 4.458 | Train PPL:  86.291\n",
      "\tVal Loss: 4.241 |  Val PPL:  69.488\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.441975116729736\n",
      "Epoch: 1002\n",
      "\tTrain Loss: 4.442 | Train PPL:  84.943\n",
      "\tVal Loss: 4.239 |  Val PPL:  69.325\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.45705509185791\n",
      "Epoch: 1003\n",
      "\tTrain Loss: 4.457 | Train PPL:  86.233\n",
      "\tVal Loss: 4.239 |  Val PPL:  69.330\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.464216709136963\n",
      "Epoch: 1004\n",
      "\tTrain Loss: 4.464 | Train PPL:  86.853\n",
      "\tVal Loss: 4.240 |  Val PPL:  69.410\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.437780380249023\n",
      "Epoch: 1005\n",
      "\tTrain Loss: 4.438 | Train PPL:  84.587\n",
      "\tVal Loss: 4.240 |  Val PPL:  69.420\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.432099342346191\n",
      "Epoch: 1006\n",
      "\tTrain Loss: 4.432 | Train PPL:  84.108\n",
      "\tVal Loss: 4.242 |  Val PPL:  69.538\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.433956146240234\n",
      "Epoch: 1007\n",
      "\tTrain Loss: 4.434 | Train PPL:  84.264\n",
      "\tVal Loss: 4.245 |  Val PPL:  69.726\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.4516825675964355\n",
      "Epoch: 1008\n",
      "\tTrain Loss: 4.452 | Train PPL:  85.771\n",
      "\tVal Loss: 4.248 |  Val PPL:  69.941\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.4131293296813965\n",
      "Epoch: 1009\n",
      "\tTrain Loss: 4.413 | Train PPL:  82.527\n",
      "\tVal Loss: 4.248 |  Val PPL:  69.968\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.4195876121521\n",
      "Epoch: 1010\n",
      "\tTrain Loss: 4.420 | Train PPL:  83.062\n",
      "\tVal Loss: 4.246 |  Val PPL:  69.803\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.415055274963379\n",
      "Epoch: 1011\n",
      "\tTrain Loss: 4.415 | Train PPL:  82.686\n",
      "\tVal Loss: 4.240 |  Val PPL:  69.429\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.419212818145752\n",
      "Epoch: 1012\n",
      "\tTrain Loss: 4.419 | Train PPL:  83.031\n",
      "\tVal Loss: 4.237 |  Val PPL:  69.196\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.444041728973389\n",
      "Epoch: 1013\n",
      "\tTrain Loss: 4.444 | Train PPL:  85.118\n",
      "\tVal Loss: 4.234 |  Val PPL:  69.002\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.395448207855225\n",
      "Epoch: 1014\n",
      "\tTrain Loss: 4.395 | Train PPL:  81.081\n",
      "\tVal Loss: 4.232 |  Val PPL:  68.858\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.423610687255859\n",
      "Epoch: 1015\n",
      "\tTrain Loss: 4.424 | Train PPL:  83.397\n",
      "\tVal Loss: 4.231 |  Val PPL:  68.757\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.458067893981934\n",
      "Epoch: 1016\n",
      "\tTrain Loss: 4.458 | Train PPL:  86.321\n",
      "\tVal Loss: 4.230 |  Val PPL:  68.690\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.423266887664795\n",
      "Epoch: 1017\n",
      "\tTrain Loss: 4.423 | Train PPL:  83.368\n",
      "\tVal Loss: 4.229 |  Val PPL:  68.642\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.439543724060059\n",
      "Epoch: 1018\n",
      "\tTrain Loss: 4.440 | Train PPL:  84.736\n",
      "\tVal Loss: 4.227 |  Val PPL:  68.490\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.417802810668945\n",
      "Epoch: 1019\n",
      "\tTrain Loss: 4.418 | Train PPL:  82.914\n",
      "\tVal Loss: 4.223 |  Val PPL:  68.259\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.408331871032715\n",
      "Epoch: 1020\n",
      "\tTrain Loss: 4.408 | Train PPL:  82.132\n",
      "\tVal Loss: 4.220 |  Val PPL:  68.029\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.404903411865234\n",
      "Epoch: 1021\n",
      "\tTrain Loss: 4.405 | Train PPL:  81.851\n",
      "\tVal Loss: 4.217 |  Val PPL:  67.854\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.434471607208252\n",
      "Epoch: 1022\n",
      "\tTrain Loss: 4.434 | Train PPL:  84.308\n",
      "\tVal Loss: 4.215 |  Val PPL:  67.699\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.407625675201416\n",
      "Epoch: 1023\n",
      "\tTrain Loss: 4.408 | Train PPL:  82.074\n",
      "\tVal Loss: 4.214 |  Val PPL:  67.597\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.432380199432373\n",
      "Epoch: 1024\n",
      "\tTrain Loss: 4.432 | Train PPL:  84.131\n",
      "\tVal Loss: 4.212 |  Val PPL:  67.490\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.423769474029541\n",
      "Epoch: 1025\n",
      "\tTrain Loss: 4.424 | Train PPL:  83.410\n",
      "\tVal Loss: 4.212 |  Val PPL:  67.463\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.426969051361084\n",
      "Epoch: 1026\n",
      "\tTrain Loss: 4.427 | Train PPL:  83.677\n",
      "\tVal Loss: 4.210 |  Val PPL:  67.358\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.404184818267822\n",
      "Epoch: 1027\n",
      "\tTrain Loss: 4.404 | Train PPL:  81.792\n",
      "\tVal Loss: 4.208 |  Val PPL:  67.241\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.427003383636475\n",
      "Epoch: 1028\n",
      "\tTrain Loss: 4.427 | Train PPL:  83.680\n",
      "\tVal Loss: 4.206 |  Val PPL:  67.077\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.428279876708984\n",
      "Epoch: 1029\n",
      "\tTrain Loss: 4.428 | Train PPL:  83.787\n",
      "\tVal Loss: 4.204 |  Val PPL:  66.935\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.415646076202393\n",
      "Epoch: 1030\n",
      "\tTrain Loss: 4.416 | Train PPL:  82.735\n",
      "\tVal Loss: 4.203 |  Val PPL:  66.856\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.412337779998779\n",
      "Epoch: 1031\n",
      "\tTrain Loss: 4.412 | Train PPL:  82.462\n",
      "\tVal Loss: 4.203 |  Val PPL:  66.869\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.4209885597229\n",
      "Epoch: 1032\n",
      "\tTrain Loss: 4.421 | Train PPL:  83.178\n",
      "\tVal Loss: 4.202 |  Val PPL:  66.838\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.395247459411621\n",
      "Epoch: 1033\n",
      "\tTrain Loss: 4.395 | Train PPL:  81.065\n",
      "\tVal Loss: 4.201 |  Val PPL:  66.724\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.419232368469238\n",
      "Epoch: 1034\n",
      "\tTrain Loss: 4.419 | Train PPL:  83.033\n",
      "\tVal Loss: 4.198 |  Val PPL:  66.532\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.400156497955322\n",
      "Epoch: 1035\n",
      "\tTrain Loss: 4.400 | Train PPL:  81.464\n",
      "\tVal Loss: 4.194 |  Val PPL:  66.312\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.408159255981445\n",
      "Epoch: 1036\n",
      "\tTrain Loss: 4.408 | Train PPL:  82.118\n",
      "\tVal Loss: 4.191 |  Val PPL:  66.095\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.4134907722473145\n",
      "Epoch: 1037\n",
      "\tTrain Loss: 4.413 | Train PPL:  82.557\n",
      "\tVal Loss: 4.189 |  Val PPL:  65.938\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.398745059967041\n",
      "Epoch: 1038\n",
      "\tTrain Loss: 4.399 | Train PPL:  81.349\n",
      "\tVal Loss: 4.188 |  Val PPL:  65.912\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.393861770629883\n",
      "Epoch: 1039\n",
      "\tTrain Loss: 4.394 | Train PPL:  80.952\n",
      "\tVal Loss: 4.189 |  Val PPL:  65.939\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.40969181060791\n",
      "Epoch: 1040\n",
      "\tTrain Loss: 4.410 | Train PPL:  82.244\n",
      "\tVal Loss: 4.188 |  Val PPL:  65.908\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.405094146728516\n",
      "Epoch: 1041\n",
      "\tTrain Loss: 4.405 | Train PPL:  81.867\n",
      "\tVal Loss: 4.187 |  Val PPL:  65.800\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.371376991271973\n",
      "Epoch: 1042\n",
      "\tTrain Loss: 4.371 | Train PPL:  79.153\n",
      "\tVal Loss: 4.184 |  Val PPL:  65.655\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.416658878326416\n",
      "Epoch: 1043\n",
      "\tTrain Loss: 4.417 | Train PPL:  82.819\n",
      "\tVal Loss: 4.182 |  Val PPL:  65.500\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.4159955978393555\n",
      "Epoch: 1044\n",
      "\tTrain Loss: 4.416 | Train PPL:  82.764\n",
      "\tVal Loss: 4.179 |  Val PPL:  65.311\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.4081010818481445\n",
      "Epoch: 1045\n",
      "\tTrain Loss: 4.408 | Train PPL:  82.113\n",
      "\tVal Loss: 4.177 |  Val PPL:  65.168\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.411984443664551\n",
      "Epoch: 1046\n",
      "\tTrain Loss: 4.412 | Train PPL:  82.433\n",
      "\tVal Loss: 4.177 |  Val PPL:  65.138\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.385658264160156\n",
      "Epoch: 1047\n",
      "\tTrain Loss: 4.386 | Train PPL:  80.291\n",
      "\tVal Loss: 4.176 |  Val PPL:  65.083\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.390881061553955\n",
      "Epoch: 1048\n",
      "\tTrain Loss: 4.391 | Train PPL:  80.711\n",
      "\tVal Loss: 4.176 |  Val PPL:  65.107\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.3968586921691895\n",
      "Epoch: 1049\n",
      "\tTrain Loss: 4.397 | Train PPL:  81.195\n",
      "\tVal Loss: 4.177 |  Val PPL:  65.144\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.400339603424072\n",
      "Epoch: 1050\n",
      "\tTrain Loss: 4.400 | Train PPL:  81.479\n",
      "\tVal Loss: 4.177 |  Val PPL:  65.162\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.366824626922607\n",
      "Epoch: 1051\n",
      "\tTrain Loss: 4.367 | Train PPL:  78.793\n",
      "\tVal Loss: 4.176 |  Val PPL:  65.099\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.3867692947387695\n",
      "Epoch: 1052\n",
      "\tTrain Loss: 4.387 | Train PPL:  80.380\n",
      "\tVal Loss: 4.174 |  Val PPL:  64.971\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.3698930740356445\n",
      "Epoch: 1053\n",
      "\tTrain Loss: 4.370 | Train PPL:  79.035\n",
      "\tVal Loss: 4.170 |  Val PPL:  64.748\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.3564066886901855\n",
      "Epoch: 1054\n",
      "\tTrain Loss: 4.356 | Train PPL:  77.976\n",
      "\tVal Loss: 4.167 |  Val PPL:  64.544\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.3874616622924805\n",
      "Epoch: 1055\n",
      "\tTrain Loss: 4.387 | Train PPL:  80.436\n",
      "\tVal Loss: 4.165 |  Val PPL:  64.407\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.388101577758789\n",
      "Epoch: 1056\n",
      "\tTrain Loss: 4.388 | Train PPL:  80.487\n",
      "\tVal Loss: 4.165 |  Val PPL:  64.418\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.382906913757324\n",
      "Epoch: 1057\n",
      "\tTrain Loss: 4.383 | Train PPL:  80.070\n",
      "\tVal Loss: 4.164 |  Val PPL:  64.352\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.388671875\n",
      "Epoch: 1058\n",
      "\tTrain Loss: 4.389 | Train PPL:  80.533\n",
      "\tVal Loss: 4.161 |  Val PPL:  64.162\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.357543468475342\n",
      "Epoch: 1059\n",
      "\tTrain Loss: 4.358 | Train PPL:  78.065\n",
      "\tVal Loss: 4.159 |  Val PPL:  63.998\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.357610702514648\n",
      "Epoch: 1060\n",
      "\tTrain Loss: 4.358 | Train PPL:  78.070\n",
      "\tVal Loss: 4.158 |  Val PPL:  63.916\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.37094259262085\n",
      "Epoch: 1061\n",
      "\tTrain Loss: 4.371 | Train PPL:  79.118\n",
      "\tVal Loss: 4.158 |  Val PPL:  63.929\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.362142086029053\n",
      "Epoch: 1062\n",
      "\tTrain Loss: 4.362 | Train PPL:  78.425\n",
      "\tVal Loss: 4.159 |  Val PPL:  63.998\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.3564910888671875\n",
      "Epoch: 1063\n",
      "\tTrain Loss: 4.356 | Train PPL:  77.983\n",
      "\tVal Loss: 4.159 |  Val PPL:  64.031\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.353063583374023\n",
      "Epoch: 1064\n",
      "\tTrain Loss: 4.353 | Train PPL:  77.716\n",
      "\tVal Loss: 4.160 |  Val PPL:  64.085\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.349766254425049\n",
      "Epoch: 1065\n",
      "\tTrain Loss: 4.350 | Train PPL:  77.460\n",
      "\tVal Loss: 4.160 |  Val PPL:  64.050\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.3561272621154785\n",
      "Epoch: 1066\n",
      "\tTrain Loss: 4.356 | Train PPL:  77.955\n",
      "\tVal Loss: 4.157 |  Val PPL:  63.902\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.381104469299316\n",
      "Epoch: 1067\n",
      "\tTrain Loss: 4.381 | Train PPL:  79.926\n",
      "\tVal Loss: 4.154 |  Val PPL:  63.696\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.372978687286377\n",
      "Epoch: 1068\n",
      "\tTrain Loss: 4.373 | Train PPL:  79.279\n",
      "\tVal Loss: 4.150 |  Val PPL:  63.406\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.37483549118042\n",
      "Epoch: 1069\n",
      "\tTrain Loss: 4.375 | Train PPL:  79.427\n",
      "\tVal Loss: 4.144 |  Val PPL:  63.078\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.380123138427734\n",
      "Epoch: 1070\n",
      "\tTrain Loss: 4.380 | Train PPL:  79.848\n",
      "\tVal Loss: 4.141 |  Val PPL:  62.841\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.343502998352051\n",
      "Epoch: 1071\n",
      "\tTrain Loss: 4.344 | Train PPL:  76.977\n",
      "\tVal Loss: 4.139 |  Val PPL:  62.720\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.325770854949951\n",
      "Epoch: 1072\n",
      "\tTrain Loss: 4.326 | Train PPL:  75.624\n",
      "\tVal Loss: 4.137 |  Val PPL:  62.616\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.382557392120361\n",
      "Epoch: 1073\n",
      "\tTrain Loss: 4.383 | Train PPL:  80.042\n",
      "\tVal Loss: 4.137 |  Val PPL:  62.596\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.35685920715332\n",
      "Epoch: 1074\n",
      "\tTrain Loss: 4.357 | Train PPL:  78.012\n",
      "\tVal Loss: 4.136 |  Val PPL:  62.574\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.3501105308532715\n",
      "Epoch: 1075\n",
      "\tTrain Loss: 4.350 | Train PPL:  77.487\n",
      "\tVal Loss: 4.137 |  Val PPL:  62.606\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.342140197753906\n",
      "Epoch: 1076\n",
      "\tTrain Loss: 4.342 | Train PPL:  76.872\n",
      "\tVal Loss: 4.138 |  Val PPL:  62.692\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.375195503234863\n",
      "Epoch: 1077\n",
      "\tTrain Loss: 4.375 | Train PPL:  79.455\n",
      "\tVal Loss: 4.137 |  Val PPL:  62.632\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.340048313140869\n",
      "Epoch: 1078\n",
      "\tTrain Loss: 4.340 | Train PPL:  76.711\n",
      "\tVal Loss: 4.135 |  Val PPL:  62.483\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.351675033569336\n",
      "Epoch: 1079\n",
      "\tTrain Loss: 4.352 | Train PPL:  77.608\n",
      "\tVal Loss: 4.132 |  Val PPL:  62.296\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.352758407592773\n",
      "Epoch: 1080\n",
      "\tTrain Loss: 4.353 | Train PPL:  77.692\n",
      "\tVal Loss: 4.129 |  Val PPL:  62.090\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.3450212478637695\n",
      "Epoch: 1081\n",
      "\tTrain Loss: 4.345 | Train PPL:  77.094\n",
      "\tVal Loss: 4.125 |  Val PPL:  61.889\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.322519779205322\n",
      "Epoch: 1082\n",
      "\tTrain Loss: 4.323 | Train PPL:  75.378\n",
      "\tVal Loss: 4.123 |  Val PPL:  61.766\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.348917007446289\n",
      "Epoch: 1083\n",
      "\tTrain Loss: 4.349 | Train PPL:  77.395\n",
      "\tVal Loss: 4.123 |  Val PPL:  61.725\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.336790561676025\n",
      "Epoch: 1084\n",
      "\tTrain Loss: 4.337 | Train PPL:  76.462\n",
      "\tVal Loss: 4.122 |  Val PPL:  61.661\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.367560386657715\n",
      "Epoch: 1085\n",
      "\tTrain Loss: 4.368 | Train PPL:  78.851\n",
      "\tVal Loss: 4.121 |  Val PPL:  61.598\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.331089496612549\n",
      "Epoch: 1086\n",
      "\tTrain Loss: 4.331 | Train PPL:  76.027\n",
      "\tVal Loss: 4.120 |  Val PPL:  61.568\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.34013557434082\n",
      "Epoch: 1087\n",
      "\tTrain Loss: 4.340 | Train PPL:  76.718\n",
      "\tVal Loss: 4.119 |  Val PPL:  61.505\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.340035438537598\n",
      "Epoch: 1088\n",
      "\tTrain Loss: 4.340 | Train PPL:  76.710\n",
      "\tVal Loss: 4.117 |  Val PPL:  61.355\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.305790901184082\n",
      "Epoch: 1089\n",
      "\tTrain Loss: 4.306 | Train PPL:  74.128\n",
      "\tVal Loss: 4.116 |  Val PPL:  61.294\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.321646213531494\n",
      "Epoch: 1090\n",
      "\tTrain Loss: 4.322 | Train PPL:  75.313\n",
      "\tVal Loss: 4.114 |  Val PPL:  61.213\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.3448920249938965\n",
      "Epoch: 1091\n",
      "\tTrain Loss: 4.345 | Train PPL:  77.084\n",
      "\tVal Loss: 4.112 |  Val PPL:  61.059\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.355530261993408\n",
      "Epoch: 1092\n",
      "\tTrain Loss: 4.356 | Train PPL:  77.908\n",
      "\tVal Loss: 4.109 |  Val PPL:  60.882\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.327352046966553\n",
      "Epoch: 1093\n",
      "\tTrain Loss: 4.327 | Train PPL:  75.743\n",
      "\tVal Loss: 4.105 |  Val PPL:  60.654\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.331480503082275\n",
      "Epoch: 1094\n",
      "\tTrain Loss: 4.331 | Train PPL:  76.057\n",
      "\tVal Loss: 4.101 |  Val PPL:  60.408\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.345595836639404\n",
      "Epoch: 1095\n",
      "\tTrain Loss: 4.346 | Train PPL:  77.138\n",
      "\tVal Loss: 4.097 |  Val PPL:  60.178\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.318907260894775\n",
      "Epoch: 1096\n",
      "\tTrain Loss: 4.319 | Train PPL:  75.107\n",
      "\tVal Loss: 4.096 |  Val PPL:  60.090\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.330913066864014\n",
      "Epoch: 1097\n",
      "\tTrain Loss: 4.331 | Train PPL:  76.014\n",
      "\tVal Loss: 4.096 |  Val PPL:  60.116\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.3178486824035645\n",
      "Epoch: 1098\n",
      "\tTrain Loss: 4.318 | Train PPL:  75.027\n",
      "\tVal Loss: 4.098 |  Val PPL:  60.234\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.331047058105469\n",
      "Epoch: 1099\n",
      "\tTrain Loss: 4.331 | Train PPL:  76.024\n",
      "\tVal Loss: 4.101 |  Val PPL:  60.397\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.3147735595703125\n",
      "Epoch: 1100\n",
      "\tTrain Loss: 4.315 | Train PPL:  74.797\n",
      "\tVal Loss: 4.102 |  Val PPL:  60.460\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.327180862426758\n",
      "Epoch: 1101\n",
      "\tTrain Loss: 4.327 | Train PPL:  75.730\n",
      "\tVal Loss: 4.103 |  Val PPL:  60.503\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.3159894943237305\n",
      "Epoch: 1102\n",
      "\tTrain Loss: 4.316 | Train PPL:  74.888\n",
      "\tVal Loss: 4.102 |  Val PPL:  60.477\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.327971458435059\n",
      "Epoch: 1103\n",
      "\tTrain Loss: 4.328 | Train PPL:  75.790\n",
      "\tVal Loss: 4.101 |  Val PPL:  60.416\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.300751686096191\n",
      "Epoch: 1104\n",
      "\tTrain Loss: 4.301 | Train PPL:  73.755\n",
      "\tVal Loss: 4.101 |  Val PPL:  60.395\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.335129261016846\n",
      "Epoch: 1105\n",
      "\tTrain Loss: 4.335 | Train PPL:  76.335\n",
      "\tVal Loss: 4.099 |  Val PPL:  60.292\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.3291425704956055\n",
      "Epoch: 1106\n",
      "\tTrain Loss: 4.329 | Train PPL:  75.879\n",
      "\tVal Loss: 4.098 |  Val PPL:  60.248\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.315736770629883\n",
      "Epoch: 1107\n",
      "\tTrain Loss: 4.316 | Train PPL:  74.869\n",
      "\tVal Loss: 4.098 |  Val PPL:  60.212\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.3300933837890625\n",
      "Epoch: 1108\n",
      "\tTrain Loss: 4.330 | Train PPL:  75.951\n",
      "\tVal Loss: 4.096 |  Val PPL:  60.106\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.32160758972168\n",
      "Epoch: 1109\n",
      "\tTrain Loss: 4.322 | Train PPL:  75.310\n",
      "\tVal Loss: 4.092 |  Val PPL:  59.874\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.316617965698242\n",
      "Epoch: 1110\n",
      "\tTrain Loss: 4.317 | Train PPL:  74.935\n",
      "\tVal Loss: 4.087 |  Val PPL:  59.580\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.326192855834961\n",
      "Epoch: 1111\n",
      "\tTrain Loss: 4.326 | Train PPL:  75.656\n",
      "\tVal Loss: 4.083 |  Val PPL:  59.332\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.326999664306641\n",
      "Epoch: 1112\n",
      "\tTrain Loss: 4.327 | Train PPL:  75.717\n",
      "\tVal Loss: 4.080 |  Val PPL:  59.155\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.296186447143555\n",
      "Epoch: 1113\n",
      "\tTrain Loss: 4.296 | Train PPL:  73.419\n",
      "\tVal Loss: 4.079 |  Val PPL:  59.086\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.313119888305664\n",
      "Epoch: 1114\n",
      "\tTrain Loss: 4.313 | Train PPL:  74.673\n",
      "\tVal Loss: 4.079 |  Val PPL:  59.074\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.30723762512207\n",
      "Epoch: 1115\n",
      "\tTrain Loss: 4.307 | Train PPL:  74.235\n",
      "\tVal Loss: 4.079 |  Val PPL:  59.088\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.305131912231445\n",
      "Epoch: 1116\n",
      "\tTrain Loss: 4.305 | Train PPL:  74.079\n",
      "\tVal Loss: 4.078 |  Val PPL:  59.033\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.3356804847717285\n",
      "Epoch: 1117\n",
      "\tTrain Loss: 4.336 | Train PPL:  76.377\n",
      "\tVal Loss: 4.078 |  Val PPL:  59.011\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.300967693328857\n",
      "Epoch: 1118\n",
      "\tTrain Loss: 4.301 | Train PPL:  73.771\n",
      "\tVal Loss: 4.077 |  Val PPL:  58.997\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.27861213684082\n",
      "Epoch: 1119\n",
      "\tTrain Loss: 4.279 | Train PPL:  72.140\n",
      "\tVal Loss: 4.076 |  Val PPL:  58.885\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.28721284866333\n",
      "Epoch: 1120\n",
      "\tTrain Loss: 4.287 | Train PPL:  72.763\n",
      "\tVal Loss: 4.074 |  Val PPL:  58.810\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.2938408851623535\n",
      "Epoch: 1121\n",
      "\tTrain Loss: 4.294 | Train PPL:  73.247\n",
      "\tVal Loss: 4.073 |  Val PPL:  58.752\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.315725803375244\n",
      "Epoch: 1122\n",
      "\tTrain Loss: 4.316 | Train PPL:  74.868\n",
      "\tVal Loss: 4.071 |  Val PPL:  58.601\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.3287858963012695\n",
      "Epoch: 1123\n",
      "\tTrain Loss: 4.329 | Train PPL:  75.852\n",
      "\tVal Loss: 4.067 |  Val PPL:  58.362\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.293989658355713\n",
      "Epoch: 1124\n",
      "\tTrain Loss: 4.294 | Train PPL:  73.258\n",
      "\tVal Loss: 4.063 |  Val PPL:  58.157\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.286071300506592\n",
      "Epoch: 1125\n",
      "\tTrain Loss: 4.286 | Train PPL:  72.680\n",
      "\tVal Loss: 4.061 |  Val PPL:  58.034\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.308361530303955\n",
      "Epoch: 1126\n",
      "\tTrain Loss: 4.308 | Train PPL:  74.319\n",
      "\tVal Loss: 4.059 |  Val PPL:  57.929\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.2945170402526855\n",
      "Epoch: 1127\n",
      "\tTrain Loss: 4.295 | Train PPL:  73.297\n",
      "\tVal Loss: 4.059 |  Val PPL:  57.915\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.269002914428711\n",
      "Epoch: 1128\n",
      "\tTrain Loss: 4.269 | Train PPL:  71.450\n",
      "\tVal Loss: 4.059 |  Val PPL:  57.922\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.323062419891357\n",
      "Epoch: 1129\n",
      "\tTrain Loss: 4.323 | Train PPL:  75.419\n",
      "\tVal Loss: 4.060 |  Val PPL:  57.962\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.283824920654297\n",
      "Epoch: 1130\n",
      "\tTrain Loss: 4.284 | Train PPL:  72.517\n",
      "\tVal Loss: 4.059 |  Val PPL:  57.909\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.314721584320068\n",
      "Epoch: 1131\n",
      "\tTrain Loss: 4.315 | Train PPL:  74.793\n",
      "\tVal Loss: 4.058 |  Val PPL:  57.865\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.2839436531066895\n",
      "Epoch: 1132\n",
      "\tTrain Loss: 4.284 | Train PPL:  72.526\n",
      "\tVal Loss: 4.058 |  Val PPL:  57.836\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.278648853302002\n",
      "Epoch: 1133\n",
      "\tTrain Loss: 4.279 | Train PPL:  72.143\n",
      "\tVal Loss: 4.058 |  Val PPL:  57.876\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.302464008331299\n",
      "Epoch: 1134\n",
      "\tTrain Loss: 4.302 | Train PPL:  73.882\n",
      "\tVal Loss: 4.057 |  Val PPL:  57.774\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.299228191375732\n",
      "Epoch: 1135\n",
      "\tTrain Loss: 4.299 | Train PPL:  73.643\n",
      "\tVal Loss: 4.055 |  Val PPL:  57.695\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.291362762451172\n",
      "Epoch: 1136\n",
      "\tTrain Loss: 4.291 | Train PPL:  73.066\n",
      "\tVal Loss: 4.053 |  Val PPL:  57.558\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.273260116577148\n",
      "Epoch: 1137\n",
      "\tTrain Loss: 4.273 | Train PPL:  71.755\n",
      "\tVal Loss: 4.049 |  Val PPL:  57.368\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.277480602264404\n",
      "Epoch: 1138\n",
      "\tTrain Loss: 4.277 | Train PPL:  72.059\n",
      "\tVal Loss: 4.045 |  Val PPL:  57.129\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.2626495361328125\n",
      "Epoch: 1139\n",
      "\tTrain Loss: 4.263 | Train PPL:  70.998\n",
      "\tVal Loss: 4.042 |  Val PPL:  56.938\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.2602972984313965\n",
      "Epoch: 1140\n",
      "\tTrain Loss: 4.260 | Train PPL:  70.831\n",
      "\tVal Loss: 4.039 |  Val PPL:  56.773\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.301713943481445\n",
      "Epoch: 1141\n",
      "\tTrain Loss: 4.302 | Train PPL:  73.826\n",
      "\tVal Loss: 4.039 |  Val PPL:  56.771\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.264590740203857\n",
      "Epoch: 1142\n",
      "\tTrain Loss: 4.265 | Train PPL:  71.136\n",
      "\tVal Loss: 4.038 |  Val PPL:  56.685\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.2779316902160645\n",
      "Epoch: 1143\n",
      "\tTrain Loss: 4.278 | Train PPL:  72.091\n",
      "\tVal Loss: 4.036 |  Val PPL:  56.591\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.247202396392822\n",
      "Epoch: 1144\n",
      "\tTrain Loss: 4.247 | Train PPL:  69.910\n",
      "\tVal Loss: 4.034 |  Val PPL:  56.464\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.2798285484313965\n",
      "Epoch: 1145\n",
      "\tTrain Loss: 4.280 | Train PPL:  72.228\n",
      "\tVal Loss: 4.034 |  Val PPL:  56.469\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.272818565368652\n",
      "Epoch: 1146\n",
      "\tTrain Loss: 4.273 | Train PPL:  71.724\n",
      "\tVal Loss: 4.036 |  Val PPL:  56.599\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.26482629776001\n",
      "Epoch: 1147\n",
      "\tTrain Loss: 4.265 | Train PPL:  71.153\n",
      "\tVal Loss: 4.039 |  Val PPL:  56.796\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.290288925170898\n",
      "Epoch: 1148\n",
      "\tTrain Loss: 4.290 | Train PPL:  72.988\n",
      "\tVal Loss: 4.039 |  Val PPL:  56.771\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.2745041847229\n",
      "Epoch: 1149\n",
      "\tTrain Loss: 4.275 | Train PPL:  71.845\n",
      "\tVal Loss: 4.039 |  Val PPL:  56.797\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.26962423324585\n",
      "Epoch: 1150\n",
      "\tTrain Loss: 4.270 | Train PPL:  71.495\n",
      "\tVal Loss: 4.039 |  Val PPL:  56.792\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.242259979248047\n",
      "Epoch: 1151\n",
      "\tTrain Loss: 4.242 | Train PPL:  69.565\n",
      "\tVal Loss: 4.038 |  Val PPL:  56.709\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.280191898345947\n",
      "Epoch: 1152\n",
      "\tTrain Loss: 4.280 | Train PPL:  72.254\n",
      "\tVal Loss: 4.035 |  Val PPL:  56.532\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.2686448097229\n",
      "Epoch: 1153\n",
      "\tTrain Loss: 4.269 | Train PPL:  71.425\n",
      "\tVal Loss: 4.030 |  Val PPL:  56.258\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.2860565185546875\n",
      "Epoch: 1154\n",
      "\tTrain Loss: 4.286 | Train PPL:  72.679\n",
      "\tVal Loss: 4.026 |  Val PPL:  56.029\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.252174377441406\n",
      "Epoch: 1155\n",
      "\tTrain Loss: 4.252 | Train PPL:  70.258\n",
      "\tVal Loss: 4.023 |  Val PPL:  55.863\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.2570695877075195\n",
      "Epoch: 1156\n",
      "\tTrain Loss: 4.257 | Train PPL:  70.603\n",
      "\tVal Loss: 4.021 |  Val PPL:  55.753\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.255492210388184\n",
      "Epoch: 1157\n",
      "\tTrain Loss: 4.255 | Train PPL:  70.492\n",
      "\tVal Loss: 4.020 |  Val PPL:  55.689\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.269481658935547\n",
      "Epoch: 1158\n",
      "\tTrain Loss: 4.269 | Train PPL:  71.485\n",
      "\tVal Loss: 4.019 |  Val PPL:  55.633\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.235982418060303\n",
      "Epoch: 1159\n",
      "\tTrain Loss: 4.236 | Train PPL:  69.130\n",
      "\tVal Loss: 4.019 |  Val PPL:  55.626\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.261114597320557\n",
      "Epoch: 1160\n",
      "\tTrain Loss: 4.261 | Train PPL:  70.889\n",
      "\tVal Loss: 4.020 |  Val PPL:  55.686\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.261762619018555\n",
      "Epoch: 1161\n",
      "\tTrain Loss: 4.262 | Train PPL:  70.935\n",
      "\tVal Loss: 4.020 |  Val PPL:  55.683\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.271702766418457\n",
      "Epoch: 1162\n",
      "\tTrain Loss: 4.272 | Train PPL:  71.644\n",
      "\tVal Loss: 4.017 |  Val PPL:  55.527\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.277368545532227\n",
      "Epoch: 1163\n",
      "\tTrain Loss: 4.277 | Train PPL:  72.051\n",
      "\tVal Loss: 4.013 |  Val PPL:  55.315\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.265213966369629\n",
      "Epoch: 1164\n",
      "\tTrain Loss: 4.265 | Train PPL:  71.180\n",
      "\tVal Loss: 4.011 |  Val PPL:  55.187\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.295133113861084\n",
      "Epoch: 1165\n",
      "\tTrain Loss: 4.295 | Train PPL:  73.342\n",
      "\tVal Loss: 4.010 |  Val PPL:  55.139\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.276658058166504\n",
      "Epoch: 1166\n",
      "\tTrain Loss: 4.277 | Train PPL:  71.999\n",
      "\tVal Loss: 4.010 |  Val PPL:  55.124\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.240383148193359\n",
      "Epoch: 1167\n",
      "\tTrain Loss: 4.240 | Train PPL:  69.434\n",
      "\tVal Loss: 4.012 |  Val PPL:  55.241\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.267236709594727\n",
      "Epoch: 1168\n",
      "\tTrain Loss: 4.267 | Train PPL:  71.324\n",
      "\tVal Loss: 4.014 |  Val PPL:  55.390\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.254907608032227\n",
      "Epoch: 1169\n",
      "\tTrain Loss: 4.255 | Train PPL:  70.450\n",
      "\tVal Loss: 4.018 |  Val PPL:  55.567\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.233521938323975\n",
      "Epoch: 1170\n",
      "\tTrain Loss: 4.234 | Train PPL:  68.960\n",
      "\tVal Loss: 4.017 |  Val PPL:  55.521\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.264923572540283\n",
      "Epoch: 1171\n",
      "\tTrain Loss: 4.265 | Train PPL:  71.159\n",
      "\tVal Loss: 4.014 |  Val PPL:  55.363\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.241597652435303\n",
      "Epoch: 1172\n",
      "\tTrain Loss: 4.242 | Train PPL:  69.519\n",
      "\tVal Loss: 4.010 |  Val PPL:  55.141\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.225743770599365\n",
      "Epoch: 1173\n",
      "\tTrain Loss: 4.226 | Train PPL:  68.425\n",
      "\tVal Loss: 4.005 |  Val PPL:  54.887\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.251410961151123\n",
      "Epoch: 1174\n",
      "\tTrain Loss: 4.251 | Train PPL:  70.204\n",
      "\tVal Loss: 4.000 |  Val PPL:  54.610\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.260225772857666\n",
      "Epoch: 1175\n",
      "\tTrain Loss: 4.260 | Train PPL:  70.826\n",
      "\tVal Loss: 3.996 |  Val PPL:  54.378\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.260436534881592\n",
      "Epoch: 1176\n",
      "\tTrain Loss: 4.260 | Train PPL:  70.841\n",
      "\tVal Loss: 3.992 |  Val PPL:  54.178\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.233758926391602\n",
      "Epoch: 1177\n",
      "\tTrain Loss: 4.234 | Train PPL:  68.976\n",
      "\tVal Loss: 3.990 |  Val PPL:  54.035\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.263925075531006\n",
      "Epoch: 1178\n",
      "\tTrain Loss: 4.264 | Train PPL:  71.088\n",
      "\tVal Loss: 3.988 |  Val PPL:  53.969\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.23066520690918\n",
      "Epoch: 1179\n",
      "\tTrain Loss: 4.231 | Train PPL:  68.763\n",
      "\tVal Loss: 3.988 |  Val PPL:  53.927\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.239971160888672\n",
      "Epoch: 1180\n",
      "\tTrain Loss: 4.240 | Train PPL:  69.406\n",
      "\tVal Loss: 3.989 |  Val PPL:  53.979\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.231931686401367\n",
      "Epoch: 1181\n",
      "\tTrain Loss: 4.232 | Train PPL:  68.850\n",
      "\tVal Loss: 3.989 |  Val PPL:  54.028\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.241527080535889\n",
      "Epoch: 1182\n",
      "\tTrain Loss: 4.242 | Train PPL:  69.514\n",
      "\tVal Loss: 3.990 |  Val PPL:  54.054\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.2334370613098145\n",
      "Epoch: 1183\n",
      "\tTrain Loss: 4.233 | Train PPL:  68.954\n",
      "\tVal Loss: 3.989 |  Val PPL:  54.019\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.245425224304199\n",
      "Epoch: 1184\n",
      "\tTrain Loss: 4.245 | Train PPL:  69.785\n",
      "\tVal Loss: 3.989 |  Val PPL:  53.975\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.224097728729248\n",
      "Epoch: 1185\n",
      "\tTrain Loss: 4.224 | Train PPL:  68.313\n",
      "\tVal Loss: 3.987 |  Val PPL:  53.918\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.236059665679932\n",
      "Epoch: 1186\n",
      "\tTrain Loss: 4.236 | Train PPL:  69.135\n",
      "\tVal Loss: 3.984 |  Val PPL:  53.758\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.231170654296875\n",
      "Epoch: 1187\n",
      "\tTrain Loss: 4.231 | Train PPL:  68.798\n",
      "\tVal Loss: 3.982 |  Val PPL:  53.633\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.21070671081543\n",
      "Epoch: 1188\n",
      "\tTrain Loss: 4.211 | Train PPL:  67.404\n",
      "\tVal Loss: 3.981 |  Val PPL:  53.552\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.224298000335693\n",
      "Epoch: 1189\n",
      "\tTrain Loss: 4.224 | Train PPL:  68.327\n",
      "\tVal Loss: 3.980 |  Val PPL:  53.519\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.249873161315918\n",
      "Epoch: 1190\n",
      "\tTrain Loss: 4.250 | Train PPL:  70.097\n",
      "\tVal Loss: 3.980 |  Val PPL:  53.497\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.256606578826904\n",
      "Epoch: 1191\n",
      "\tTrain Loss: 4.257 | Train PPL:  70.570\n",
      "\tVal Loss: 3.979 |  Val PPL:  53.465\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.228400230407715\n",
      "Epoch: 1192\n",
      "\tTrain Loss: 4.228 | Train PPL:  68.607\n",
      "\tVal Loss: 3.979 |  Val PPL:  53.437\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.20700216293335\n",
      "Epoch: 1193\n",
      "\tTrain Loss: 4.207 | Train PPL:  67.155\n",
      "\tVal Loss: 3.978 |  Val PPL:  53.385\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.2117509841918945\n",
      "Epoch: 1194\n",
      "\tTrain Loss: 4.212 | Train PPL:  67.475\n",
      "\tVal Loss: 3.978 |  Val PPL:  53.399\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.221850872039795\n",
      "Epoch: 1195\n",
      "\tTrain Loss: 4.222 | Train PPL:  68.160\n",
      "\tVal Loss: 3.978 |  Val PPL:  53.435\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.207644462585449\n",
      "Epoch: 1196\n",
      "\tTrain Loss: 4.208 | Train PPL:  67.198\n",
      "\tVal Loss: 3.978 |  Val PPL:  53.400\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.21483850479126\n",
      "Epoch: 1197\n",
      "\tTrain Loss: 4.215 | Train PPL:  67.683\n",
      "\tVal Loss: 3.975 |  Val PPL:  53.274\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.2001495361328125\n",
      "Epoch: 1198\n",
      "\tTrain Loss: 4.200 | Train PPL:  66.696\n",
      "\tVal Loss: 3.974 |  Val PPL:  53.193\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.226142406463623\n",
      "Epoch: 1199\n",
      "\tTrain Loss: 4.226 | Train PPL:  68.453\n",
      "\tVal Loss: 3.972 |  Val PPL:  53.086\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.193756103515625\n",
      "Epoch: 1200\n",
      "\tTrain Loss: 4.194 | Train PPL:  66.271\n",
      "\tVal Loss: 3.969 |  Val PPL:  52.943\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.233388423919678\n",
      "Epoch: 1201\n",
      "\tTrain Loss: 4.233 | Train PPL:  68.950\n",
      "\tVal Loss: 3.968 |  Val PPL:  52.868\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.2069525718688965\n",
      "Epoch: 1202\n",
      "\tTrain Loss: 4.207 | Train PPL:  67.152\n",
      "\tVal Loss: 3.966 |  Val PPL:  52.776\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.219367027282715\n",
      "Epoch: 1203\n",
      "\tTrain Loss: 4.219 | Train PPL:  67.990\n",
      "\tVal Loss: 3.965 |  Val PPL:  52.741\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.235823631286621\n",
      "Epoch: 1204\n",
      "\tTrain Loss: 4.236 | Train PPL:  69.119\n",
      "\tVal Loss: 3.965 |  Val PPL:  52.699\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.180217742919922\n",
      "Epoch: 1205\n",
      "\tTrain Loss: 4.180 | Train PPL:  65.380\n",
      "\tVal Loss: 3.965 |  Val PPL:  52.721\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.21599006652832\n",
      "Epoch: 1206\n",
      "\tTrain Loss: 4.216 | Train PPL:  67.761\n",
      "\tVal Loss: 3.966 |  Val PPL:  52.762\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.199869632720947\n",
      "Epoch: 1207\n",
      "\tTrain Loss: 4.200 | Train PPL:  66.678\n",
      "\tVal Loss: 3.968 |  Val PPL:  52.885\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.217828750610352\n",
      "Epoch: 1208\n",
      "\tTrain Loss: 4.218 | Train PPL:  67.886\n",
      "\tVal Loss: 3.969 |  Val PPL:  52.926\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.21872615814209\n",
      "Epoch: 1209\n",
      "\tTrain Loss: 4.219 | Train PPL:  67.947\n",
      "\tVal Loss: 3.966 |  Val PPL:  52.791\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.216556549072266\n",
      "Epoch: 1210\n",
      "\tTrain Loss: 4.217 | Train PPL:  67.800\n",
      "\tVal Loss: 3.962 |  Val PPL:  52.564\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.17931604385376\n",
      "Epoch: 1211\n",
      "\tTrain Loss: 4.179 | Train PPL:  65.321\n",
      "\tVal Loss: 3.958 |  Val PPL:  52.372\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.220325946807861\n",
      "Epoch: 1212\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.056\n",
      "\tVal Loss: 3.956 |  Val PPL:  52.253\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.197010517120361\n",
      "Epoch: 1213\n",
      "\tTrain Loss: 4.197 | Train PPL:  66.487\n",
      "\tVal Loss: 3.954 |  Val PPL:  52.155\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.186183929443359\n",
      "Epoch: 1214\n",
      "\tTrain Loss: 4.186 | Train PPL:  65.771\n",
      "\tVal Loss: 3.953 |  Val PPL:  52.094\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.2140398025512695\n",
      "Epoch: 1215\n",
      "\tTrain Loss: 4.214 | Train PPL:  67.629\n",
      "\tVal Loss: 3.952 |  Val PPL:  52.040\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.21265172958374\n",
      "Epoch: 1216\n",
      "\tTrain Loss: 4.213 | Train PPL:  67.535\n",
      "\tVal Loss: 3.950 |  Val PPL:  51.960\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.206502914428711\n",
      "Epoch: 1217\n",
      "\tTrain Loss: 4.207 | Train PPL:  67.121\n",
      "\tVal Loss: 3.949 |  Val PPL:  51.880\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.201427936553955\n",
      "Epoch: 1218\n",
      "\tTrain Loss: 4.201 | Train PPL:  66.782\n",
      "\tVal Loss: 3.947 |  Val PPL:  51.780\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.194854736328125\n",
      "Epoch: 1219\n",
      "\tTrain Loss: 4.195 | Train PPL:  66.344\n",
      "\tVal Loss: 3.945 |  Val PPL:  51.686\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.186155319213867\n",
      "Epoch: 1220\n",
      "\tTrain Loss: 4.186 | Train PPL:  65.769\n",
      "\tVal Loss: 3.942 |  Val PPL:  51.531\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.19960880279541\n",
      "Epoch: 1221\n",
      "\tTrain Loss: 4.200 | Train PPL:  66.660\n",
      "\tVal Loss: 3.941 |  Val PPL:  51.459\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.181424140930176\n",
      "Epoch: 1222\n",
      "\tTrain Loss: 4.181 | Train PPL:  65.459\n",
      "\tVal Loss: 3.941 |  Val PPL:  51.446\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.205397129058838\n",
      "Epoch: 1223\n",
      "\tTrain Loss: 4.205 | Train PPL:  67.047\n",
      "\tVal Loss: 3.941 |  Val PPL:  51.445\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.205549716949463\n",
      "Epoch: 1224\n",
      "\tTrain Loss: 4.206 | Train PPL:  67.057\n",
      "\tVal Loss: 3.941 |  Val PPL:  51.449\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.184927940368652\n",
      "Epoch: 1225\n",
      "\tTrain Loss: 4.185 | Train PPL:  65.689\n",
      "\tVal Loss: 3.942 |  Val PPL:  51.522\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.202818393707275\n",
      "Epoch: 1226\n",
      "\tTrain Loss: 4.203 | Train PPL:  66.875\n",
      "\tVal Loss: 3.941 |  Val PPL:  51.489\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.203961372375488\n",
      "Epoch: 1227\n",
      "\tTrain Loss: 4.204 | Train PPL:  66.951\n",
      "\tVal Loss: 3.939 |  Val PPL:  51.387\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.197608947753906\n",
      "Epoch: 1228\n",
      "\tTrain Loss: 4.198 | Train PPL:  66.527\n",
      "\tVal Loss: 3.936 |  Val PPL:  51.224\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.183797359466553\n",
      "Epoch: 1229\n",
      "\tTrain Loss: 4.184 | Train PPL:  65.615\n",
      "\tVal Loss: 3.933 |  Val PPL:  51.058\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.208907604217529\n",
      "Epoch: 1230\n",
      "\tTrain Loss: 4.209 | Train PPL:  67.283\n",
      "\tVal Loss: 3.929 |  Val PPL:  50.832\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.192312240600586\n",
      "Epoch: 1231\n",
      "\tTrain Loss: 4.192 | Train PPL:  66.176\n",
      "\tVal Loss: 3.925 |  Val PPL:  50.641\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.170287609100342\n",
      "Epoch: 1232\n",
      "\tTrain Loss: 4.170 | Train PPL:  64.734\n",
      "\tVal Loss: 3.923 |  Val PPL:  50.532\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.1959967613220215\n",
      "Epoch: 1233\n",
      "\tTrain Loss: 4.196 | Train PPL:  66.420\n",
      "\tVal Loss: 3.923 |  Val PPL:  50.544\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.190507888793945\n",
      "Epoch: 1234\n",
      "\tTrain Loss: 4.191 | Train PPL:  66.056\n",
      "\tVal Loss: 3.924 |  Val PPL:  50.613\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.17777681350708\n",
      "Epoch: 1235\n",
      "\tTrain Loss: 4.178 | Train PPL:  65.221\n",
      "\tVal Loss: 3.925 |  Val PPL:  50.631\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.171738147735596\n",
      "Epoch: 1236\n",
      "\tTrain Loss: 4.172 | Train PPL:  64.828\n",
      "\tVal Loss: 3.925 |  Val PPL:  50.646\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.165946006774902\n",
      "Epoch: 1237\n",
      "\tTrain Loss: 4.166 | Train PPL:  64.454\n",
      "\tVal Loss: 3.925 |  Val PPL:  50.675\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.164697170257568\n",
      "Epoch: 1238\n",
      "\tTrain Loss: 4.165 | Train PPL:  64.373\n",
      "\tVal Loss: 3.924 |  Val PPL:  50.604\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.171226978302002\n",
      "Epoch: 1239\n",
      "\tTrain Loss: 4.171 | Train PPL:  64.795\n",
      "\tVal Loss: 3.922 |  Val PPL:  50.497\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.188503265380859\n",
      "Epoch: 1240\n",
      "\tTrain Loss: 4.189 | Train PPL:  65.924\n",
      "\tVal Loss: 3.919 |  Val PPL:  50.349\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.177976131439209\n",
      "Epoch: 1241\n",
      "\tTrain Loss: 4.178 | Train PPL:  65.234\n",
      "\tVal Loss: 3.916 |  Val PPL:  50.174\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.182733535766602\n",
      "Epoch: 1242\n",
      "\tTrain Loss: 4.183 | Train PPL:  65.545\n",
      "\tVal Loss: 3.912 |  Val PPL:  49.990\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.1744303703308105\n",
      "Epoch: 1243\n",
      "\tTrain Loss: 4.174 | Train PPL:  65.003\n",
      "\tVal Loss: 3.908 |  Val PPL:  49.792\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.184690952301025\n",
      "Epoch: 1244\n",
      "\tTrain Loss: 4.185 | Train PPL:  65.673\n",
      "\tVal Loss: 3.906 |  Val PPL:  49.689\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.181097984313965\n",
      "Epoch: 1245\n",
      "\tTrain Loss: 4.181 | Train PPL:  65.438\n",
      "\tVal Loss: 3.905 |  Val PPL:  49.639\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.147168159484863\n",
      "Epoch: 1246\n",
      "\tTrain Loss: 4.147 | Train PPL:  63.255\n",
      "\tVal Loss: 3.905 |  Val PPL:  49.630\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.1601128578186035\n",
      "Epoch: 1247\n",
      "\tTrain Loss: 4.160 | Train PPL:  64.079\n",
      "\tVal Loss: 3.904 |  Val PPL:  49.623\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.153468608856201\n",
      "Epoch: 1248\n",
      "\tTrain Loss: 4.153 | Train PPL:  63.654\n",
      "\tVal Loss: 3.905 |  Val PPL:  49.631\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.1691131591796875\n",
      "Epoch: 1249\n",
      "\tTrain Loss: 4.169 | Train PPL:  64.658\n",
      "\tVal Loss: 3.904 |  Val PPL:  49.591\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.168833255767822\n",
      "Epoch: 1250\n",
      "\tTrain Loss: 4.169 | Train PPL:  64.640\n",
      "\tVal Loss: 3.902 |  Val PPL:  49.505\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.179783821105957\n",
      "Epoch: 1251\n",
      "\tTrain Loss: 4.180 | Train PPL:  65.352\n",
      "\tVal Loss: 3.902 |  Val PPL:  49.479\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.166906356811523\n",
      "Epoch: 1252\n",
      "\tTrain Loss: 4.167 | Train PPL:  64.516\n",
      "\tVal Loss: 3.900 |  Val PPL:  49.414\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.154219150543213\n",
      "Epoch: 1253\n",
      "\tTrain Loss: 4.154 | Train PPL:  63.702\n",
      "\tVal Loss: 3.899 |  Val PPL:  49.332\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.167628765106201\n",
      "Epoch: 1254\n",
      "\tTrain Loss: 4.168 | Train PPL:  64.562\n",
      "\tVal Loss: 3.898 |  Val PPL:  49.289\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.170598030090332\n",
      "Epoch: 1255\n",
      "\tTrain Loss: 4.171 | Train PPL:  64.754\n",
      "\tVal Loss: 3.897 |  Val PPL:  49.246\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.1442484855651855\n",
      "Epoch: 1256\n",
      "\tTrain Loss: 4.144 | Train PPL:  63.070\n",
      "\tVal Loss: 3.897 |  Val PPL:  49.233\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.154078483581543\n",
      "Epoch: 1257\n",
      "\tTrain Loss: 4.154 | Train PPL:  63.693\n",
      "\tVal Loss: 3.896 |  Val PPL:  49.199\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.175849914550781\n",
      "Epoch: 1258\n",
      "\tTrain Loss: 4.176 | Train PPL:  65.095\n",
      "\tVal Loss: 3.896 |  Val PPL:  49.188\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.1436076164245605\n",
      "Epoch: 1259\n",
      "\tTrain Loss: 4.144 | Train PPL:  63.030\n",
      "\tVal Loss: 3.896 |  Val PPL:  49.218\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.1694183349609375\n",
      "Epoch: 1260\n",
      "\tTrain Loss: 4.169 | Train PPL:  64.678\n",
      "\tVal Loss: 3.898 |  Val PPL:  49.286\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.138103008270264\n",
      "Epoch: 1261\n",
      "\tTrain Loss: 4.138 | Train PPL:  62.684\n",
      "\tVal Loss: 3.897 |  Val PPL:  49.235\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.171253204345703\n",
      "Epoch: 1262\n",
      "\tTrain Loss: 4.171 | Train PPL:  64.797\n",
      "\tVal Loss: 3.893 |  Val PPL:  49.077\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.170995712280273\n",
      "Epoch: 1263\n",
      "\tTrain Loss: 4.171 | Train PPL:  64.780\n",
      "\tVal Loss: 3.890 |  Val PPL:  48.913\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.130191326141357\n",
      "Epoch: 1264\n",
      "\tTrain Loss: 4.130 | Train PPL:  62.190\n",
      "\tVal Loss: 3.888 |  Val PPL:  48.830\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.175388336181641\n",
      "Epoch: 1265\n",
      "\tTrain Loss: 4.175 | Train PPL:  65.065\n",
      "\tVal Loss: 3.887 |  Val PPL:  48.784\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.131772994995117\n",
      "Epoch: 1266\n",
      "\tTrain Loss: 4.132 | Train PPL:  62.288\n",
      "\tVal Loss: 3.887 |  Val PPL:  48.782\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.172793388366699\n",
      "Epoch: 1267\n",
      "\tTrain Loss: 4.173 | Train PPL:  64.896\n",
      "\tVal Loss: 3.888 |  Val PPL:  48.822\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.1458210945129395\n",
      "Epoch: 1268\n",
      "\tTrain Loss: 4.146 | Train PPL:  63.169\n",
      "\tVal Loss: 3.889 |  Val PPL:  48.849\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.150827407836914\n",
      "Epoch: 1269\n",
      "\tTrain Loss: 4.151 | Train PPL:  63.487\n",
      "\tVal Loss: 3.889 |  Val PPL:  48.863\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.150516986846924\n",
      "Epoch: 1270\n",
      "\tTrain Loss: 4.151 | Train PPL:  63.467\n",
      "\tVal Loss: 3.887 |  Val PPL:  48.783\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.183737754821777\n",
      "Epoch: 1271\n",
      "\tTrain Loss: 4.184 | Train PPL:  65.611\n",
      "\tVal Loss: 3.884 |  Val PPL:  48.614\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.144749641418457\n",
      "Epoch: 1272\n",
      "\tTrain Loss: 4.145 | Train PPL:  63.102\n",
      "\tVal Loss: 3.880 |  Val PPL:  48.443\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.150371551513672\n",
      "Epoch: 1273\n",
      "\tTrain Loss: 4.150 | Train PPL:  63.458\n",
      "\tVal Loss: 3.878 |  Val PPL:  48.334\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.142604827880859\n",
      "Epoch: 1274\n",
      "\tTrain Loss: 4.143 | Train PPL:  62.967\n",
      "\tVal Loss: 3.877 |  Val PPL:  48.293\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.141787528991699\n",
      "Epoch: 1275\n",
      "\tTrain Loss: 4.142 | Train PPL:  62.915\n",
      "\tVal Loss: 3.878 |  Val PPL:  48.306\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.129629611968994\n",
      "Epoch: 1276\n",
      "\tTrain Loss: 4.130 | Train PPL:  62.155\n",
      "\tVal Loss: 3.878 |  Val PPL:  48.315\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.139811992645264\n",
      "Epoch: 1277\n",
      "\tTrain Loss: 4.140 | Train PPL:  62.791\n",
      "\tVal Loss: 3.878 |  Val PPL:  48.337\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.129532814025879\n",
      "Epoch: 1278\n",
      "\tTrain Loss: 4.130 | Train PPL:  62.149\n",
      "\tVal Loss: 3.879 |  Val PPL:  48.369\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.122207164764404\n",
      "Epoch: 1279\n",
      "\tTrain Loss: 4.122 | Train PPL:  61.695\n",
      "\tVal Loss: 3.881 |  Val PPL:  48.474\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.129040718078613\n",
      "Epoch: 1280\n",
      "\tTrain Loss: 4.129 | Train PPL:  62.118\n",
      "\tVal Loss: 3.882 |  Val PPL:  48.498\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.10468053817749\n",
      "Epoch: 1281\n",
      "\tTrain Loss: 4.105 | Train PPL:  60.623\n",
      "\tVal Loss: 3.879 |  Val PPL:  48.372\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.125332832336426\n",
      "Epoch: 1282\n",
      "\tTrain Loss: 4.125 | Train PPL:  61.888\n",
      "\tVal Loss: 3.874 |  Val PPL:  48.157\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.155426979064941\n",
      "Epoch: 1283\n",
      "\tTrain Loss: 4.155 | Train PPL:  63.779\n",
      "\tVal Loss: 3.871 |  Val PPL:  48.006\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.135480880737305\n",
      "Epoch: 1284\n",
      "\tTrain Loss: 4.135 | Train PPL:  62.520\n",
      "\tVal Loss: 3.868 |  Val PPL:  47.857\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.117889404296875\n",
      "Epoch: 1285\n",
      "\tTrain Loss: 4.118 | Train PPL:  61.429\n",
      "\tVal Loss: 3.866 |  Val PPL:  47.740\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.152223110198975\n",
      "Epoch: 1286\n",
      "\tTrain Loss: 4.152 | Train PPL:  63.575\n",
      "\tVal Loss: 3.864 |  Val PPL:  47.674\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.116885662078857\n",
      "Epoch: 1287\n",
      "\tTrain Loss: 4.117 | Train PPL:  61.368\n",
      "\tVal Loss: 3.863 |  Val PPL:  47.609\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.11984920501709\n",
      "Epoch: 1288\n",
      "\tTrain Loss: 4.120 | Train PPL:  61.550\n",
      "\tVal Loss: 3.863 |  Val PPL:  47.598\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.096107482910156\n",
      "Epoch: 1289\n",
      "\tTrain Loss: 4.096 | Train PPL:  60.106\n",
      "\tVal Loss: 3.861 |  Val PPL:  47.530\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.109573841094971\n",
      "Epoch: 1290\n",
      "\tTrain Loss: 4.110 | Train PPL:  60.921\n",
      "\tVal Loss: 3.859 |  Val PPL:  47.417\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.095122337341309\n",
      "Epoch: 1291\n",
      "\tTrain Loss: 4.095 | Train PPL:  60.047\n",
      "\tVal Loss: 3.855 |  Val PPL:  47.248\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.133877754211426\n",
      "Epoch: 1292\n",
      "\tTrain Loss: 4.134 | Train PPL:  62.420\n",
      "\tVal Loss: 3.854 |  Val PPL:  47.203\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.1196746826171875\n",
      "Epoch: 1293\n",
      "\tTrain Loss: 4.120 | Train PPL:  61.539\n",
      "\tVal Loss: 3.853 |  Val PPL:  47.116\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.14601469039917\n",
      "Epoch: 1294\n",
      "\tTrain Loss: 4.146 | Train PPL:  63.182\n",
      "\tVal Loss: 3.851 |  Val PPL:  47.030\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.103684425354004\n",
      "Epoch: 1295\n",
      "\tTrain Loss: 4.104 | Train PPL:  60.563\n",
      "\tVal Loss: 3.849 |  Val PPL:  46.955\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.137998580932617\n",
      "Epoch: 1296\n",
      "\tTrain Loss: 4.138 | Train PPL:  62.677\n",
      "\tVal Loss: 3.847 |  Val PPL:  46.858\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.113193035125732\n",
      "Epoch: 1297\n",
      "\tTrain Loss: 4.113 | Train PPL:  61.142\n",
      "\tVal Loss: 3.845 |  Val PPL:  46.780\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.103166103363037\n",
      "Epoch: 1298\n",
      "\tTrain Loss: 4.103 | Train PPL:  60.532\n",
      "\tVal Loss: 3.843 |  Val PPL:  46.645\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.08864688873291\n",
      "Epoch: 1299\n",
      "\tTrain Loss: 4.089 | Train PPL:  59.659\n",
      "\tVal Loss: 3.839 |  Val PPL:  46.472\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.119297504425049\n",
      "Epoch: 1300\n",
      "\tTrain Loss: 4.119 | Train PPL:  61.516\n",
      "\tVal Loss: 3.836 |  Val PPL:  46.343\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.141030788421631\n",
      "Epoch: 1301\n",
      "\tTrain Loss: 4.141 | Train PPL:  62.868\n",
      "\tVal Loss: 3.835 |  Val PPL:  46.288\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.077763080596924\n",
      "Epoch: 1302\n",
      "\tTrain Loss: 4.078 | Train PPL:  59.013\n",
      "\tVal Loss: 3.835 |  Val PPL:  46.315\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.096542835235596\n",
      "Epoch: 1303\n",
      "\tTrain Loss: 4.097 | Train PPL:  60.132\n",
      "\tVal Loss: 3.838 |  Val PPL:  46.415\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.115325927734375\n",
      "Epoch: 1304\n",
      "\tTrain Loss: 4.115 | Train PPL:  61.272\n",
      "\tVal Loss: 3.839 |  Val PPL:  46.481\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.08081579208374\n",
      "Epoch: 1305\n",
      "\tTrain Loss: 4.081 | Train PPL:  59.194\n",
      "\tVal Loss: 3.841 |  Val PPL:  46.580\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.108652591705322\n",
      "Epoch: 1306\n",
      "\tTrain Loss: 4.109 | Train PPL:  60.865\n",
      "\tVal Loss: 3.844 |  Val PPL:  46.692\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.103168487548828\n",
      "Epoch: 1307\n",
      "\tTrain Loss: 4.103 | Train PPL:  60.532\n",
      "\tVal Loss: 3.846 |  Val PPL:  46.809\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.108280181884766\n",
      "Epoch: 1308\n",
      "\tTrain Loss: 4.108 | Train PPL:  60.842\n",
      "\tVal Loss: 3.845 |  Val PPL:  46.779\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.124243259429932\n",
      "Epoch: 1309\n",
      "\tTrain Loss: 4.124 | Train PPL:  61.821\n",
      "\tVal Loss: 3.844 |  Val PPL:  46.697\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.115132808685303\n",
      "Epoch: 1310\n",
      "\tTrain Loss: 4.115 | Train PPL:  61.260\n",
      "\tVal Loss: 3.841 |  Val PPL:  46.572\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.1363396644592285\n",
      "Epoch: 1311\n",
      "\tTrain Loss: 4.136 | Train PPL:  62.573\n",
      "\tVal Loss: 3.836 |  Val PPL:  46.339\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.103107452392578\n",
      "Epoch: 1312\n",
      "\tTrain Loss: 4.103 | Train PPL:  60.528\n",
      "\tVal Loss: 3.832 |  Val PPL:  46.150\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.099147319793701\n",
      "Epoch: 1313\n",
      "\tTrain Loss: 4.099 | Train PPL:  60.289\n",
      "\tVal Loss: 3.829 |  Val PPL:  46.016\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.082894802093506\n",
      "Epoch: 1314\n",
      "\tTrain Loss: 4.083 | Train PPL:  59.317\n",
      "\tVal Loss: 3.828 |  Val PPL:  45.974\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.074766635894775\n",
      "Epoch: 1315\n",
      "\tTrain Loss: 4.075 | Train PPL:  58.837\n",
      "\tVal Loss: 3.827 |  Val PPL:  45.943\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.103686809539795\n",
      "Epoch: 1316\n",
      "\tTrain Loss: 4.104 | Train PPL:  60.563\n",
      "\tVal Loss: 3.827 |  Val PPL:  45.928\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.131816864013672\n",
      "Epoch: 1317\n",
      "\tTrain Loss: 4.132 | Train PPL:  62.291\n",
      "\tVal Loss: 3.826 |  Val PPL:  45.883\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.095794200897217\n",
      "Epoch: 1318\n",
      "\tTrain Loss: 4.096 | Train PPL:  60.087\n",
      "\tVal Loss: 3.825 |  Val PPL:  45.814\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.076374053955078\n",
      "Epoch: 1319\n",
      "\tTrain Loss: 4.076 | Train PPL:  58.931\n",
      "\tVal Loss: 3.823 |  Val PPL:  45.747\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.059138298034668\n",
      "Epoch: 1320\n",
      "\tTrain Loss: 4.059 | Train PPL:  57.924\n",
      "\tVal Loss: 3.822 |  Val PPL:  45.712\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.095184326171875\n",
      "Epoch: 1321\n",
      "\tTrain Loss: 4.095 | Train PPL:  60.050\n",
      "\tVal Loss: 3.822 |  Val PPL:  45.695\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.070116996765137\n",
      "Epoch: 1322\n",
      "\tTrain Loss: 4.070 | Train PPL:  58.564\n",
      "\tVal Loss: 3.821 |  Val PPL:  45.636\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.091455936431885\n",
      "Epoch: 1323\n",
      "\tTrain Loss: 4.091 | Train PPL:  59.827\n",
      "\tVal Loss: 3.818 |  Val PPL:  45.534\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.093376636505127\n",
      "Epoch: 1324\n",
      "\tTrain Loss: 4.093 | Train PPL:  59.942\n",
      "\tVal Loss: 3.817 |  Val PPL:  45.446\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.087655544281006\n",
      "Epoch: 1325\n",
      "\tTrain Loss: 4.088 | Train PPL:  59.600\n",
      "\tVal Loss: 3.816 |  Val PPL:  45.408\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.096529006958008\n",
      "Epoch: 1326\n",
      "\tTrain Loss: 4.097 | Train PPL:  60.131\n",
      "\tVal Loss: 3.816 |  Val PPL:  45.420\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.103369235992432\n",
      "Epoch: 1327\n",
      "\tTrain Loss: 4.103 | Train PPL:  60.544\n",
      "\tVal Loss: 3.817 |  Val PPL:  45.475\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.121935844421387\n",
      "Epoch: 1328\n",
      "\tTrain Loss: 4.122 | Train PPL:  61.679\n",
      "\tVal Loss: 3.817 |  Val PPL:  45.485\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.091281890869141\n",
      "Epoch: 1329\n",
      "\tTrain Loss: 4.091 | Train PPL:  59.817\n",
      "\tVal Loss: 3.816 |  Val PPL:  45.436\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.096083164215088\n",
      "Epoch: 1330\n",
      "\tTrain Loss: 4.096 | Train PPL:  60.104\n",
      "\tVal Loss: 3.816 |  Val PPL:  45.412\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.090719223022461\n",
      "Epoch: 1331\n",
      "\tTrain Loss: 4.091 | Train PPL:  59.783\n",
      "\tVal Loss: 3.817 |  Val PPL:  45.450\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.0879693031311035\n",
      "Epoch: 1332\n",
      "\tTrain Loss: 4.088 | Train PPL:  59.619\n",
      "\tVal Loss: 3.819 |  Val PPL:  45.548\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.083422660827637\n",
      "Epoch: 1333\n",
      "\tTrain Loss: 4.083 | Train PPL:  59.348\n",
      "\tVal Loss: 3.821 |  Val PPL:  45.660\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.08626651763916\n",
      "Epoch: 1334\n",
      "\tTrain Loss: 4.086 | Train PPL:  59.517\n",
      "\tVal Loss: 3.824 |  Val PPL:  45.793\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.098606109619141\n",
      "Epoch: 1335\n",
      "\tTrain Loss: 4.099 | Train PPL:  60.256\n",
      "\tVal Loss: 3.820 |  Val PPL:  45.608\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.118252277374268\n",
      "Epoch: 1336\n",
      "\tTrain Loss: 4.118 | Train PPL:  61.452\n",
      "\tVal Loss: 3.814 |  Val PPL:  45.347\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.058721542358398\n",
      "Epoch: 1337\n",
      "\tTrain Loss: 4.059 | Train PPL:  57.900\n",
      "\tVal Loss: 3.810 |  Val PPL:  45.169\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.086051940917969\n",
      "Epoch: 1338\n",
      "\tTrain Loss: 4.086 | Train PPL:  59.505\n",
      "\tVal Loss: 3.805 |  Val PPL:  44.928\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.089456081390381\n",
      "Epoch: 1339\n",
      "\tTrain Loss: 4.089 | Train PPL:  59.707\n",
      "\tVal Loss: 3.800 |  Val PPL:  44.716\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.086048603057861\n",
      "Epoch: 1340\n",
      "\tTrain Loss: 4.086 | Train PPL:  59.504\n",
      "\tVal Loss: 3.796 |  Val PPL:  44.514\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.080224514007568\n",
      "Epoch: 1341\n",
      "\tTrain Loss: 4.080 | Train PPL:  59.159\n",
      "\tVal Loss: 3.794 |  Val PPL:  44.432\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.092833995819092\n",
      "Epoch: 1342\n",
      "\tTrain Loss: 4.093 | Train PPL:  59.909\n",
      "\tVal Loss: 3.792 |  Val PPL:  44.329\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.108162879943848\n",
      "Epoch: 1343\n",
      "\tTrain Loss: 4.108 | Train PPL:  60.835\n",
      "\tVal Loss: 3.788 |  Val PPL:  44.177\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.082508563995361\n",
      "Epoch: 1344\n",
      "\tTrain Loss: 4.083 | Train PPL:  59.294\n",
      "\tVal Loss: 3.785 |  Val PPL:  44.038\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.074195861816406\n",
      "Epoch: 1345\n",
      "\tTrain Loss: 4.074 | Train PPL:  58.803\n",
      "\tVal Loss: 3.784 |  Val PPL:  43.990\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.045594692230225\n",
      "Epoch: 1346\n",
      "\tTrain Loss: 4.046 | Train PPL:  57.145\n",
      "\tVal Loss: 3.785 |  Val PPL:  44.022\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.060016632080078\n",
      "Epoch: 1347\n",
      "\tTrain Loss: 4.060 | Train PPL:  57.975\n",
      "\tVal Loss: 3.787 |  Val PPL:  44.114\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.031279563903809\n",
      "Epoch: 1348\n",
      "\tTrain Loss: 4.031 | Train PPL:  56.333\n",
      "\tVal Loss: 3.789 |  Val PPL:  44.228\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.080683708190918\n",
      "Epoch: 1349\n",
      "\tTrain Loss: 4.081 | Train PPL:  59.186\n",
      "\tVal Loss: 3.792 |  Val PPL:  44.334\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.082035064697266\n",
      "Epoch: 1350\n",
      "\tTrain Loss: 4.082 | Train PPL:  59.266\n",
      "\tVal Loss: 3.795 |  Val PPL:  44.483\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.080618858337402\n",
      "Epoch: 1351\n",
      "\tTrain Loss: 4.081 | Train PPL:  59.182\n",
      "\tVal Loss: 3.799 |  Val PPL:  44.652\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.089827060699463\n",
      "Epoch: 1352\n",
      "\tTrain Loss: 4.090 | Train PPL:  59.730\n",
      "\tVal Loss: 3.801 |  Val PPL:  44.738\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.051541805267334\n",
      "Epoch: 1353\n",
      "\tTrain Loss: 4.052 | Train PPL:  57.486\n",
      "\tVal Loss: 3.800 |  Val PPL:  44.713\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.0488667488098145\n",
      "Epoch: 1354\n",
      "\tTrain Loss: 4.049 | Train PPL:  57.332\n",
      "\tVal Loss: 3.798 |  Val PPL:  44.598\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.048133373260498\n",
      "Epoch: 1355\n",
      "\tTrain Loss: 4.048 | Train PPL:  57.290\n",
      "\tVal Loss: 3.793 |  Val PPL:  44.405\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.063576698303223\n",
      "Epoch: 1356\n",
      "\tTrain Loss: 4.064 | Train PPL:  58.182\n",
      "\tVal Loss: 3.789 |  Val PPL:  44.193\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.0716166496276855\n",
      "Epoch: 1357\n",
      "\tTrain Loss: 4.072 | Train PPL:  58.652\n",
      "\tVal Loss: 3.784 |  Val PPL:  43.976\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.043033123016357\n",
      "Epoch: 1358\n",
      "\tTrain Loss: 4.043 | Train PPL:  56.999\n",
      "\tVal Loss: 3.779 |  Val PPL:  43.766\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.072819709777832\n",
      "Epoch: 1359\n",
      "\tTrain Loss: 4.073 | Train PPL:  58.722\n",
      "\tVal Loss: 3.775 |  Val PPL:  43.599\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.0560760498046875\n",
      "Epoch: 1360\n",
      "\tTrain Loss: 4.056 | Train PPL:  57.747\n",
      "\tVal Loss: 3.771 |  Val PPL:  43.439\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.060082912445068\n",
      "Epoch: 1361\n",
      "\tTrain Loss: 4.060 | Train PPL:  57.979\n",
      "\tVal Loss: 3.769 |  Val PPL:  43.330\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.081234931945801\n",
      "Epoch: 1362\n",
      "\tTrain Loss: 4.081 | Train PPL:  59.219\n",
      "\tVal Loss: 3.768 |  Val PPL:  43.306\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.054747581481934\n",
      "Epoch: 1363\n",
      "\tTrain Loss: 4.055 | Train PPL:  57.671\n",
      "\tVal Loss: 3.769 |  Val PPL:  43.334\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.0597453117370605\n",
      "Epoch: 1364\n",
      "\tTrain Loss: 4.060 | Train PPL:  57.960\n",
      "\tVal Loss: 3.771 |  Val PPL:  43.443\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.065716743469238\n",
      "Epoch: 1365\n",
      "\tTrain Loss: 4.066 | Train PPL:  58.307\n",
      "\tVal Loss: 3.774 |  Val PPL:  43.571\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.031535625457764\n",
      "Epoch: 1366\n",
      "\tTrain Loss: 4.032 | Train PPL:  56.347\n",
      "\tVal Loss: 3.775 |  Val PPL:  43.607\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.065866470336914\n",
      "Epoch: 1367\n",
      "\tTrain Loss: 4.066 | Train PPL:  58.315\n",
      "\tVal Loss: 3.774 |  Val PPL:  43.569\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.071470737457275\n",
      "Epoch: 1368\n",
      "\tTrain Loss: 4.071 | Train PPL:  58.643\n",
      "\tVal Loss: 3.774 |  Val PPL:  43.554\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.059056282043457\n",
      "Epoch: 1369\n",
      "\tTrain Loss: 4.059 | Train PPL:  57.920\n",
      "\tVal Loss: 3.773 |  Val PPL:  43.515\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.063348293304443\n",
      "Epoch: 1370\n",
      "\tTrain Loss: 4.063 | Train PPL:  58.169\n",
      "\tVal Loss: 3.772 |  Val PPL:  43.454\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.066020965576172\n",
      "Epoch: 1371\n",
      "\tTrain Loss: 4.066 | Train PPL:  58.324\n",
      "\tVal Loss: 3.770 |  Val PPL:  43.377\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.074456214904785\n",
      "Epoch: 1372\n",
      "\tTrain Loss: 4.074 | Train PPL:  58.818\n",
      "\tVal Loss: 3.768 |  Val PPL:  43.281\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.052275657653809\n",
      "Epoch: 1373\n",
      "\tTrain Loss: 4.052 | Train PPL:  57.528\n",
      "\tVal Loss: 3.765 |  Val PPL:  43.157\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.0623393058776855\n",
      "Epoch: 1374\n",
      "\tTrain Loss: 4.062 | Train PPL:  58.110\n",
      "\tVal Loss: 3.763 |  Val PPL:  43.085\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.0550031661987305\n",
      "Epoch: 1375\n",
      "\tTrain Loss: 4.055 | Train PPL:  57.685\n",
      "\tVal Loss: 3.762 |  Val PPL:  43.052\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.054438591003418\n",
      "Epoch: 1376\n",
      "\tTrain Loss: 4.054 | Train PPL:  57.653\n",
      "\tVal Loss: 3.762 |  Val PPL:  43.024\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.033139705657959\n",
      "Epoch: 1377\n",
      "\tTrain Loss: 4.033 | Train PPL:  56.438\n",
      "\tVal Loss: 3.761 |  Val PPL:  43.006\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.040429592132568\n",
      "Epoch: 1378\n",
      "\tTrain Loss: 4.040 | Train PPL:  56.851\n",
      "\tVal Loss: 3.760 |  Val PPL:  42.962\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.038596153259277\n",
      "Epoch: 1379\n",
      "\tTrain Loss: 4.039 | Train PPL:  56.747\n",
      "\tVal Loss: 3.759 |  Val PPL:  42.905\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.039572715759277\n",
      "Epoch: 1380\n",
      "\tTrain Loss: 4.040 | Train PPL:  56.802\n",
      "\tVal Loss: 3.757 |  Val PPL:  42.819\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.037536144256592\n",
      "Epoch: 1381\n",
      "\tTrain Loss: 4.038 | Train PPL:  56.687\n",
      "\tVal Loss: 3.756 |  Val PPL:  42.797\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.021371364593506\n",
      "Epoch: 1382\n",
      "\tTrain Loss: 4.021 | Train PPL:  55.778\n",
      "\tVal Loss: 3.756 |  Val PPL:  42.796\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.068583011627197\n",
      "Epoch: 1383\n",
      "\tTrain Loss: 4.069 | Train PPL:  58.474\n",
      "\tVal Loss: 3.757 |  Val PPL:  42.832\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.051928520202637\n",
      "Epoch: 1384\n",
      "\tTrain Loss: 4.052 | Train PPL:  57.508\n",
      "\tVal Loss: 3.758 |  Val PPL:  42.884\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.021749019622803\n",
      "Epoch: 1385\n",
      "\tTrain Loss: 4.022 | Train PPL:  55.799\n",
      "\tVal Loss: 3.761 |  Val PPL:  42.971\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.0131707191467285\n",
      "Epoch: 1386\n",
      "\tTrain Loss: 4.013 | Train PPL:  55.322\n",
      "\tVal Loss: 3.762 |  Val PPL:  43.054\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.025864601135254\n",
      "Epoch: 1387\n",
      "\tTrain Loss: 4.026 | Train PPL:  56.029\n",
      "\tVal Loss: 3.764 |  Val PPL:  43.130\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.048734664916992\n",
      "Epoch: 1388\n",
      "\tTrain Loss: 4.049 | Train PPL:  57.325\n",
      "\tVal Loss: 3.765 |  Val PPL:  43.172\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.034185409545898\n",
      "Epoch: 1389\n",
      "\tTrain Loss: 4.034 | Train PPL:  56.497\n",
      "\tVal Loss: 3.764 |  Val PPL:  43.135\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.022134780883789\n",
      "Epoch: 1390\n",
      "\tTrain Loss: 4.022 | Train PPL:  55.820\n",
      "\tVal Loss: 3.763 |  Val PPL:  43.061\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.04188346862793\n",
      "Epoch: 1391\n",
      "\tTrain Loss: 4.042 | Train PPL:  56.933\n",
      "\tVal Loss: 3.759 |  Val PPL:  42.919\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.016932010650635\n",
      "Epoch: 1392\n",
      "\tTrain Loss: 4.017 | Train PPL:  55.530\n",
      "\tVal Loss: 3.757 |  Val PPL:  42.816\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.011434555053711\n",
      "Epoch: 1393\n",
      "\tTrain Loss: 4.011 | Train PPL:  55.226\n",
      "\tVal Loss: 3.754 |  Val PPL:  42.687\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9951226711273193\n",
      "Epoch: 1394\n",
      "\tTrain Loss: 3.995 | Train PPL:  54.333\n",
      "\tVal Loss: 3.751 |  Val PPL:  42.566\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.018955230712891\n",
      "Epoch: 1395\n",
      "\tTrain Loss: 4.019 | Train PPL:  55.643\n",
      "\tVal Loss: 3.749 |  Val PPL:  42.471\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.0329270362854\n",
      "Epoch: 1396\n",
      "\tTrain Loss: 4.033 | Train PPL:  56.426\n",
      "\tVal Loss: 3.747 |  Val PPL:  42.378\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.037236213684082\n",
      "Epoch: 1397\n",
      "\tTrain Loss: 4.037 | Train PPL:  56.670\n",
      "\tVal Loss: 3.744 |  Val PPL:  42.259\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.062388896942139\n",
      "Epoch: 1398\n",
      "\tTrain Loss: 4.062 | Train PPL:  58.113\n",
      "\tVal Loss: 3.742 |  Val PPL:  42.168\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.042916774749756\n",
      "Epoch: 1399\n",
      "\tTrain Loss: 4.043 | Train PPL:  56.992\n",
      "\tVal Loss: 3.741 |  Val PPL:  42.138\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.011828422546387\n",
      "Epoch: 1400\n",
      "\tTrain Loss: 4.012 | Train PPL:  55.248\n",
      "\tVal Loss: 3.741 |  Val PPL:  42.158\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.016035079956055\n",
      "Epoch: 1401\n",
      "\tTrain Loss: 4.016 | Train PPL:  55.481\n",
      "\tVal Loss: 3.742 |  Val PPL:  42.180\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.034367561340332\n",
      "Epoch: 1402\n",
      "\tTrain Loss: 4.034 | Train PPL:  56.507\n",
      "\tVal Loss: 3.743 |  Val PPL:  42.206\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.981952428817749\n",
      "Epoch: 1403\n",
      "\tTrain Loss: 3.982 | Train PPL:  53.622\n",
      "\tVal Loss: 3.742 |  Val PPL:  42.176\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.032327175140381\n",
      "Epoch: 1404\n",
      "\tTrain Loss: 4.032 | Train PPL:  56.392\n",
      "\tVal Loss: 3.741 |  Val PPL:  42.126\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.010996341705322\n",
      "Epoch: 1405\n",
      "\tTrain Loss: 4.011 | Train PPL:  55.202\n",
      "\tVal Loss: 3.740 |  Val PPL:  42.112\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.026273250579834\n",
      "Epoch: 1406\n",
      "\tTrain Loss: 4.026 | Train PPL:  56.052\n",
      "\tVal Loss: 3.740 |  Val PPL:  42.102\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9798595905303955\n",
      "Epoch: 1407\n",
      "\tTrain Loss: 3.980 | Train PPL:  53.510\n",
      "\tVal Loss: 3.738 |  Val PPL:  42.015\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.015172481536865\n",
      "Epoch: 1408\n",
      "\tTrain Loss: 4.015 | Train PPL:  55.433\n",
      "\tVal Loss: 3.735 |  Val PPL:  41.899\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.0045976638793945\n",
      "Epoch: 1409\n",
      "\tTrain Loss: 4.005 | Train PPL:  54.850\n",
      "\tVal Loss: 3.733 |  Val PPL:  41.789\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9869701862335205\n",
      "Epoch: 1410\n",
      "\tTrain Loss: 3.987 | Train PPL:  53.891\n",
      "\tVal Loss: 3.732 |  Val PPL:  41.745\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.010622024536133\n",
      "Epoch: 1411\n",
      "\tTrain Loss: 4.011 | Train PPL:  55.181\n",
      "\tVal Loss: 3.731 |  Val PPL:  41.724\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.014132976531982\n",
      "Epoch: 1412\n",
      "\tTrain Loss: 4.014 | Train PPL:  55.375\n",
      "\tVal Loss: 3.730 |  Val PPL:  41.668\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.019208908081055\n",
      "Epoch: 1413\n",
      "\tTrain Loss: 4.019 | Train PPL:  55.657\n",
      "\tVal Loss: 3.728 |  Val PPL:  41.599\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.037851810455322\n",
      "Epoch: 1414\n",
      "\tTrain Loss: 4.038 | Train PPL:  56.704\n",
      "\tVal Loss: 3.727 |  Val PPL:  41.535\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.016756534576416\n",
      "Epoch: 1415\n",
      "\tTrain Loss: 4.017 | Train PPL:  55.521\n",
      "\tVal Loss: 3.727 |  Val PPL:  41.575\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.034287929534912\n",
      "Epoch: 1416\n",
      "\tTrain Loss: 4.034 | Train PPL:  56.503\n",
      "\tVal Loss: 3.729 |  Val PPL:  41.649\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.014087200164795\n",
      "Epoch: 1417\n",
      "\tTrain Loss: 4.014 | Train PPL:  55.373\n",
      "\tVal Loss: 3.728 |  Val PPL:  41.610\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.0235185623168945\n",
      "Epoch: 1418\n",
      "\tTrain Loss: 4.024 | Train PPL:  55.897\n",
      "\tVal Loss: 3.726 |  Val PPL:  41.523\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.041801929473877\n",
      "Epoch: 1419\n",
      "\tTrain Loss: 4.042 | Train PPL:  56.929\n",
      "\tVal Loss: 3.725 |  Val PPL:  41.476\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.013717174530029\n",
      "Epoch: 1420\n",
      "\tTrain Loss: 4.014 | Train PPL:  55.352\n",
      "\tVal Loss: 3.725 |  Val PPL:  41.487\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.012139797210693\n",
      "Epoch: 1421\n",
      "\tTrain Loss: 4.012 | Train PPL:  55.265\n",
      "\tVal Loss: 3.726 |  Val PPL:  41.505\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.003428936004639\n",
      "Epoch: 1422\n",
      "\tTrain Loss: 4.003 | Train PPL:  54.786\n",
      "\tVal Loss: 3.726 |  Val PPL:  41.496\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.991485118865967\n",
      "Epoch: 1423\n",
      "\tTrain Loss: 3.991 | Train PPL:  54.135\n",
      "\tVal Loss: 3.724 |  Val PPL:  41.418\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.019976615905762\n",
      "Epoch: 1424\n",
      "\tTrain Loss: 4.020 | Train PPL:  55.700\n",
      "\tVal Loss: 3.722 |  Val PPL:  41.354\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.007626056671143\n",
      "Epoch: 1425\n",
      "\tTrain Loss: 4.008 | Train PPL:  55.016\n",
      "\tVal Loss: 3.721 |  Val PPL:  41.300\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.008829593658447\n",
      "Epoch: 1426\n",
      "\tTrain Loss: 4.009 | Train PPL:  55.082\n",
      "\tVal Loss: 3.720 |  Val PPL:  41.262\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.0136542320251465\n",
      "Epoch: 1427\n",
      "\tTrain Loss: 4.014 | Train PPL:  55.349\n",
      "\tVal Loss: 3.718 |  Val PPL:  41.190\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.997833013534546\n",
      "Epoch: 1428\n",
      "\tTrain Loss: 3.998 | Train PPL:  54.480\n",
      "\tVal Loss: 3.717 |  Val PPL:  41.138\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9990851879119873\n",
      "Epoch: 1429\n",
      "\tTrain Loss: 3.999 | Train PPL:  54.548\n",
      "\tVal Loss: 3.715 |  Val PPL:  41.062\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.007827281951904\n",
      "Epoch: 1430\n",
      "\tTrain Loss: 4.008 | Train PPL:  55.027\n",
      "\tVal Loss: 3.714 |  Val PPL:  41.009\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.023902893066406\n",
      "Epoch: 1431\n",
      "\tTrain Loss: 4.024 | Train PPL:  55.919\n",
      "\tVal Loss: 3.713 |  Val PPL:  40.957\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.008561134338379\n",
      "Epoch: 1432\n",
      "\tTrain Loss: 4.009 | Train PPL:  55.068\n",
      "\tVal Loss: 3.711 |  Val PPL:  40.887\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.977196455001831\n",
      "Epoch: 1433\n",
      "\tTrain Loss: 3.977 | Train PPL:  53.367\n",
      "\tVal Loss: 3.710 |  Val PPL:  40.842\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9862568378448486\n",
      "Epoch: 1434\n",
      "\tTrain Loss: 3.986 | Train PPL:  53.853\n",
      "\tVal Loss: 3.710 |  Val PPL:  40.872\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.015402317047119\n",
      "Epoch: 1435\n",
      "\tTrain Loss: 4.015 | Train PPL:  55.446\n",
      "\tVal Loss: 3.712 |  Val PPL:  40.920\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.019866943359375\n",
      "Epoch: 1436\n",
      "\tTrain Loss: 4.020 | Train PPL:  55.694\n",
      "\tVal Loss: 3.713 |  Val PPL:  40.970\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.009984016418457\n",
      "Epoch: 1437\n",
      "\tTrain Loss: 4.010 | Train PPL:  55.146\n",
      "\tVal Loss: 3.713 |  Val PPL:  40.994\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9906952381134033\n",
      "Epoch: 1438\n",
      "\tTrain Loss: 3.991 | Train PPL:  54.092\n",
      "\tVal Loss: 3.715 |  Val PPL:  41.046\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.007230758666992\n",
      "Epoch: 1439\n",
      "\tTrain Loss: 4.007 | Train PPL:  54.994\n",
      "\tVal Loss: 3.715 |  Val PPL:  41.063\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9974374771118164\n",
      "Epoch: 1440\n",
      "\tTrain Loss: 3.997 | Train PPL:  54.458\n",
      "\tVal Loss: 3.715 |  Val PPL:  41.079\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.007604598999023\n",
      "Epoch: 1441\n",
      "\tTrain Loss: 4.008 | Train PPL:  55.015\n",
      "\tVal Loss: 3.716 |  Val PPL:  41.088\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9795618057250977\n",
      "Epoch: 1442\n",
      "\tTrain Loss: 3.980 | Train PPL:  53.494\n",
      "\tVal Loss: 3.714 |  Val PPL:  41.008\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.000437259674072\n",
      "Epoch: 1443\n",
      "\tTrain Loss: 4.000 | Train PPL:  54.622\n",
      "\tVal Loss: 3.711 |  Val PPL:  40.914\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9797868728637695\n",
      "Epoch: 1444\n",
      "\tTrain Loss: 3.980 | Train PPL:  53.506\n",
      "\tVal Loss: 3.710 |  Val PPL:  40.870\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9737842082977295\n",
      "Epoch: 1445\n",
      "\tTrain Loss: 3.974 | Train PPL:  53.185\n",
      "\tVal Loss: 3.710 |  Val PPL:  40.850\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9763736724853516\n",
      "Epoch: 1446\n",
      "\tTrain Loss: 3.976 | Train PPL:  53.323\n",
      "\tVal Loss: 3.709 |  Val PPL:  40.819\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.961155891418457\n",
      "Epoch: 1447\n",
      "\tTrain Loss: 3.961 | Train PPL:  52.518\n",
      "\tVal Loss: 3.708 |  Val PPL:  40.773\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.964820623397827\n",
      "Epoch: 1448\n",
      "\tTrain Loss: 3.965 | Train PPL:  52.711\n",
      "\tVal Loss: 3.706 |  Val PPL:  40.680\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9842395782470703\n",
      "Epoch: 1449\n",
      "\tTrain Loss: 3.984 | Train PPL:  53.744\n",
      "\tVal Loss: 3.703 |  Val PPL:  40.556\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.003072738647461\n",
      "Epoch: 1450\n",
      "\tTrain Loss: 4.003 | Train PPL:  54.766\n",
      "\tVal Loss: 3.700 |  Val PPL:  40.453\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.998974561691284\n",
      "Epoch: 1451\n",
      "\tTrain Loss: 3.999 | Train PPL:  54.542\n",
      "\tVal Loss: 3.697 |  Val PPL:  40.346\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9691126346588135\n",
      "Epoch: 1452\n",
      "\tTrain Loss: 3.969 | Train PPL:  52.938\n",
      "\tVal Loss: 3.695 |  Val PPL:  40.264\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.00393533706665\n",
      "Epoch: 1453\n",
      "\tTrain Loss: 4.004 | Train PPL:  54.813\n",
      "\tVal Loss: 3.694 |  Val PPL:  40.209\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.998138189315796\n",
      "Epoch: 1454\n",
      "\tTrain Loss: 3.998 | Train PPL:  54.497\n",
      "\tVal Loss: 3.693 |  Val PPL:  40.182\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.028081893920898\n",
      "Epoch: 1455\n",
      "\tTrain Loss: 4.028 | Train PPL:  56.153\n",
      "\tVal Loss: 3.694 |  Val PPL:  40.219\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9983551502227783\n",
      "Epoch: 1456\n",
      "\tTrain Loss: 3.998 | Train PPL:  54.508\n",
      "\tVal Loss: 3.696 |  Val PPL:  40.301\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9904096126556396\n",
      "Epoch: 1457\n",
      "\tTrain Loss: 3.990 | Train PPL:  54.077\n",
      "\tVal Loss: 3.700 |  Val PPL:  40.436\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9925942420959473\n",
      "Epoch: 1458\n",
      "\tTrain Loss: 3.993 | Train PPL:  54.195\n",
      "\tVal Loss: 3.702 |  Val PPL:  40.533\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.961963176727295\n",
      "Epoch: 1459\n",
      "\tTrain Loss: 3.962 | Train PPL:  52.560\n",
      "\tVal Loss: 3.702 |  Val PPL:  40.530\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9800989627838135\n",
      "Epoch: 1460\n",
      "\tTrain Loss: 3.980 | Train PPL:  53.522\n",
      "\tVal Loss: 3.702 |  Val PPL:  40.539\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.009952068328857\n",
      "Epoch: 1461\n",
      "\tTrain Loss: 4.010 | Train PPL:  55.144\n",
      "\tVal Loss: 3.702 |  Val PPL:  40.536\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9702937602996826\n",
      "Epoch: 1462\n",
      "\tTrain Loss: 3.970 | Train PPL:  53.000\n",
      "\tVal Loss: 3.701 |  Val PPL:  40.474\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 4.00779390335083\n",
      "Epoch: 1463\n",
      "\tTrain Loss: 4.008 | Train PPL:  55.025\n",
      "\tVal Loss: 3.698 |  Val PPL:  40.380\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9785664081573486\n",
      "Epoch: 1464\n",
      "\tTrain Loss: 3.979 | Train PPL:  53.440\n",
      "\tVal Loss: 3.694 |  Val PPL:  40.212\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.996753215789795\n",
      "Epoch: 1465\n",
      "\tTrain Loss: 3.997 | Train PPL:  54.421\n",
      "\tVal Loss: 3.691 |  Val PPL:  40.092\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.962674140930176\n",
      "Epoch: 1466\n",
      "\tTrain Loss: 3.963 | Train PPL:  52.598\n",
      "\tVal Loss: 3.689 |  Val PPL:  39.997\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9679319858551025\n",
      "Epoch: 1467\n",
      "\tTrain Loss: 3.968 | Train PPL:  52.875\n",
      "\tVal Loss: 3.688 |  Val PPL:  39.947\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.942708969116211\n",
      "Epoch: 1468\n",
      "\tTrain Loss: 3.943 | Train PPL:  51.558\n",
      "\tVal Loss: 3.686 |  Val PPL:  39.872\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9761106967926025\n",
      "Epoch: 1469\n",
      "\tTrain Loss: 3.976 | Train PPL:  53.309\n",
      "\tVal Loss: 3.685 |  Val PPL:  39.830\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.965618848800659\n",
      "Epoch: 1470\n",
      "\tTrain Loss: 3.966 | Train PPL:  52.753\n",
      "\tVal Loss: 3.683 |  Val PPL:  39.768\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.953094244003296\n",
      "Epoch: 1471\n",
      "\tTrain Loss: 3.953 | Train PPL:  52.096\n",
      "\tVal Loss: 3.682 |  Val PPL:  39.722\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9563794136047363\n",
      "Epoch: 1472\n",
      "\tTrain Loss: 3.956 | Train PPL:  52.268\n",
      "\tVal Loss: 3.682 |  Val PPL:  39.734\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9743881225585938\n",
      "Epoch: 1473\n",
      "\tTrain Loss: 3.974 | Train PPL:  53.218\n",
      "\tVal Loss: 3.684 |  Val PPL:  39.803\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.973296880722046\n",
      "Epoch: 1474\n",
      "\tTrain Loss: 3.973 | Train PPL:  53.160\n",
      "\tVal Loss: 3.685 |  Val PPL:  39.860\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.963513135910034\n",
      "Epoch: 1475\n",
      "\tTrain Loss: 3.964 | Train PPL:  52.642\n",
      "\tVal Loss: 3.687 |  Val PPL:  39.917\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9731013774871826\n",
      "Epoch: 1476\n",
      "\tTrain Loss: 3.973 | Train PPL:  53.149\n",
      "\tVal Loss: 3.688 |  Val PPL:  39.967\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9726786613464355\n",
      "Epoch: 1477\n",
      "\tTrain Loss: 3.973 | Train PPL:  53.127\n",
      "\tVal Loss: 3.689 |  Val PPL:  40.008\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.982731342315674\n",
      "Epoch: 1478\n",
      "\tTrain Loss: 3.983 | Train PPL:  53.663\n",
      "\tVal Loss: 3.688 |  Val PPL:  39.968\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9652278423309326\n",
      "Epoch: 1479\n",
      "\tTrain Loss: 3.965 | Train PPL:  52.732\n",
      "\tVal Loss: 3.685 |  Val PPL:  39.845\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.960890769958496\n",
      "Epoch: 1480\n",
      "\tTrain Loss: 3.961 | Train PPL:  52.504\n",
      "\tVal Loss: 3.680 |  Val PPL:  39.652\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.965886354446411\n",
      "Epoch: 1481\n",
      "\tTrain Loss: 3.966 | Train PPL:  52.767\n",
      "\tVal Loss: 3.676 |  Val PPL:  39.501\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.957120656967163\n",
      "Epoch: 1482\n",
      "\tTrain Loss: 3.957 | Train PPL:  52.307\n",
      "\tVal Loss: 3.673 |  Val PPL:  39.354\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9686152935028076\n",
      "Epoch: 1483\n",
      "\tTrain Loss: 3.969 | Train PPL:  52.911\n",
      "\tVal Loss: 3.669 |  Val PPL:  39.217\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.996852397918701\n",
      "Epoch: 1484\n",
      "\tTrain Loss: 3.997 | Train PPL:  54.427\n",
      "\tVal Loss: 3.666 |  Val PPL:  39.096\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9607765674591064\n",
      "Epoch: 1485\n",
      "\tTrain Loss: 3.961 | Train PPL:  52.498\n",
      "\tVal Loss: 3.663 |  Val PPL:  38.970\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9833366870880127\n",
      "Epoch: 1486\n",
      "\tTrain Loss: 3.983 | Train PPL:  53.696\n",
      "\tVal Loss: 3.661 |  Val PPL:  38.883\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.986299753189087\n",
      "Epoch: 1487\n",
      "\tTrain Loss: 3.986 | Train PPL:  53.855\n",
      "\tVal Loss: 3.659 |  Val PPL:  38.838\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9779858589172363\n",
      "Epoch: 1488\n",
      "\tTrain Loss: 3.978 | Train PPL:  53.409\n",
      "\tVal Loss: 3.660 |  Val PPL:  38.875\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9650967121124268\n",
      "Epoch: 1489\n",
      "\tTrain Loss: 3.965 | Train PPL:  52.725\n",
      "\tVal Loss: 3.661 |  Val PPL:  38.916\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9468982219696045\n",
      "Epoch: 1490\n",
      "\tTrain Loss: 3.947 | Train PPL:  51.775\n",
      "\tVal Loss: 3.664 |  Val PPL:  39.001\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.971029281616211\n",
      "Epoch: 1491\n",
      "\tTrain Loss: 3.971 | Train PPL:  53.039\n",
      "\tVal Loss: 3.666 |  Val PPL:  39.091\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9685773849487305\n",
      "Epoch: 1492\n",
      "\tTrain Loss: 3.969 | Train PPL:  52.909\n",
      "\tVal Loss: 3.668 |  Val PPL:  39.165\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9642341136932373\n",
      "Epoch: 1493\n",
      "\tTrain Loss: 3.964 | Train PPL:  52.680\n",
      "\tVal Loss: 3.669 |  Val PPL:  39.216\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9479191303253174\n",
      "Epoch: 1494\n",
      "\tTrain Loss: 3.948 | Train PPL:  51.827\n",
      "\tVal Loss: 3.670 |  Val PPL:  39.261\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9722518920898438\n",
      "Epoch: 1495\n",
      "\tTrain Loss: 3.972 | Train PPL:  53.104\n",
      "\tVal Loss: 3.669 |  Val PPL:  39.231\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9447057247161865\n",
      "Epoch: 1496\n",
      "\tTrain Loss: 3.945 | Train PPL:  51.661\n",
      "\tVal Loss: 3.668 |  Val PPL:  39.186\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9600157737731934\n",
      "Epoch: 1497\n",
      "\tTrain Loss: 3.960 | Train PPL:  52.458\n",
      "\tVal Loss: 3.665 |  Val PPL:  39.045\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.930742025375366\n",
      "Epoch: 1498\n",
      "\tTrain Loss: 3.931 | Train PPL:  50.945\n",
      "\tVal Loss: 3.661 |  Val PPL:  38.889\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.982158899307251\n",
      "Epoch: 1499\n",
      "\tTrain Loss: 3.982 | Train PPL:  53.633\n",
      "\tVal Loss: 3.657 |  Val PPL:  38.756\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9551029205322266\n",
      "Epoch: 1500\n",
      "\tTrain Loss: 3.955 | Train PPL:  52.201\n",
      "\tVal Loss: 3.655 |  Val PPL:  38.648\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9257726669311523\n",
      "Epoch: 1501\n",
      "\tTrain Loss: 3.926 | Train PPL:  50.692\n",
      "\tVal Loss: 3.651 |  Val PPL:  38.526\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.960862159729004\n",
      "Epoch: 1502\n",
      "\tTrain Loss: 3.961 | Train PPL:  52.503\n",
      "\tVal Loss: 3.649 |  Val PPL:  38.450\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9697372913360596\n",
      "Epoch: 1503\n",
      "\tTrain Loss: 3.970 | Train PPL:  52.971\n",
      "\tVal Loss: 3.648 |  Val PPL:  38.403\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.960296630859375\n",
      "Epoch: 1504\n",
      "\tTrain Loss: 3.960 | Train PPL:  52.473\n",
      "\tVal Loss: 3.648 |  Val PPL:  38.404\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.957156181335449\n",
      "Epoch: 1505\n",
      "\tTrain Loss: 3.957 | Train PPL:  52.308\n",
      "\tVal Loss: 3.650 |  Val PPL:  38.494\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9581165313720703\n",
      "Epoch: 1506\n",
      "\tTrain Loss: 3.958 | Train PPL:  52.359\n",
      "\tVal Loss: 3.655 |  Val PPL:  38.652\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9575588703155518\n",
      "Epoch: 1507\n",
      "\tTrain Loss: 3.958 | Train PPL:  52.329\n",
      "\tVal Loss: 3.658 |  Val PPL:  38.775\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.963355541229248\n",
      "Epoch: 1508\n",
      "\tTrain Loss: 3.963 | Train PPL:  52.634\n",
      "\tVal Loss: 3.659 |  Val PPL:  38.834\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.94327974319458\n",
      "Epoch: 1509\n",
      "\tTrain Loss: 3.943 | Train PPL:  51.588\n",
      "\tVal Loss: 3.660 |  Val PPL:  38.859\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.965407371520996\n",
      "Epoch: 1510\n",
      "\tTrain Loss: 3.965 | Train PPL:  52.742\n",
      "\tVal Loss: 3.660 |  Val PPL:  38.843\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.937474250793457\n",
      "Epoch: 1511\n",
      "\tTrain Loss: 3.937 | Train PPL:  51.289\n",
      "\tVal Loss: 3.660 |  Val PPL:  38.879\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.944329023361206\n",
      "Epoch: 1512\n",
      "\tTrain Loss: 3.944 | Train PPL:  51.642\n",
      "\tVal Loss: 3.660 |  Val PPL:  38.863\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9421026706695557\n",
      "Epoch: 1513\n",
      "\tTrain Loss: 3.942 | Train PPL:  51.527\n",
      "\tVal Loss: 3.658 |  Val PPL:  38.796\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.945250988006592\n",
      "Epoch: 1514\n",
      "\tTrain Loss: 3.945 | Train PPL:  51.689\n",
      "\tVal Loss: 3.655 |  Val PPL:  38.652\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9544830322265625\n",
      "Epoch: 1515\n",
      "\tTrain Loss: 3.954 | Train PPL:  52.169\n",
      "\tVal Loss: 3.652 |  Val PPL:  38.548\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9581985473632812\n",
      "Epoch: 1516\n",
      "\tTrain Loss: 3.958 | Train PPL:  52.363\n",
      "\tVal Loss: 3.649 |  Val PPL:  38.440\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.930385112762451\n",
      "Epoch: 1517\n",
      "\tTrain Loss: 3.930 | Train PPL:  50.927\n",
      "\tVal Loss: 3.647 |  Val PPL:  38.364\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9246373176574707\n",
      "Epoch: 1518\n",
      "\tTrain Loss: 3.925 | Train PPL:  50.635\n",
      "\tVal Loss: 3.645 |  Val PPL:  38.300\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.951139211654663\n",
      "Epoch: 1519\n",
      "\tTrain Loss: 3.951 | Train PPL:  51.995\n",
      "\tVal Loss: 3.644 |  Val PPL:  38.231\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9400038719177246\n",
      "Epoch: 1520\n",
      "\tTrain Loss: 3.940 | Train PPL:  51.419\n",
      "\tVal Loss: 3.642 |  Val PPL:  38.151\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.950807809829712\n",
      "Epoch: 1521\n",
      "\tTrain Loss: 3.951 | Train PPL:  51.977\n",
      "\tVal Loss: 3.639 |  Val PPL:  38.062\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.93866229057312\n",
      "Epoch: 1522\n",
      "\tTrain Loss: 3.939 | Train PPL:  51.350\n",
      "\tVal Loss: 3.638 |  Val PPL:  38.026\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.952436685562134\n",
      "Epoch: 1523\n",
      "\tTrain Loss: 3.952 | Train PPL:  52.062\n",
      "\tVal Loss: 3.638 |  Val PPL:  38.019\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9459664821624756\n",
      "Epoch: 1524\n",
      "\tTrain Loss: 3.946 | Train PPL:  51.726\n",
      "\tVal Loss: 3.639 |  Val PPL:  38.037\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9440934658050537\n",
      "Epoch: 1525\n",
      "\tTrain Loss: 3.944 | Train PPL:  51.630\n",
      "\tVal Loss: 3.639 |  Val PPL:  38.045\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.951307535171509\n",
      "Epoch: 1526\n",
      "\tTrain Loss: 3.951 | Train PPL:  52.003\n",
      "\tVal Loss: 3.639 |  Val PPL:  38.065\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9432713985443115\n",
      "Epoch: 1527\n",
      "\tTrain Loss: 3.943 | Train PPL:  51.587\n",
      "\tVal Loss: 3.640 |  Val PPL:  38.090\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.950037717819214\n",
      "Epoch: 1528\n",
      "\tTrain Loss: 3.950 | Train PPL:  51.937\n",
      "\tVal Loss: 3.642 |  Val PPL:  38.171\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.925539493560791\n",
      "Epoch: 1529\n",
      "\tTrain Loss: 3.926 | Train PPL:  50.680\n",
      "\tVal Loss: 3.643 |  Val PPL:  38.224\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9459245204925537\n",
      "Epoch: 1530\n",
      "\tTrain Loss: 3.946 | Train PPL:  51.724\n",
      "\tVal Loss: 3.642 |  Val PPL:  38.185\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9283034801483154\n",
      "Epoch: 1531\n",
      "\tTrain Loss: 3.928 | Train PPL:  50.821\n",
      "\tVal Loss: 3.641 |  Val PPL:  38.124\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.950371742248535\n",
      "Epoch: 1532\n",
      "\tTrain Loss: 3.950 | Train PPL:  51.955\n",
      "\tVal Loss: 3.638 |  Val PPL:  38.017\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9063572883605957\n",
      "Epoch: 1533\n",
      "\tTrain Loss: 3.906 | Train PPL:  49.718\n",
      "\tVal Loss: 3.636 |  Val PPL:  37.928\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9462833404541016\n",
      "Epoch: 1534\n",
      "\tTrain Loss: 3.946 | Train PPL:  51.743\n",
      "\tVal Loss: 3.635 |  Val PPL:  37.887\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.920138120651245\n",
      "Epoch: 1535\n",
      "\tTrain Loss: 3.920 | Train PPL:  50.407\n",
      "\tVal Loss: 3.634 |  Val PPL:  37.860\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9433515071868896\n",
      "Epoch: 1536\n",
      "\tTrain Loss: 3.943 | Train PPL:  51.591\n",
      "\tVal Loss: 3.634 |  Val PPL:  37.846\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9543442726135254\n",
      "Epoch: 1537\n",
      "\tTrain Loss: 3.954 | Train PPL:  52.161\n",
      "\tVal Loss: 3.633 |  Val PPL:  37.828\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9449546337127686\n",
      "Epoch: 1538\n",
      "\tTrain Loss: 3.945 | Train PPL:  51.674\n",
      "\tVal Loss: 3.633 |  Val PPL:  37.838\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9284822940826416\n",
      "Epoch: 1539\n",
      "\tTrain Loss: 3.928 | Train PPL:  50.830\n",
      "\tVal Loss: 3.634 |  Val PPL:  37.849\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.912750482559204\n",
      "Epoch: 1540\n",
      "\tTrain Loss: 3.913 | Train PPL:  50.036\n",
      "\tVal Loss: 3.634 |  Val PPL:  37.869\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.908658266067505\n",
      "Epoch: 1541\n",
      "\tTrain Loss: 3.909 | Train PPL:  49.832\n",
      "\tVal Loss: 3.634 |  Val PPL:  37.864\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.925813913345337\n",
      "Epoch: 1542\n",
      "\tTrain Loss: 3.926 | Train PPL:  50.694\n",
      "\tVal Loss: 3.633 |  Val PPL:  37.840\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.941801071166992\n",
      "Epoch: 1543\n",
      "\tTrain Loss: 3.942 | Train PPL:  51.511\n",
      "\tVal Loss: 3.632 |  Val PPL:  37.803\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.921419620513916\n",
      "Epoch: 1544\n",
      "\tTrain Loss: 3.921 | Train PPL:  50.472\n",
      "\tVal Loss: 3.631 |  Val PPL:  37.751\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9447429180145264\n",
      "Epoch: 1545\n",
      "\tTrain Loss: 3.945 | Train PPL:  51.663\n",
      "\tVal Loss: 3.629 |  Val PPL:  37.692\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.92285418510437\n",
      "Epoch: 1546\n",
      "\tTrain Loss: 3.923 | Train PPL:  50.545\n",
      "\tVal Loss: 3.628 |  Val PPL:  37.652\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.93530535697937\n",
      "Epoch: 1547\n",
      "\tTrain Loss: 3.935 | Train PPL:  51.178\n",
      "\tVal Loss: 3.629 |  Val PPL:  37.677\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9293811321258545\n",
      "Epoch: 1548\n",
      "\tTrain Loss: 3.929 | Train PPL:  50.875\n",
      "\tVal Loss: 3.630 |  Val PPL:  37.722\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.923865795135498\n",
      "Epoch: 1549\n",
      "\tTrain Loss: 3.924 | Train PPL:  50.596\n",
      "\tVal Loss: 3.631 |  Val PPL:  37.768\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9198102951049805\n",
      "Epoch: 1550\n",
      "\tTrain Loss: 3.920 | Train PPL:  50.391\n",
      "\tVal Loss: 3.633 |  Val PPL:  37.825\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.914982557296753\n",
      "Epoch: 1551\n",
      "\tTrain Loss: 3.915 | Train PPL:  50.148\n",
      "\tVal Loss: 3.634 |  Val PPL:  37.880\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.925539493560791\n",
      "Epoch: 1552\n",
      "\tTrain Loss: 3.926 | Train PPL:  50.680\n",
      "\tVal Loss: 3.635 |  Val PPL:  37.885\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9355084896087646\n",
      "Epoch: 1553\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.188\n",
      "\tVal Loss: 3.634 |  Val PPL:  37.872\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9338345527648926\n",
      "Epoch: 1554\n",
      "\tTrain Loss: 3.934 | Train PPL:  51.103\n",
      "\tVal Loss: 3.633 |  Val PPL:  37.816\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9181928634643555\n",
      "Epoch: 1555\n",
      "\tTrain Loss: 3.918 | Train PPL:  50.309\n",
      "\tVal Loss: 3.630 |  Val PPL:  37.726\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.930219888687134\n",
      "Epoch: 1556\n",
      "\tTrain Loss: 3.930 | Train PPL:  50.918\n",
      "\tVal Loss: 3.630 |  Val PPL:  37.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9487478733062744\n",
      "Epoch: 1557\n",
      "\tTrain Loss: 3.949 | Train PPL:  51.870\n",
      "\tVal Loss: 3.628 |  Val PPL:  37.651\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9533491134643555\n",
      "Epoch: 1558\n",
      "\tTrain Loss: 3.953 | Train PPL:  52.110\n",
      "\tVal Loss: 3.627 |  Val PPL:  37.608\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9036800861358643\n",
      "Epoch: 1559\n",
      "\tTrain Loss: 3.904 | Train PPL:  49.585\n",
      "\tVal Loss: 3.627 |  Val PPL:  37.581\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9263675212860107\n",
      "Epoch: 1560\n",
      "\tTrain Loss: 3.926 | Train PPL:  50.722\n",
      "\tVal Loss: 3.626 |  Val PPL:  37.545\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.928769826889038\n",
      "Epoch: 1561\n",
      "\tTrain Loss: 3.929 | Train PPL:  50.844\n",
      "\tVal Loss: 3.624 |  Val PPL:  37.484\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.916935443878174\n",
      "Epoch: 1562\n",
      "\tTrain Loss: 3.917 | Train PPL:  50.246\n",
      "\tVal Loss: 3.622 |  Val PPL:  37.430\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9246487617492676\n",
      "Epoch: 1563\n",
      "\tTrain Loss: 3.925 | Train PPL:  50.635\n",
      "\tVal Loss: 3.621 |  Val PPL:  37.388\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.924403667449951\n",
      "Epoch: 1564\n",
      "\tTrain Loss: 3.924 | Train PPL:  50.623\n",
      "\tVal Loss: 3.621 |  Val PPL:  37.358\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9366331100463867\n",
      "Epoch: 1565\n",
      "\tTrain Loss: 3.937 | Train PPL:  51.246\n",
      "\tVal Loss: 3.620 |  Val PPL:  37.335\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9254045486450195\n",
      "Epoch: 1566\n",
      "\tTrain Loss: 3.925 | Train PPL:  50.674\n",
      "\tVal Loss: 3.620 |  Val PPL:  37.339\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.91637921333313\n",
      "Epoch: 1567\n",
      "\tTrain Loss: 3.916 | Train PPL:  50.218\n",
      "\tVal Loss: 3.619 |  Val PPL:  37.307\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.899979829788208\n",
      "Epoch: 1568\n",
      "\tTrain Loss: 3.900 | Train PPL:  49.401\n",
      "\tVal Loss: 3.618 |  Val PPL:  37.270\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9099738597869873\n",
      "Epoch: 1569\n",
      "\tTrain Loss: 3.910 | Train PPL:  49.898\n",
      "\tVal Loss: 3.617 |  Val PPL:  37.209\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.924379348754883\n",
      "Epoch: 1570\n",
      "\tTrain Loss: 3.924 | Train PPL:  50.622\n",
      "\tVal Loss: 3.615 |  Val PPL:  37.147\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9550962448120117\n",
      "Epoch: 1571\n",
      "\tTrain Loss: 3.955 | Train PPL:  52.201\n",
      "\tVal Loss: 3.614 |  Val PPL:  37.114\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9268124103546143\n",
      "Epoch: 1572\n",
      "\tTrain Loss: 3.927 | Train PPL:  50.745\n",
      "\tVal Loss: 3.614 |  Val PPL:  37.107\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9095866680145264\n",
      "Epoch: 1573\n",
      "\tTrain Loss: 3.910 | Train PPL:  49.878\n",
      "\tVal Loss: 3.615 |  Val PPL:  37.141\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8962409496307373\n",
      "Epoch: 1574\n",
      "\tTrain Loss: 3.896 | Train PPL:  49.217\n",
      "\tVal Loss: 3.616 |  Val PPL:  37.193\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9302785396575928\n",
      "Epoch: 1575\n",
      "\tTrain Loss: 3.930 | Train PPL:  50.921\n",
      "\tVal Loss: 3.616 |  Val PPL:  37.202\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9067463874816895\n",
      "Epoch: 1576\n",
      "\tTrain Loss: 3.907 | Train PPL:  49.737\n",
      "\tVal Loss: 3.617 |  Val PPL:  37.211\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9442973136901855\n",
      "Epoch: 1577\n",
      "\tTrain Loss: 3.944 | Train PPL:  51.640\n",
      "\tVal Loss: 3.617 |  Val PPL:  37.215\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.917710065841675\n",
      "Epoch: 1578\n",
      "\tTrain Loss: 3.918 | Train PPL:  50.285\n",
      "\tVal Loss: 3.616 |  Val PPL:  37.205\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9232020378112793\n",
      "Epoch: 1579\n",
      "\tTrain Loss: 3.923 | Train PPL:  50.562\n",
      "\tVal Loss: 3.615 |  Val PPL:  37.162\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.891888380050659\n",
      "Epoch: 1580\n",
      "\tTrain Loss: 3.892 | Train PPL:  49.003\n",
      "\tVal Loss: 3.613 |  Val PPL:  37.090\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.882990837097168\n",
      "Epoch: 1581\n",
      "\tTrain Loss: 3.883 | Train PPL:  48.569\n",
      "\tVal Loss: 3.611 |  Val PPL:  37.014\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9097983837127686\n",
      "Epoch: 1582\n",
      "\tTrain Loss: 3.910 | Train PPL:  49.889\n",
      "\tVal Loss: 3.609 |  Val PPL:  36.929\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9314303398132324\n",
      "Epoch: 1583\n",
      "\tTrain Loss: 3.931 | Train PPL:  50.980\n",
      "\tVal Loss: 3.607 |  Val PPL:  36.870\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.892864227294922\n",
      "Epoch: 1584\n",
      "\tTrain Loss: 3.893 | Train PPL:  49.051\n",
      "\tVal Loss: 3.606 |  Val PPL:  36.807\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9126980304718018\n",
      "Epoch: 1585\n",
      "\tTrain Loss: 3.913 | Train PPL:  50.034\n",
      "\tVal Loss: 3.605 |  Val PPL:  36.764\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.907526731491089\n",
      "Epoch: 1586\n",
      "\tTrain Loss: 3.908 | Train PPL:  49.776\n",
      "\tVal Loss: 3.603 |  Val PPL:  36.715\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8950202465057373\n",
      "Epoch: 1587\n",
      "\tTrain Loss: 3.895 | Train PPL:  49.157\n",
      "\tVal Loss: 3.602 |  Val PPL:  36.682\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8760247230529785\n",
      "Epoch: 1588\n",
      "\tTrain Loss: 3.876 | Train PPL:  48.232\n",
      "\tVal Loss: 3.602 |  Val PPL:  36.655\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8973774909973145\n",
      "Epoch: 1589\n",
      "\tTrain Loss: 3.897 | Train PPL:  49.273\n",
      "\tVal Loss: 3.601 |  Val PPL:  36.633\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.892392873764038\n",
      "Epoch: 1590\n",
      "\tTrain Loss: 3.892 | Train PPL:  49.028\n",
      "\tVal Loss: 3.601 |  Val PPL:  36.620\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9004225730895996\n",
      "Epoch: 1591\n",
      "\tTrain Loss: 3.900 | Train PPL:  49.423\n",
      "\tVal Loss: 3.600 |  Val PPL:  36.613\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8919482231140137\n",
      "Epoch: 1592\n",
      "\tTrain Loss: 3.892 | Train PPL:  49.006\n",
      "\tVal Loss: 3.600 |  Val PPL:  36.604\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.87540864944458\n",
      "Epoch: 1593\n",
      "\tTrain Loss: 3.875 | Train PPL:  48.202\n",
      "\tVal Loss: 3.600 |  Val PPL:  36.595\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8910398483276367\n",
      "Epoch: 1594\n",
      "\tTrain Loss: 3.891 | Train PPL:  48.962\n",
      "\tVal Loss: 3.600 |  Val PPL:  36.604\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9289803504943848\n",
      "Epoch: 1595\n",
      "\tTrain Loss: 3.929 | Train PPL:  50.855\n",
      "\tVal Loss: 3.602 |  Val PPL:  36.653\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9205286502838135\n",
      "Epoch: 1596\n",
      "\tTrain Loss: 3.921 | Train PPL:  50.427\n",
      "\tVal Loss: 3.603 |  Val PPL:  36.703\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8937883377075195\n",
      "Epoch: 1597\n",
      "\tTrain Loss: 3.894 | Train PPL:  49.097\n",
      "\tVal Loss: 3.604 |  Val PPL:  36.751\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9135007858276367\n",
      "Epoch: 1598\n",
      "\tTrain Loss: 3.914 | Train PPL:  50.074\n",
      "\tVal Loss: 3.606 |  Val PPL:  36.821\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.889753580093384\n",
      "Epoch: 1599\n",
      "\tTrain Loss: 3.890 | Train PPL:  48.899\n",
      "\tVal Loss: 3.607 |  Val PPL:  36.861\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.860954999923706\n",
      "Epoch: 1600\n",
      "\tTrain Loss: 3.861 | Train PPL:  47.511\n",
      "\tVal Loss: 3.607 |  Val PPL:  36.856\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8754286766052246\n",
      "Epoch: 1601\n",
      "\tTrain Loss: 3.875 | Train PPL:  48.203\n",
      "\tVal Loss: 3.606 |  Val PPL:  36.821\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8971519470214844\n",
      "Epoch: 1602\n",
      "\tTrain Loss: 3.897 | Train PPL:  49.262\n",
      "\tVal Loss: 3.604 |  Val PPL:  36.743\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.885984182357788\n",
      "Epoch: 1603\n",
      "\tTrain Loss: 3.886 | Train PPL:  48.715\n",
      "\tVal Loss: 3.601 |  Val PPL:  36.632\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.906615972518921\n",
      "Epoch: 1604\n",
      "\tTrain Loss: 3.907 | Train PPL:  49.730\n",
      "\tVal Loss: 3.598 |  Val PPL:  36.534\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9089534282684326\n",
      "Epoch: 1605\n",
      "\tTrain Loss: 3.909 | Train PPL:  49.847\n",
      "\tVal Loss: 3.596 |  Val PPL:  36.441\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.915572166442871\n",
      "Epoch: 1606\n",
      "\tTrain Loss: 3.916 | Train PPL:  50.178\n",
      "\tVal Loss: 3.593 |  Val PPL:  36.349\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.906222105026245\n",
      "Epoch: 1607\n",
      "\tTrain Loss: 3.906 | Train PPL:  49.711\n",
      "\tVal Loss: 3.591 |  Val PPL:  36.275\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9001312255859375\n",
      "Epoch: 1608\n",
      "\tTrain Loss: 3.900 | Train PPL:  49.409\n",
      "\tVal Loss: 3.589 |  Val PPL:  36.215\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.90226674079895\n",
      "Epoch: 1609\n",
      "\tTrain Loss: 3.902 | Train PPL:  49.515\n",
      "\tVal Loss: 3.589 |  Val PPL:  36.201\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8638229370117188\n",
      "Epoch: 1610\n",
      "\tTrain Loss: 3.864 | Train PPL:  47.647\n",
      "\tVal Loss: 3.589 |  Val PPL:  36.215\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.883543014526367\n",
      "Epoch: 1611\n",
      "\tTrain Loss: 3.884 | Train PPL:  48.596\n",
      "\tVal Loss: 3.590 |  Val PPL:  36.218\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8847084045410156\n",
      "Epoch: 1612\n",
      "\tTrain Loss: 3.885 | Train PPL:  48.653\n",
      "\tVal Loss: 3.590 |  Val PPL:  36.247\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8855948448181152\n",
      "Epoch: 1613\n",
      "\tTrain Loss: 3.886 | Train PPL:  48.696\n",
      "\tVal Loss: 3.591 |  Val PPL:  36.257\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.883559465408325\n",
      "Epoch: 1614\n",
      "\tTrain Loss: 3.884 | Train PPL:  48.597\n",
      "\tVal Loss: 3.590 |  Val PPL:  36.237\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.901979446411133\n",
      "Epoch: 1615\n",
      "\tTrain Loss: 3.902 | Train PPL:  49.500\n",
      "\tVal Loss: 3.590 |  Val PPL:  36.224\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.884269952774048\n",
      "Epoch: 1616\n",
      "\tTrain Loss: 3.884 | Train PPL:  48.631\n",
      "\tVal Loss: 3.589 |  Val PPL:  36.214\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.879821300506592\n",
      "Epoch: 1617\n",
      "\tTrain Loss: 3.880 | Train PPL:  48.416\n",
      "\tVal Loss: 3.589 |  Val PPL:  36.181\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8974685668945312\n",
      "Epoch: 1618\n",
      "\tTrain Loss: 3.897 | Train PPL:  49.278\n",
      "\tVal Loss: 3.587 |  Val PPL:  36.134\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.882364273071289\n",
      "Epoch: 1619\n",
      "\tTrain Loss: 3.882 | Train PPL:  48.539\n",
      "\tVal Loss: 3.585 |  Val PPL:  36.058\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.875296115875244\n",
      "Epoch: 1620\n",
      "\tTrain Loss: 3.875 | Train PPL:  48.197\n",
      "\tVal Loss: 3.583 |  Val PPL:  35.990\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.876786708831787\n",
      "Epoch: 1621\n",
      "\tTrain Loss: 3.877 | Train PPL:  48.269\n",
      "\tVal Loss: 3.582 |  Val PPL:  35.949\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.914536476135254\n",
      "Epoch: 1622\n",
      "\tTrain Loss: 3.915 | Train PPL:  50.126\n",
      "\tVal Loss: 3.582 |  Val PPL:  35.939\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9077110290527344\n",
      "Epoch: 1623\n",
      "\tTrain Loss: 3.908 | Train PPL:  49.785\n",
      "\tVal Loss: 3.582 |  Val PPL:  35.961\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.882812976837158\n",
      "Epoch: 1624\n",
      "\tTrain Loss: 3.883 | Train PPL:  48.561\n",
      "\tVal Loss: 3.583 |  Val PPL:  35.980\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9012668132781982\n",
      "Epoch: 1625\n",
      "\tTrain Loss: 3.901 | Train PPL:  49.465\n",
      "\tVal Loss: 3.584 |  Val PPL:  36.007\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8786463737487793\n",
      "Epoch: 1626\n",
      "\tTrain Loss: 3.879 | Train PPL:  48.359\n",
      "\tVal Loss: 3.584 |  Val PPL:  36.027\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8891260623931885\n",
      "Epoch: 1627\n",
      "\tTrain Loss: 3.889 | Train PPL:  48.868\n",
      "\tVal Loss: 3.584 |  Val PPL:  36.019\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8951404094696045\n",
      "Epoch: 1628\n",
      "\tTrain Loss: 3.895 | Train PPL:  49.163\n",
      "\tVal Loss: 3.584 |  Val PPL:  36.026\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.865374803543091\n",
      "Epoch: 1629\n",
      "\tTrain Loss: 3.865 | Train PPL:  47.721\n",
      "\tVal Loss: 3.585 |  Val PPL:  36.036\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8833060264587402\n",
      "Epoch: 1630\n",
      "\tTrain Loss: 3.883 | Train PPL:  48.585\n",
      "\tVal Loss: 3.585 |  Val PPL:  36.049\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8787572383880615\n",
      "Epoch: 1631\n",
      "\tTrain Loss: 3.879 | Train PPL:  48.364\n",
      "\tVal Loss: 3.585 |  Val PPL:  36.040\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.869663715362549\n",
      "Epoch: 1632\n",
      "\tTrain Loss: 3.870 | Train PPL:  47.926\n",
      "\tVal Loss: 3.585 |  Val PPL:  36.056\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8811631202697754\n",
      "Epoch: 1633\n",
      "\tTrain Loss: 3.881 | Train PPL:  48.481\n",
      "\tVal Loss: 3.585 |  Val PPL:  36.065\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.881390333175659\n",
      "Epoch: 1634\n",
      "\tTrain Loss: 3.881 | Train PPL:  48.492\n",
      "\tVal Loss: 3.585 |  Val PPL:  36.071\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.883361339569092\n",
      "Epoch: 1635\n",
      "\tTrain Loss: 3.883 | Train PPL:  48.587\n",
      "\tVal Loss: 3.586 |  Val PPL:  36.072\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8744637966156006\n",
      "Epoch: 1636\n",
      "\tTrain Loss: 3.874 | Train PPL:  48.157\n",
      "\tVal Loss: 3.585 |  Val PPL:  36.044\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8987412452697754\n",
      "Epoch: 1637\n",
      "\tTrain Loss: 3.899 | Train PPL:  49.340\n",
      "\tVal Loss: 3.584 |  Val PPL:  36.005\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8921444416046143\n",
      "Epoch: 1638\n",
      "\tTrain Loss: 3.892 | Train PPL:  49.016\n",
      "\tVal Loss: 3.583 |  Val PPL:  35.979\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8909947872161865\n",
      "Epoch: 1639\n",
      "\tTrain Loss: 3.891 | Train PPL:  48.960\n",
      "\tVal Loss: 3.583 |  Val PPL:  35.965\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.881336212158203\n",
      "Epoch: 1640\n",
      "\tTrain Loss: 3.881 | Train PPL:  48.489\n",
      "\tVal Loss: 3.582 |  Val PPL:  35.963\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.882654905319214\n",
      "Epoch: 1641\n",
      "\tTrain Loss: 3.883 | Train PPL:  48.553\n",
      "\tVal Loss: 3.583 |  Val PPL:  35.973\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8857131004333496\n",
      "Epoch: 1642\n",
      "\tTrain Loss: 3.886 | Train PPL:  48.702\n",
      "\tVal Loss: 3.583 |  Val PPL:  35.968\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.879276752471924\n",
      "Epoch: 1643\n",
      "\tTrain Loss: 3.879 | Train PPL:  48.389\n",
      "\tVal Loss: 3.583 |  Val PPL:  35.967\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8809187412261963\n",
      "Epoch: 1644\n",
      "\tTrain Loss: 3.881 | Train PPL:  48.469\n",
      "\tVal Loss: 3.583 |  Val PPL:  35.983\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.851996898651123\n",
      "Epoch: 1645\n",
      "\tTrain Loss: 3.852 | Train PPL:  47.087\n",
      "\tVal Loss: 3.584 |  Val PPL:  36.003\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8819291591644287\n",
      "Epoch: 1646\n",
      "\tTrain Loss: 3.882 | Train PPL:  48.518\n",
      "\tVal Loss: 3.584 |  Val PPL:  36.008\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8893139362335205\n",
      "Epoch: 1647\n",
      "\tTrain Loss: 3.889 | Train PPL:  48.877\n",
      "\tVal Loss: 3.583 |  Val PPL:  35.975\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8946545124053955\n",
      "Epoch: 1648\n",
      "\tTrain Loss: 3.895 | Train PPL:  49.139\n",
      "\tVal Loss: 3.582 |  Val PPL:  35.952\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.878244400024414\n",
      "Epoch: 1649\n",
      "\tTrain Loss: 3.878 | Train PPL:  48.339\n",
      "\tVal Loss: 3.581 |  Val PPL:  35.924\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8913841247558594\n",
      "Epoch: 1650\n",
      "\tTrain Loss: 3.891 | Train PPL:  48.979\n",
      "\tVal Loss: 3.580 |  Val PPL:  35.865\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8980796337127686\n",
      "Epoch: 1651\n",
      "\tTrain Loss: 3.898 | Train PPL:  49.308\n",
      "\tVal Loss: 3.578 |  Val PPL:  35.803\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8652467727661133\n",
      "Epoch: 1652\n",
      "\tTrain Loss: 3.865 | Train PPL:  47.715\n",
      "\tVal Loss: 3.576 |  Val PPL:  35.745\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8613598346710205\n",
      "Epoch: 1653\n",
      "\tTrain Loss: 3.861 | Train PPL:  47.530\n",
      "\tVal Loss: 3.575 |  Val PPL:  35.700\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8631443977355957\n",
      "Epoch: 1654\n",
      "\tTrain Loss: 3.863 | Train PPL:  47.615\n",
      "\tVal Loss: 3.575 |  Val PPL:  35.690\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8886613845825195\n",
      "Epoch: 1655\n",
      "\tTrain Loss: 3.889 | Train PPL:  48.845\n",
      "\tVal Loss: 3.575 |  Val PPL:  35.695\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8745498657226562\n",
      "Epoch: 1656\n",
      "\tTrain Loss: 3.875 | Train PPL:  48.161\n",
      "\tVal Loss: 3.575 |  Val PPL:  35.677\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8732738494873047\n",
      "Epoch: 1657\n",
      "\tTrain Loss: 3.873 | Train PPL:  48.100\n",
      "\tVal Loss: 3.574 |  Val PPL:  35.656\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8867530822753906\n",
      "Epoch: 1658\n",
      "\tTrain Loss: 3.887 | Train PPL:  48.752\n",
      "\tVal Loss: 3.573 |  Val PPL:  35.638\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8892877101898193\n",
      "Epoch: 1659\n",
      "\tTrain Loss: 3.889 | Train PPL:  48.876\n",
      "\tVal Loss: 3.573 |  Val PPL:  35.608\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8812832832336426\n",
      "Epoch: 1660\n",
      "\tTrain Loss: 3.881 | Train PPL:  48.486\n",
      "\tVal Loss: 3.572 |  Val PPL:  35.589\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.888582944869995\n",
      "Epoch: 1661\n",
      "\tTrain Loss: 3.889 | Train PPL:  48.842\n",
      "\tVal Loss: 3.572 |  Val PPL:  35.591\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.896270751953125\n",
      "Epoch: 1662\n",
      "\tTrain Loss: 3.896 | Train PPL:  49.219\n",
      "\tVal Loss: 3.572 |  Val PPL:  35.595\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9130423069000244\n",
      "Epoch: 1663\n",
      "\tTrain Loss: 3.913 | Train PPL:  50.051\n",
      "\tVal Loss: 3.572 |  Val PPL:  35.594\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8587865829467773\n",
      "Epoch: 1664\n",
      "\tTrain Loss: 3.859 | Train PPL:  47.408\n",
      "\tVal Loss: 3.572 |  Val PPL:  35.594\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8830630779266357\n",
      "Epoch: 1665\n",
      "\tTrain Loss: 3.883 | Train PPL:  48.573\n",
      "\tVal Loss: 3.572 |  Val PPL:  35.577\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8792858123779297\n",
      "Epoch: 1666\n",
      "\tTrain Loss: 3.879 | Train PPL:  48.390\n",
      "\tVal Loss: 3.571 |  Val PPL:  35.564\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8823254108428955\n",
      "Epoch: 1667\n",
      "\tTrain Loss: 3.882 | Train PPL:  48.537\n",
      "\tVal Loss: 3.571 |  Val PPL:  35.549\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.867434501647949\n",
      "Epoch: 1668\n",
      "\tTrain Loss: 3.867 | Train PPL:  47.820\n",
      "\tVal Loss: 3.571 |  Val PPL:  35.547\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.893782377243042\n",
      "Epoch: 1669\n",
      "\tTrain Loss: 3.894 | Train PPL:  49.096\n",
      "\tVal Loss: 3.571 |  Val PPL:  35.552\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8669469356536865\n",
      "Epoch: 1670\n",
      "\tTrain Loss: 3.867 | Train PPL:  47.796\n",
      "\tVal Loss: 3.571 |  Val PPL:  35.540\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.842928886413574\n",
      "Epoch: 1671\n",
      "\tTrain Loss: 3.843 | Train PPL:  46.662\n",
      "\tVal Loss: 3.570 |  Val PPL:  35.510\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8741657733917236\n",
      "Epoch: 1672\n",
      "\tTrain Loss: 3.874 | Train PPL:  48.143\n",
      "\tVal Loss: 3.569 |  Val PPL:  35.471\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8867650032043457\n",
      "Epoch: 1673\n",
      "\tTrain Loss: 3.887 | Train PPL:  48.753\n",
      "\tVal Loss: 3.568 |  Val PPL:  35.438\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8640661239624023\n",
      "Epoch: 1674\n",
      "\tTrain Loss: 3.864 | Train PPL:  47.659\n",
      "\tVal Loss: 3.567 |  Val PPL:  35.396\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8434810638427734\n",
      "Epoch: 1675\n",
      "\tTrain Loss: 3.843 | Train PPL:  46.688\n",
      "\tVal Loss: 3.566 |  Val PPL:  35.362\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8767712116241455\n",
      "Epoch: 1676\n",
      "\tTrain Loss: 3.877 | Train PPL:  48.268\n",
      "\tVal Loss: 3.565 |  Val PPL:  35.353\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.850520133972168\n",
      "Epoch: 1677\n",
      "\tTrain Loss: 3.851 | Train PPL:  47.018\n",
      "\tVal Loss: 3.565 |  Val PPL:  35.350\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8740718364715576\n",
      "Epoch: 1678\n",
      "\tTrain Loss: 3.874 | Train PPL:  48.138\n",
      "\tVal Loss: 3.565 |  Val PPL:  35.337\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8594014644622803\n",
      "Epoch: 1679\n",
      "\tTrain Loss: 3.859 | Train PPL:  47.437\n",
      "\tVal Loss: 3.564 |  Val PPL:  35.303\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8902199268341064\n",
      "Epoch: 1680\n",
      "\tTrain Loss: 3.890 | Train PPL:  48.922\n",
      "\tVal Loss: 3.563 |  Val PPL:  35.264\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.880481481552124\n",
      "Epoch: 1681\n",
      "\tTrain Loss: 3.880 | Train PPL:  48.448\n",
      "\tVal Loss: 3.562 |  Val PPL:  35.221\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8428828716278076\n",
      "Epoch: 1682\n",
      "\tTrain Loss: 3.843 | Train PPL:  46.660\n",
      "\tVal Loss: 3.561 |  Val PPL:  35.192\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.894641876220703\n",
      "Epoch: 1683\n",
      "\tTrain Loss: 3.895 | Train PPL:  49.138\n",
      "\tVal Loss: 3.560 |  Val PPL:  35.172\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.848813056945801\n",
      "Epoch: 1684\n",
      "\tTrain Loss: 3.849 | Train PPL:  46.937\n",
      "\tVal Loss: 3.560 |  Val PPL:  35.152\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8825366497039795\n",
      "Epoch: 1685\n",
      "\tTrain Loss: 3.883 | Train PPL:  48.547\n",
      "\tVal Loss: 3.560 |  Val PPL:  35.146\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8787965774536133\n",
      "Epoch: 1686\n",
      "\tTrain Loss: 3.879 | Train PPL:  48.366\n",
      "\tVal Loss: 3.560 |  Val PPL:  35.146\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8566904067993164\n",
      "Epoch: 1687\n",
      "\tTrain Loss: 3.857 | Train PPL:  47.309\n",
      "\tVal Loss: 3.560 |  Val PPL:  35.156\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8582568168640137\n",
      "Epoch: 1688\n",
      "\tTrain Loss: 3.858 | Train PPL:  47.383\n",
      "\tVal Loss: 3.560 |  Val PPL:  35.171\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8389203548431396\n",
      "Epoch: 1689\n",
      "\tTrain Loss: 3.839 | Train PPL:  46.475\n",
      "\tVal Loss: 3.560 |  Val PPL:  35.181\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8939170837402344\n",
      "Epoch: 1690\n",
      "\tTrain Loss: 3.894 | Train PPL:  49.103\n",
      "\tVal Loss: 3.561 |  Val PPL:  35.186\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.865894079208374\n",
      "Epoch: 1691\n",
      "\tTrain Loss: 3.866 | Train PPL:  47.746\n",
      "\tVal Loss: 3.560 |  Val PPL:  35.176\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8753414154052734\n",
      "Epoch: 1692\n",
      "\tTrain Loss: 3.875 | Train PPL:  48.199\n",
      "\tVal Loss: 3.560 |  Val PPL:  35.152\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.852055788040161\n",
      "Epoch: 1693\n",
      "\tTrain Loss: 3.852 | Train PPL:  47.090\n",
      "\tVal Loss: 3.559 |  Val PPL:  35.126\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.871340751647949\n",
      "Epoch: 1694\n",
      "\tTrain Loss: 3.871 | Train PPL:  48.007\n",
      "\tVal Loss: 3.558 |  Val PPL:  35.108\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8717663288116455\n",
      "Epoch: 1695\n",
      "\tTrain Loss: 3.872 | Train PPL:  48.027\n",
      "\tVal Loss: 3.558 |  Val PPL:  35.085\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8594508171081543\n",
      "Epoch: 1696\n",
      "\tTrain Loss: 3.859 | Train PPL:  47.439\n",
      "\tVal Loss: 3.558 |  Val PPL:  35.077\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9111199378967285\n",
      "Epoch: 1697\n",
      "\tTrain Loss: 3.911 | Train PPL:  49.955\n",
      "\tVal Loss: 3.557 |  Val PPL:  35.074\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.858534574508667\n",
      "Epoch: 1698\n",
      "\tTrain Loss: 3.859 | Train PPL:  47.396\n",
      "\tVal Loss: 3.558 |  Val PPL:  35.077\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8802108764648438\n",
      "Epoch: 1699\n",
      "\tTrain Loss: 3.880 | Train PPL:  48.434\n",
      "\tVal Loss: 3.558 |  Val PPL:  35.078\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8639121055603027\n",
      "Epoch: 1700\n",
      "\tTrain Loss: 3.864 | Train PPL:  47.651\n",
      "\tVal Loss: 3.557 |  Val PPL:  35.071\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.882370710372925\n",
      "Epoch: 1701\n",
      "\tTrain Loss: 3.882 | Train PPL:  48.539\n",
      "\tVal Loss: 3.558 |  Val PPL:  35.076\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8648555278778076\n",
      "Epoch: 1702\n",
      "\tTrain Loss: 3.865 | Train PPL:  47.696\n",
      "\tVal Loss: 3.557 |  Val PPL:  35.075\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.863590717315674\n",
      "Epoch: 1703\n",
      "\tTrain Loss: 3.864 | Train PPL:  47.636\n",
      "\tVal Loss: 3.557 |  Val PPL:  35.072\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8573479652404785\n",
      "Epoch: 1704\n",
      "\tTrain Loss: 3.857 | Train PPL:  47.340\n",
      "\tVal Loss: 3.557 |  Val PPL:  35.062\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8708386421203613\n",
      "Epoch: 1705\n",
      "\tTrain Loss: 3.871 | Train PPL:  47.983\n",
      "\tVal Loss: 3.557 |  Val PPL:  35.043\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.847543239593506\n",
      "Epoch: 1706\n",
      "\tTrain Loss: 3.848 | Train PPL:  46.878\n",
      "\tVal Loss: 3.556 |  Val PPL:  35.029\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8652126789093018\n",
      "Epoch: 1707\n",
      "\tTrain Loss: 3.865 | Train PPL:  47.713\n",
      "\tVal Loss: 3.555 |  Val PPL:  35.001\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.855393409729004\n",
      "Epoch: 1708\n",
      "\tTrain Loss: 3.855 | Train PPL:  47.247\n",
      "\tVal Loss: 3.555 |  Val PPL:  34.972\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.9008452892303467\n",
      "Epoch: 1709\n",
      "\tTrain Loss: 3.901 | Train PPL:  49.444\n",
      "\tVal Loss: 3.554 |  Val PPL:  34.949\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.857518196105957\n",
      "Epoch: 1710\n",
      "\tTrain Loss: 3.858 | Train PPL:  47.348\n",
      "\tVal Loss: 3.553 |  Val PPL:  34.913\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.875699281692505\n",
      "Epoch: 1711\n",
      "\tTrain Loss: 3.876 | Train PPL:  48.216\n",
      "\tVal Loss: 3.552 |  Val PPL:  34.890\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8487203121185303\n",
      "Epoch: 1712\n",
      "\tTrain Loss: 3.849 | Train PPL:  46.933\n",
      "\tVal Loss: 3.552 |  Val PPL:  34.884\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8347153663635254\n",
      "Epoch: 1713\n",
      "\tTrain Loss: 3.835 | Train PPL:  46.280\n",
      "\tVal Loss: 3.552 |  Val PPL:  34.877\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8659374713897705\n",
      "Epoch: 1714\n",
      "\tTrain Loss: 3.866 | Train PPL:  47.748\n",
      "\tVal Loss: 3.551 |  Val PPL:  34.865\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.874298572540283\n",
      "Epoch: 1715\n",
      "\tTrain Loss: 3.874 | Train PPL:  48.149\n",
      "\tVal Loss: 3.552 |  Val PPL:  34.870\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.847531795501709\n",
      "Epoch: 1716\n",
      "\tTrain Loss: 3.848 | Train PPL:  46.877\n",
      "\tVal Loss: 3.552 |  Val PPL:  34.881\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8447837829589844\n",
      "Epoch: 1717\n",
      "\tTrain Loss: 3.845 | Train PPL:  46.749\n",
      "\tVal Loss: 3.553 |  Val PPL:  34.904\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.87066912651062\n",
      "Epoch: 1718\n",
      "\tTrain Loss: 3.871 | Train PPL:  47.974\n",
      "\tVal Loss: 3.553 |  Val PPL:  34.914\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8547322750091553\n",
      "Epoch: 1719\n",
      "\tTrain Loss: 3.855 | Train PPL:  47.216\n",
      "\tVal Loss: 3.553 |  Val PPL:  34.921\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.840081214904785\n",
      "Epoch: 1720\n",
      "\tTrain Loss: 3.840 | Train PPL:  46.529\n",
      "\tVal Loss: 3.554 |  Val PPL:  34.941\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8299484252929688\n",
      "Epoch: 1721\n",
      "\tTrain Loss: 3.830 | Train PPL:  46.060\n",
      "\tVal Loss: 3.554 |  Val PPL:  34.953\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8552186489105225\n",
      "Epoch: 1722\n",
      "\tTrain Loss: 3.855 | Train PPL:  47.239\n",
      "\tVal Loss: 3.554 |  Val PPL:  34.943\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.849771738052368\n",
      "Epoch: 1723\n",
      "\tTrain Loss: 3.850 | Train PPL:  46.982\n",
      "\tVal Loss: 3.553 |  Val PPL:  34.927\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.850511312484741\n",
      "Epoch: 1724\n",
      "\tTrain Loss: 3.851 | Train PPL:  47.017\n",
      "\tVal Loss: 3.553 |  Val PPL:  34.930\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8519630432128906\n",
      "Epoch: 1725\n",
      "\tTrain Loss: 3.852 | Train PPL:  47.085\n",
      "\tVal Loss: 3.553 |  Val PPL:  34.909\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8534247875213623\n",
      "Epoch: 1726\n",
      "\tTrain Loss: 3.853 | Train PPL:  47.154\n",
      "\tVal Loss: 3.553 |  Val PPL:  34.906\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.888115167617798\n",
      "Epoch: 1727\n",
      "\tTrain Loss: 3.888 | Train PPL:  48.819\n",
      "\tVal Loss: 3.553 |  Val PPL:  34.915\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.880063056945801\n",
      "Epoch: 1728\n",
      "\tTrain Loss: 3.880 | Train PPL:  48.427\n",
      "\tVal Loss: 3.553 |  Val PPL:  34.923\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.872310161590576\n",
      "Epoch: 1729\n",
      "\tTrain Loss: 3.872 | Train PPL:  48.053\n",
      "\tVal Loss: 3.553 |  Val PPL:  34.923\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.857288122177124\n",
      "Epoch: 1730\n",
      "\tTrain Loss: 3.857 | Train PPL:  47.337\n",
      "\tVal Loss: 3.552 |  Val PPL:  34.899\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8575406074523926\n",
      "Epoch: 1731\n",
      "\tTrain Loss: 3.858 | Train PPL:  47.349\n",
      "\tVal Loss: 3.551 |  Val PPL:  34.860\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.862626075744629\n",
      "Epoch: 1732\n",
      "\tTrain Loss: 3.863 | Train PPL:  47.590\n",
      "\tVal Loss: 3.551 |  Val PPL:  34.838\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8568851947784424\n",
      "Epoch: 1733\n",
      "\tTrain Loss: 3.857 | Train PPL:  47.318\n",
      "\tVal Loss: 3.550 |  Val PPL:  34.817\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.871967077255249\n",
      "Epoch: 1734\n",
      "\tTrain Loss: 3.872 | Train PPL:  48.037\n",
      "\tVal Loss: 3.549 |  Val PPL:  34.785\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.858292818069458\n",
      "Epoch: 1735\n",
      "\tTrain Loss: 3.858 | Train PPL:  47.384\n",
      "\tVal Loss: 3.549 |  Val PPL:  34.763\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8359763622283936\n",
      "Epoch: 1736\n",
      "\tTrain Loss: 3.836 | Train PPL:  46.339\n",
      "\tVal Loss: 3.548 |  Val PPL:  34.745\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8550961017608643\n",
      "Epoch: 1737\n",
      "\tTrain Loss: 3.855 | Train PPL:  47.233\n",
      "\tVal Loss: 3.548 |  Val PPL:  34.749\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.852473258972168\n",
      "Epoch: 1738\n",
      "\tTrain Loss: 3.852 | Train PPL:  47.109\n",
      "\tVal Loss: 3.548 |  Val PPL:  34.758\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.82781982421875\n",
      "Epoch: 1739\n",
      "\tTrain Loss: 3.828 | Train PPL:  45.962\n",
      "\tVal Loss: 3.549 |  Val PPL:  34.776\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8386595249176025\n",
      "Epoch: 1740\n",
      "\tTrain Loss: 3.839 | Train PPL:  46.463\n",
      "\tVal Loss: 3.549 |  Val PPL:  34.777\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8554251194000244\n",
      "Epoch: 1741\n",
      "\tTrain Loss: 3.855 | Train PPL:  47.249\n",
      "\tVal Loss: 3.549 |  Val PPL:  34.772\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.889338493347168\n",
      "Epoch: 1742\n",
      "\tTrain Loss: 3.889 | Train PPL:  48.879\n",
      "\tVal Loss: 3.548 |  Val PPL:  34.750\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.848792552947998\n",
      "Epoch: 1743\n",
      "\tTrain Loss: 3.849 | Train PPL:  46.936\n",
      "\tVal Loss: 3.547 |  Val PPL:  34.713\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.834462881088257\n",
      "Epoch: 1744\n",
      "\tTrain Loss: 3.834 | Train PPL:  46.269\n",
      "\tVal Loss: 3.546 |  Val PPL:  34.681\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.840507984161377\n",
      "Epoch: 1745\n",
      "\tTrain Loss: 3.841 | Train PPL:  46.549\n",
      "\tVal Loss: 3.545 |  Val PPL:  34.633\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.828260660171509\n",
      "Epoch: 1746\n",
      "\tTrain Loss: 3.828 | Train PPL:  45.982\n",
      "\tVal Loss: 3.544 |  Val PPL:  34.603\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.864414930343628\n",
      "Epoch: 1747\n",
      "\tTrain Loss: 3.864 | Train PPL:  47.675\n",
      "\tVal Loss: 3.543 |  Val PPL:  34.563\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8514773845672607\n",
      "Epoch: 1748\n",
      "\tTrain Loss: 3.851 | Train PPL:  47.063\n",
      "\tVal Loss: 3.542 |  Val PPL:  34.530\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8273558616638184\n",
      "Epoch: 1749\n",
      "\tTrain Loss: 3.827 | Train PPL:  45.941\n",
      "\tVal Loss: 3.541 |  Val PPL:  34.511\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8227195739746094\n",
      "Epoch: 1750\n",
      "\tTrain Loss: 3.823 | Train PPL:  45.728\n",
      "\tVal Loss: 3.541 |  Val PPL:  34.504\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.842639923095703\n",
      "Epoch: 1751\n",
      "\tTrain Loss: 3.843 | Train PPL:  46.648\n",
      "\tVal Loss: 3.541 |  Val PPL:  34.498\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.850033760070801\n",
      "Epoch: 1752\n",
      "\tTrain Loss: 3.850 | Train PPL:  46.995\n",
      "\tVal Loss: 3.540 |  Val PPL:  34.477\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8351845741271973\n",
      "Epoch: 1753\n",
      "\tTrain Loss: 3.835 | Train PPL:  46.302\n",
      "\tVal Loss: 3.540 |  Val PPL:  34.466\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.853180170059204\n",
      "Epoch: 1754\n",
      "\tTrain Loss: 3.853 | Train PPL:  47.143\n",
      "\tVal Loss: 3.540 |  Val PPL:  34.477\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8303403854370117\n",
      "Epoch: 1755\n",
      "\tTrain Loss: 3.830 | Train PPL:  46.078\n",
      "\tVal Loss: 3.541 |  Val PPL:  34.486\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8389015197753906\n",
      "Epoch: 1756\n",
      "\tTrain Loss: 3.839 | Train PPL:  46.474\n",
      "\tVal Loss: 3.541 |  Val PPL:  34.497\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8509907722473145\n",
      "Epoch: 1757\n",
      "\tTrain Loss: 3.851 | Train PPL:  47.040\n",
      "\tVal Loss: 3.541 |  Val PPL:  34.513\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8760194778442383\n",
      "Epoch: 1758\n",
      "\tTrain Loss: 3.876 | Train PPL:  48.232\n",
      "\tVal Loss: 3.541 |  Val PPL:  34.517\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.87187123298645\n",
      "Epoch: 1759\n",
      "\tTrain Loss: 3.872 | Train PPL:  48.032\n",
      "\tVal Loss: 3.542 |  Val PPL:  34.522\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8313167095184326\n",
      "Epoch: 1760\n",
      "\tTrain Loss: 3.831 | Train PPL:  46.123\n",
      "\tVal Loss: 3.542 |  Val PPL:  34.534\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8241844177246094\n",
      "Epoch: 1761\n",
      "\tTrain Loss: 3.824 | Train PPL:  45.795\n",
      "\tVal Loss: 3.542 |  Val PPL:  34.544\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8338491916656494\n",
      "Epoch: 1762\n",
      "\tTrain Loss: 3.834 | Train PPL:  46.240\n",
      "\tVal Loss: 3.542 |  Val PPL:  34.547\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8505334854125977\n",
      "Epoch: 1763\n",
      "\tTrain Loss: 3.851 | Train PPL:  47.018\n",
      "\tVal Loss: 3.542 |  Val PPL:  34.534\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.849579334259033\n",
      "Epoch: 1764\n",
      "\tTrain Loss: 3.850 | Train PPL:  46.973\n",
      "\tVal Loss: 3.541 |  Val PPL:  34.513\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8366811275482178\n",
      "Epoch: 1765\n",
      "\tTrain Loss: 3.837 | Train PPL:  46.371\n",
      "\tVal Loss: 3.540 |  Val PPL:  34.456\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.855196952819824\n",
      "Epoch: 1766\n",
      "\tTrain Loss: 3.855 | Train PPL:  47.238\n",
      "\tVal Loss: 3.538 |  Val PPL:  34.403\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.883453369140625\n",
      "Epoch: 1767\n",
      "\tTrain Loss: 3.883 | Train PPL:  48.592\n",
      "\tVal Loss: 3.537 |  Val PPL:  34.367\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.817765235900879\n",
      "Epoch: 1768\n",
      "\tTrain Loss: 3.818 | Train PPL:  45.502\n",
      "\tVal Loss: 3.536 |  Val PPL:  34.317\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.843440294265747\n",
      "Epoch: 1769\n",
      "\tTrain Loss: 3.843 | Train PPL:  46.686\n",
      "\tVal Loss: 3.534 |  Val PPL:  34.270\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.849912166595459\n",
      "Epoch: 1770\n",
      "\tTrain Loss: 3.850 | Train PPL:  46.989\n",
      "\tVal Loss: 3.533 |  Val PPL:  34.226\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8353183269500732\n",
      "Epoch: 1771\n",
      "\tTrain Loss: 3.835 | Train PPL:  46.308\n",
      "\tVal Loss: 3.532 |  Val PPL:  34.204\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802327871322632\n",
      "Epoch: 1772\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.805\n",
      "\tVal Loss: 3.532 |  Val PPL:  34.184\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8567936420440674\n",
      "Epoch: 1773\n",
      "\tTrain Loss: 3.857 | Train PPL:  47.313\n",
      "\tVal Loss: 3.531 |  Val PPL:  34.175\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8361527919769287\n",
      "Epoch: 1774\n",
      "\tTrain Loss: 3.836 | Train PPL:  46.347\n",
      "\tVal Loss: 3.531 |  Val PPL:  34.173\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8366293907165527\n",
      "Epoch: 1775\n",
      "\tTrain Loss: 3.837 | Train PPL:  46.369\n",
      "\tVal Loss: 3.531 |  Val PPL:  34.160\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.851191520690918\n",
      "Epoch: 1776\n",
      "\tTrain Loss: 3.851 | Train PPL:  47.049\n",
      "\tVal Loss: 3.531 |  Val PPL:  34.162\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8380353450775146\n",
      "Epoch: 1777\n",
      "\tTrain Loss: 3.838 | Train PPL:  46.434\n",
      "\tVal Loss: 3.531 |  Val PPL:  34.165\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8252084255218506\n",
      "Epoch: 1778\n",
      "\tTrain Loss: 3.825 | Train PPL:  45.842\n",
      "\tVal Loss: 3.532 |  Val PPL:  34.181\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.844322443008423\n",
      "Epoch: 1779\n",
      "\tTrain Loss: 3.844 | Train PPL:  46.727\n",
      "\tVal Loss: 3.532 |  Val PPL:  34.205\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8262102603912354\n",
      "Epoch: 1780\n",
      "\tTrain Loss: 3.826 | Train PPL:  45.888\n",
      "\tVal Loss: 3.533 |  Val PPL:  34.240\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8670990467071533\n",
      "Epoch: 1781\n",
      "\tTrain Loss: 3.867 | Train PPL:  47.804\n",
      "\tVal Loss: 3.535 |  Val PPL:  34.282\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.837388277053833\n",
      "Epoch: 1782\n",
      "\tTrain Loss: 3.837 | Train PPL:  46.404\n",
      "\tVal Loss: 3.536 |  Val PPL:  34.317\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.84401273727417\n",
      "Epoch: 1783\n",
      "\tTrain Loss: 3.844 | Train PPL:  46.713\n",
      "\tVal Loss: 3.536 |  Val PPL:  34.340\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.839123487472534\n",
      "Epoch: 1784\n",
      "\tTrain Loss: 3.839 | Train PPL:  46.485\n",
      "\tVal Loss: 3.536 |  Val PPL:  34.338\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8396191596984863\n",
      "Epoch: 1785\n",
      "\tTrain Loss: 3.840 | Train PPL:  46.508\n",
      "\tVal Loss: 3.535 |  Val PPL:  34.296\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.861389398574829\n",
      "Epoch: 1786\n",
      "\tTrain Loss: 3.861 | Train PPL:  47.531\n",
      "\tVal Loss: 3.534 |  Val PPL:  34.253\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.815701723098755\n",
      "Epoch: 1787\n",
      "\tTrain Loss: 3.816 | Train PPL:  45.409\n",
      "\tVal Loss: 3.533 |  Val PPL:  34.225\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.846240282058716\n",
      "Epoch: 1788\n",
      "\tTrain Loss: 3.846 | Train PPL:  46.817\n",
      "\tVal Loss: 3.532 |  Val PPL:  34.192\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8556947708129883\n",
      "Epoch: 1789\n",
      "\tTrain Loss: 3.856 | Train PPL:  47.261\n",
      "\tVal Loss: 3.531 |  Val PPL:  34.152\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8369321823120117\n",
      "Epoch: 1790\n",
      "\tTrain Loss: 3.837 | Train PPL:  46.383\n",
      "\tVal Loss: 3.530 |  Val PPL:  34.117\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.836266279220581\n",
      "Epoch: 1791\n",
      "\tTrain Loss: 3.836 | Train PPL:  46.352\n",
      "\tVal Loss: 3.529 |  Val PPL:  34.079\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8525261878967285\n",
      "Epoch: 1792\n",
      "\tTrain Loss: 3.853 | Train PPL:  47.112\n",
      "\tVal Loss: 3.528 |  Val PPL:  34.055\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8469254970550537\n",
      "Epoch: 1793\n",
      "\tTrain Loss: 3.847 | Train PPL:  46.849\n",
      "\tVal Loss: 3.527 |  Val PPL:  34.024\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8216819763183594\n",
      "Epoch: 1794\n",
      "\tTrain Loss: 3.822 | Train PPL:  45.681\n",
      "\tVal Loss: 3.526 |  Val PPL:  33.987\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.831761598587036\n",
      "Epoch: 1795\n",
      "\tTrain Loss: 3.832 | Train PPL:  46.144\n",
      "\tVal Loss: 3.525 |  Val PPL:  33.960\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.850480794906616\n",
      "Epoch: 1796\n",
      "\tTrain Loss: 3.850 | Train PPL:  47.016\n",
      "\tVal Loss: 3.524 |  Val PPL:  33.931\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8135745525360107\n",
      "Epoch: 1797\n",
      "\tTrain Loss: 3.814 | Train PPL:  45.312\n",
      "\tVal Loss: 3.524 |  Val PPL:  33.915\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8305704593658447\n",
      "Epoch: 1798\n",
      "\tTrain Loss: 3.831 | Train PPL:  46.089\n",
      "\tVal Loss: 3.524 |  Val PPL:  33.915\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.817244052886963\n",
      "Epoch: 1799\n",
      "\tTrain Loss: 3.817 | Train PPL:  45.479\n",
      "\tVal Loss: 3.524 |  Val PPL:  33.933\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8327443599700928\n",
      "Epoch: 1800\n",
      "\tTrain Loss: 3.833 | Train PPL:  46.189\n",
      "\tVal Loss: 3.526 |  Val PPL:  33.972\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8397176265716553\n",
      "Epoch: 1801\n",
      "\tTrain Loss: 3.840 | Train PPL:  46.512\n",
      "\tVal Loss: 3.526 |  Val PPL:  34.003\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8438880443573\n",
      "Epoch: 1802\n",
      "\tTrain Loss: 3.844 | Train PPL:  46.707\n",
      "\tVal Loss: 3.527 |  Val PPL:  34.030\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.829747438430786\n",
      "Epoch: 1803\n",
      "\tTrain Loss: 3.830 | Train PPL:  46.051\n",
      "\tVal Loss: 3.528 |  Val PPL:  34.055\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8363406658172607\n",
      "Epoch: 1804\n",
      "\tTrain Loss: 3.836 | Train PPL:  46.356\n",
      "\tVal Loss: 3.529 |  Val PPL:  34.074\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.824343204498291\n",
      "Epoch: 1805\n",
      "\tTrain Loss: 3.824 | Train PPL:  45.803\n",
      "\tVal Loss: 3.529 |  Val PPL:  34.081\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.814748764038086\n",
      "Epoch: 1806\n",
      "\tTrain Loss: 3.815 | Train PPL:  45.365\n",
      "\tVal Loss: 3.529 |  Val PPL:  34.089\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8261983394622803\n",
      "Epoch: 1807\n",
      "\tTrain Loss: 3.826 | Train PPL:  45.888\n",
      "\tVal Loss: 3.529 |  Val PPL:  34.092\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8177273273468018\n",
      "Epoch: 1808\n",
      "\tTrain Loss: 3.818 | Train PPL:  45.501\n",
      "\tVal Loss: 3.529 |  Val PPL:  34.107\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802640914916992\n",
      "Epoch: 1809\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.819\n",
      "\tVal Loss: 3.529 |  Val PPL:  34.104\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8271448612213135\n",
      "Epoch: 1810\n",
      "\tTrain Loss: 3.827 | Train PPL:  45.931\n",
      "\tVal Loss: 3.529 |  Val PPL:  34.092\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8563039302825928\n",
      "Epoch: 1811\n",
      "\tTrain Loss: 3.856 | Train PPL:  47.290\n",
      "\tVal Loss: 3.528 |  Val PPL:  34.057\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8325562477111816\n",
      "Epoch: 1812\n",
      "\tTrain Loss: 3.833 | Train PPL:  46.180\n",
      "\tVal Loss: 3.527 |  Val PPL:  34.014\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.859834671020508\n",
      "Epoch: 1813\n",
      "\tTrain Loss: 3.860 | Train PPL:  47.458\n",
      "\tVal Loss: 3.526 |  Val PPL:  33.982\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8048267364501953\n",
      "Epoch: 1814\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.917\n",
      "\tVal Loss: 3.525 |  Val PPL:  33.968\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.837212324142456\n",
      "Epoch: 1815\n",
      "\tTrain Loss: 3.837 | Train PPL:  46.396\n",
      "\tVal Loss: 3.525 |  Val PPL:  33.962\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.851635694503784\n",
      "Epoch: 1816\n",
      "\tTrain Loss: 3.852 | Train PPL:  47.070\n",
      "\tVal Loss: 3.525 |  Val PPL:  33.956\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.839860439300537\n",
      "Epoch: 1817\n",
      "\tTrain Loss: 3.840 | Train PPL:  46.519\n",
      "\tVal Loss: 3.525 |  Val PPL:  33.961\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8312737941741943\n",
      "Epoch: 1818\n",
      "\tTrain Loss: 3.831 | Train PPL:  46.121\n",
      "\tVal Loss: 3.525 |  Val PPL:  33.954\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.83268666267395\n",
      "Epoch: 1819\n",
      "\tTrain Loss: 3.833 | Train PPL:  46.186\n",
      "\tVal Loss: 3.525 |  Val PPL:  33.949\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8194684982299805\n",
      "Epoch: 1820\n",
      "\tTrain Loss: 3.819 | Train PPL:  45.580\n",
      "\tVal Loss: 3.524 |  Val PPL:  33.932\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8316948413848877\n",
      "Epoch: 1821\n",
      "\tTrain Loss: 3.832 | Train PPL:  46.141\n",
      "\tVal Loss: 3.524 |  Val PPL:  33.916\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.820729970932007\n",
      "Epoch: 1822\n",
      "\tTrain Loss: 3.821 | Train PPL:  45.638\n",
      "\tVal Loss: 3.523 |  Val PPL:  33.898\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8360159397125244\n",
      "Epoch: 1823\n",
      "\tTrain Loss: 3.836 | Train PPL:  46.340\n",
      "\tVal Loss: 3.523 |  Val PPL:  33.870\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.810598134994507\n",
      "Epoch: 1824\n",
      "\tTrain Loss: 3.811 | Train PPL:  45.177\n",
      "\tVal Loss: 3.521 |  Val PPL:  33.826\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.842700719833374\n",
      "Epoch: 1825\n",
      "\tTrain Loss: 3.843 | Train PPL:  46.651\n",
      "\tVal Loss: 3.520 |  Val PPL:  33.784\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.835275650024414\n",
      "Epoch: 1826\n",
      "\tTrain Loss: 3.835 | Train PPL:  46.306\n",
      "\tVal Loss: 3.519 |  Val PPL:  33.747\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.859984874725342\n",
      "Epoch: 1827\n",
      "\tTrain Loss: 3.860 | Train PPL:  47.465\n",
      "\tVal Loss: 3.518 |  Val PPL:  33.710\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8124351501464844\n",
      "Epoch: 1828\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.261\n",
      "\tVal Loss: 3.517 |  Val PPL:  33.679\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8276920318603516\n",
      "Epoch: 1829\n",
      "\tTrain Loss: 3.828 | Train PPL:  45.956\n",
      "\tVal Loss: 3.516 |  Val PPL:  33.653\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.847829580307007\n",
      "Epoch: 1830\n",
      "\tTrain Loss: 3.848 | Train PPL:  46.891\n",
      "\tVal Loss: 3.515 |  Val PPL:  33.621\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8242921829223633\n",
      "Epoch: 1831\n",
      "\tTrain Loss: 3.824 | Train PPL:  45.800\n",
      "\tVal Loss: 3.514 |  Val PPL:  33.599\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8385064601898193\n",
      "Epoch: 1832\n",
      "\tTrain Loss: 3.839 | Train PPL:  46.456\n",
      "\tVal Loss: 3.514 |  Val PPL:  33.585\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.822187900543213\n",
      "Epoch: 1833\n",
      "\tTrain Loss: 3.822 | Train PPL:  45.704\n",
      "\tVal Loss: 3.514 |  Val PPL:  33.579\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.818795919418335\n",
      "Epoch: 1834\n",
      "\tTrain Loss: 3.819 | Train PPL:  45.549\n",
      "\tVal Loss: 3.514 |  Val PPL:  33.576\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.823528289794922\n",
      "Epoch: 1835\n",
      "\tTrain Loss: 3.824 | Train PPL:  45.765\n",
      "\tVal Loss: 3.514 |  Val PPL:  33.579\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.828611373901367\n",
      "Epoch: 1836\n",
      "\tTrain Loss: 3.829 | Train PPL:  45.999\n",
      "\tVal Loss: 3.514 |  Val PPL:  33.586\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.828108072280884\n",
      "Epoch: 1837\n",
      "\tTrain Loss: 3.828 | Train PPL:  45.975\n",
      "\tVal Loss: 3.514 |  Val PPL:  33.597\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.808887004852295\n",
      "Epoch: 1838\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.100\n",
      "\tVal Loss: 3.515 |  Val PPL:  33.601\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8438334465026855\n",
      "Epoch: 1839\n",
      "\tTrain Loss: 3.844 | Train PPL:  46.704\n",
      "\tVal Loss: 3.514 |  Val PPL:  33.598\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.810572624206543\n",
      "Epoch: 1840\n",
      "\tTrain Loss: 3.811 | Train PPL:  45.176\n",
      "\tVal Loss: 3.514 |  Val PPL:  33.593\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.835883617401123\n",
      "Epoch: 1841\n",
      "\tTrain Loss: 3.836 | Train PPL:  46.334\n",
      "\tVal Loss: 3.514 |  Val PPL:  33.595\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8222906589508057\n",
      "Epoch: 1842\n",
      "\tTrain Loss: 3.822 | Train PPL:  45.709\n",
      "\tVal Loss: 3.515 |  Val PPL:  33.600\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8437275886535645\n",
      "Epoch: 1843\n",
      "\tTrain Loss: 3.844 | Train PPL:  46.699\n",
      "\tVal Loss: 3.515 |  Val PPL:  33.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.812110185623169\n",
      "Epoch: 1844\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.246\n",
      "\tVal Loss: 3.516 |  Val PPL:  33.635\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.844754695892334\n",
      "Epoch: 1845\n",
      "\tTrain Loss: 3.845 | Train PPL:  46.747\n",
      "\tVal Loss: 3.517 |  Val PPL:  33.673\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.830538749694824\n",
      "Epoch: 1846\n",
      "\tTrain Loss: 3.831 | Train PPL:  46.087\n",
      "\tVal Loss: 3.518 |  Val PPL:  33.711\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8025989532470703\n",
      "Epoch: 1847\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.818\n",
      "\tVal Loss: 3.519 |  Val PPL:  33.736\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8224644660949707\n",
      "Epoch: 1848\n",
      "\tTrain Loss: 3.822 | Train PPL:  45.717\n",
      "\tVal Loss: 3.519 |  Val PPL:  33.745\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8165948390960693\n",
      "Epoch: 1849\n",
      "\tTrain Loss: 3.817 | Train PPL:  45.449\n",
      "\tVal Loss: 3.519 |  Val PPL:  33.745\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.841517448425293\n",
      "Epoch: 1850\n",
      "\tTrain Loss: 3.842 | Train PPL:  46.596\n",
      "\tVal Loss: 3.518 |  Val PPL:  33.733\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7988204956054688\n",
      "Epoch: 1851\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.648\n",
      "\tVal Loss: 3.518 |  Val PPL:  33.725\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8267083168029785\n",
      "Epoch: 1852\n",
      "\tTrain Loss: 3.827 | Train PPL:  45.911\n",
      "\tVal Loss: 3.518 |  Val PPL:  33.709\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8215372562408447\n",
      "Epoch: 1853\n",
      "\tTrain Loss: 3.822 | Train PPL:  45.674\n",
      "\tVal Loss: 3.517 |  Val PPL:  33.694\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.835906982421875\n",
      "Epoch: 1854\n",
      "\tTrain Loss: 3.836 | Train PPL:  46.335\n",
      "\tVal Loss: 3.517 |  Val PPL:  33.674\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.82452392578125\n",
      "Epoch: 1855\n",
      "\tTrain Loss: 3.825 | Train PPL:  45.811\n",
      "\tVal Loss: 3.516 |  Val PPL:  33.651\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8129806518554688\n",
      "Epoch: 1856\n",
      "\tTrain Loss: 3.813 | Train PPL:  45.285\n",
      "\tVal Loss: 3.515 |  Val PPL:  33.627\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8385090827941895\n",
      "Epoch: 1857\n",
      "\tTrain Loss: 3.839 | Train PPL:  46.456\n",
      "\tVal Loss: 3.514 |  Val PPL:  33.590\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.834667682647705\n",
      "Epoch: 1858\n",
      "\tTrain Loss: 3.835 | Train PPL:  46.278\n",
      "\tVal Loss: 3.513 |  Val PPL:  33.546\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.795551300048828\n",
      "Epoch: 1859\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.503\n",
      "\tVal Loss: 3.512 |  Val PPL:  33.507\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.801985502243042\n",
      "Epoch: 1860\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.790\n",
      "\tVal Loss: 3.511 |  Val PPL:  33.472\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.851095676422119\n",
      "Epoch: 1861\n",
      "\tTrain Loss: 3.851 | Train PPL:  47.045\n",
      "\tVal Loss: 3.510 |  Val PPL:  33.440\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.82851243019104\n",
      "Epoch: 1862\n",
      "\tTrain Loss: 3.829 | Train PPL:  45.994\n",
      "\tVal Loss: 3.509 |  Val PPL:  33.408\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.81485652923584\n",
      "Epoch: 1863\n",
      "\tTrain Loss: 3.815 | Train PPL:  45.370\n",
      "\tVal Loss: 3.508 |  Val PPL:  33.380\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8308823108673096\n",
      "Epoch: 1864\n",
      "\tTrain Loss: 3.831 | Train PPL:  46.103\n",
      "\tVal Loss: 3.507 |  Val PPL:  33.349\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7952404022216797\n",
      "Epoch: 1865\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.489\n",
      "\tVal Loss: 3.506 |  Val PPL:  33.326\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8132717609405518\n",
      "Epoch: 1866\n",
      "\tTrain Loss: 3.813 | Train PPL:  45.298\n",
      "\tVal Loss: 3.506 |  Val PPL:  33.317\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8400158882141113\n",
      "Epoch: 1867\n",
      "\tTrain Loss: 3.840 | Train PPL:  46.526\n",
      "\tVal Loss: 3.506 |  Val PPL:  33.305\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8410534858703613\n",
      "Epoch: 1868\n",
      "\tTrain Loss: 3.841 | Train PPL:  46.575\n",
      "\tVal Loss: 3.506 |  Val PPL:  33.308\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.793492555618286\n",
      "Epoch: 1869\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.411\n",
      "\tVal Loss: 3.506 |  Val PPL:  33.315\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.836756706237793\n",
      "Epoch: 1870\n",
      "\tTrain Loss: 3.837 | Train PPL:  46.375\n",
      "\tVal Loss: 3.506 |  Val PPL:  33.324\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7828476428985596\n",
      "Epoch: 1871\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.941\n",
      "\tVal Loss: 3.506 |  Val PPL:  33.330\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8060059547424316\n",
      "Epoch: 1872\n",
      "\tTrain Loss: 3.806 | Train PPL:  44.970\n",
      "\tVal Loss: 3.507 |  Val PPL:  33.333\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.866713285446167\n",
      "Epoch: 1873\n",
      "\tTrain Loss: 3.867 | Train PPL:  47.785\n",
      "\tVal Loss: 3.506 |  Val PPL:  33.330\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.829528331756592\n",
      "Epoch: 1874\n",
      "\tTrain Loss: 3.830 | Train PPL:  46.041\n",
      "\tVal Loss: 3.506 |  Val PPL:  33.331\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.818145275115967\n",
      "Epoch: 1875\n",
      "\tTrain Loss: 3.818 | Train PPL:  45.520\n",
      "\tVal Loss: 3.507 |  Val PPL:  33.338\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.820265293121338\n",
      "Epoch: 1876\n",
      "\tTrain Loss: 3.820 | Train PPL:  45.616\n",
      "\tVal Loss: 3.507 |  Val PPL:  33.343\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8022255897521973\n",
      "Epoch: 1877\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.801\n",
      "\tVal Loss: 3.507 |  Val PPL:  33.353\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.816009283065796\n",
      "Epoch: 1878\n",
      "\tTrain Loss: 3.816 | Train PPL:  45.423\n",
      "\tVal Loss: 3.507 |  Val PPL:  33.360\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7867164611816406\n",
      "Epoch: 1879\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.111\n",
      "\tVal Loss: 3.508 |  Val PPL:  33.366\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8189644813537598\n",
      "Epoch: 1880\n",
      "\tTrain Loss: 3.819 | Train PPL:  45.557\n",
      "\tVal Loss: 3.508 |  Val PPL:  33.376\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8033413887023926\n",
      "Epoch: 1881\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.851\n",
      "\tVal Loss: 3.508 |  Val PPL:  33.380\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8324151039123535\n",
      "Epoch: 1882\n",
      "\tTrain Loss: 3.832 | Train PPL:  46.174\n",
      "\tVal Loss: 3.508 |  Val PPL:  33.384\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8333775997161865\n",
      "Epoch: 1883\n",
      "\tTrain Loss: 3.833 | Train PPL:  46.218\n",
      "\tVal Loss: 3.508 |  Val PPL:  33.386\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.822747230529785\n",
      "Epoch: 1884\n",
      "\tTrain Loss: 3.823 | Train PPL:  45.730\n",
      "\tVal Loss: 3.508 |  Val PPL:  33.382\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8177878856658936\n",
      "Epoch: 1885\n",
      "\tTrain Loss: 3.818 | Train PPL:  45.503\n",
      "\tVal Loss: 3.507 |  Val PPL:  33.364\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8294286727905273\n",
      "Epoch: 1886\n",
      "\tTrain Loss: 3.829 | Train PPL:  46.036\n",
      "\tVal Loss: 3.507 |  Val PPL:  33.354\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.824711322784424\n",
      "Epoch: 1887\n",
      "\tTrain Loss: 3.825 | Train PPL:  45.820\n",
      "\tVal Loss: 3.507 |  Val PPL:  33.340\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.800215005874634\n",
      "Epoch: 1888\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.711\n",
      "\tVal Loss: 3.506 |  Val PPL:  33.322\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.830415964126587\n",
      "Epoch: 1889\n",
      "\tTrain Loss: 3.830 | Train PPL:  46.082\n",
      "\tVal Loss: 3.506 |  Val PPL:  33.306\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8051252365112305\n",
      "Epoch: 1890\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.931\n",
      "\tVal Loss: 3.505 |  Val PPL:  33.291\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8256378173828125\n",
      "Epoch: 1891\n",
      "\tTrain Loss: 3.826 | Train PPL:  45.862\n",
      "\tVal Loss: 3.505 |  Val PPL:  33.280\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8017373085021973\n",
      "Epoch: 1892\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.779\n",
      "\tVal Loss: 3.504 |  Val PPL:  33.263\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.812265634536743\n",
      "Epoch: 1893\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.253\n",
      "\tVal Loss: 3.504 |  Val PPL:  33.259\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.818510055541992\n",
      "Epoch: 1894\n",
      "\tTrain Loss: 3.819 | Train PPL:  45.536\n",
      "\tVal Loss: 3.504 |  Val PPL:  33.256\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.818561553955078\n",
      "Epoch: 1895\n",
      "\tTrain Loss: 3.819 | Train PPL:  45.539\n",
      "\tVal Loss: 3.504 |  Val PPL:  33.251\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.807380437850952\n",
      "Epoch: 1896\n",
      "\tTrain Loss: 3.807 | Train PPL:  45.032\n",
      "\tVal Loss: 3.504 |  Val PPL:  33.256\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.814279794692993\n",
      "Epoch: 1897\n",
      "\tTrain Loss: 3.814 | Train PPL:  45.344\n",
      "\tVal Loss: 3.505 |  Val PPL:  33.267\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8215231895446777\n",
      "Epoch: 1898\n",
      "\tTrain Loss: 3.822 | Train PPL:  45.674\n",
      "\tVal Loss: 3.505 |  Val PPL:  33.275\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.782144784927368\n",
      "Epoch: 1899\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.910\n",
      "\tVal Loss: 3.505 |  Val PPL:  33.285\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802121162414551\n",
      "Epoch: 1900\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.796\n",
      "\tVal Loss: 3.505 |  Val PPL:  33.288\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.821113109588623\n",
      "Epoch: 1901\n",
      "\tTrain Loss: 3.821 | Train PPL:  45.655\n",
      "\tVal Loss: 3.505 |  Val PPL:  33.292\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7898149490356445\n",
      "Epoch: 1902\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.248\n",
      "\tVal Loss: 3.505 |  Val PPL:  33.292\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.807164430618286\n",
      "Epoch: 1903\n",
      "\tTrain Loss: 3.807 | Train PPL:  45.023\n",
      "\tVal Loss: 3.505 |  Val PPL:  33.286\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.809964418411255\n",
      "Epoch: 1904\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.149\n",
      "\tVal Loss: 3.505 |  Val PPL:  33.280\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.819365978240967\n",
      "Epoch: 1905\n",
      "\tTrain Loss: 3.819 | Train PPL:  45.575\n",
      "\tVal Loss: 3.505 |  Val PPL:  33.273\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8178207874298096\n",
      "Epoch: 1906\n",
      "\tTrain Loss: 3.818 | Train PPL:  45.505\n",
      "\tVal Loss: 3.504 |  Val PPL:  33.261\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8183131217956543\n",
      "Epoch: 1907\n",
      "\tTrain Loss: 3.818 | Train PPL:  45.527\n",
      "\tVal Loss: 3.504 |  Val PPL:  33.249\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.806633949279785\n",
      "Epoch: 1908\n",
      "\tTrain Loss: 3.807 | Train PPL:  44.999\n",
      "\tVal Loss: 3.504 |  Val PPL:  33.233\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8034615516662598\n",
      "Epoch: 1909\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.856\n",
      "\tVal Loss: 3.503 |  Val PPL:  33.217\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.799201011657715\n",
      "Epoch: 1910\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.665\n",
      "\tVal Loss: 3.503 |  Val PPL:  33.205\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.778909921646118\n",
      "Epoch: 1911\n",
      "\tTrain Loss: 3.779 | Train PPL:  43.768\n",
      "\tVal Loss: 3.502 |  Val PPL:  33.192\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8272223472595215\n",
      "Epoch: 1912\n",
      "\tTrain Loss: 3.827 | Train PPL:  45.935\n",
      "\tVal Loss: 3.502 |  Val PPL:  33.185\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8013103008270264\n",
      "Epoch: 1913\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.760\n",
      "\tVal Loss: 3.502 |  Val PPL:  33.180\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8020036220550537\n",
      "Epoch: 1914\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.791\n",
      "\tVal Loss: 3.502 |  Val PPL:  33.170\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.832143545150757\n",
      "Epoch: 1915\n",
      "\tTrain Loss: 3.832 | Train PPL:  46.161\n",
      "\tVal Loss: 3.501 |  Val PPL:  33.164\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.797175884246826\n",
      "Epoch: 1916\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.575\n",
      "\tVal Loss: 3.501 |  Val PPL:  33.157\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.835768461227417\n",
      "Epoch: 1917\n",
      "\tTrain Loss: 3.836 | Train PPL:  46.329\n",
      "\tVal Loss: 3.501 |  Val PPL:  33.146\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8010752201080322\n",
      "Epoch: 1918\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.749\n",
      "\tVal Loss: 3.500 |  Val PPL:  33.131\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7954676151275635\n",
      "Epoch: 1919\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.499\n",
      "\tVal Loss: 3.500 |  Val PPL:  33.128\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.844529628753662\n",
      "Epoch: 1920\n",
      "\tTrain Loss: 3.845 | Train PPL:  46.737\n",
      "\tVal Loss: 3.501 |  Val PPL:  33.135\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.810321092605591\n",
      "Epoch: 1921\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.165\n",
      "\tVal Loss: 3.501 |  Val PPL:  33.146\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.807898759841919\n",
      "Epoch: 1922\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.056\n",
      "\tVal Loss: 3.501 |  Val PPL:  33.159\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.822503089904785\n",
      "Epoch: 1923\n",
      "\tTrain Loss: 3.823 | Train PPL:  45.719\n",
      "\tVal Loss: 3.502 |  Val PPL:  33.175\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8189620971679688\n",
      "Epoch: 1924\n",
      "\tTrain Loss: 3.819 | Train PPL:  45.557\n",
      "\tVal Loss: 3.502 |  Val PPL:  33.192\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.786313533782959\n",
      "Epoch: 1925\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.094\n",
      "\tVal Loss: 3.503 |  Val PPL:  33.210\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7937796115875244\n",
      "Epoch: 1926\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.424\n",
      "\tVal Loss: 3.504 |  Val PPL:  33.234\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8091485500335693\n",
      "Epoch: 1927\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.112\n",
      "\tVal Loss: 3.504 |  Val PPL:  33.253\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8314146995544434\n",
      "Epoch: 1928\n",
      "\tTrain Loss: 3.831 | Train PPL:  46.128\n",
      "\tVal Loss: 3.505 |  Val PPL:  33.277\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7974841594696045\n",
      "Epoch: 1929\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.589\n",
      "\tVal Loss: 3.506 |  Val PPL:  33.305\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7882583141326904\n",
      "Epoch: 1930\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.179\n",
      "\tVal Loss: 3.506 |  Val PPL:  33.323\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.783409595489502\n",
      "Epoch: 1931\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.966\n",
      "\tVal Loss: 3.507 |  Val PPL:  33.349\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.772413969039917\n",
      "Epoch: 1932\n",
      "\tTrain Loss: 3.772 | Train PPL:  43.485\n",
      "\tVal Loss: 3.508 |  Val PPL:  33.372\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8265380859375\n",
      "Epoch: 1933\n",
      "\tTrain Loss: 3.827 | Train PPL:  45.903\n",
      "\tVal Loss: 3.508 |  Val PPL:  33.391\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8063340187072754\n",
      "Epoch: 1934\n",
      "\tTrain Loss: 3.806 | Train PPL:  44.985\n",
      "\tVal Loss: 3.509 |  Val PPL:  33.404\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8026251792907715\n",
      "Epoch: 1935\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.819\n",
      "\tVal Loss: 3.509 |  Val PPL:  33.410\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8201818466186523\n",
      "Epoch: 1936\n",
      "\tTrain Loss: 3.820 | Train PPL:  45.613\n",
      "\tVal Loss: 3.509 |  Val PPL:  33.417\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8232479095458984\n",
      "Epoch: 1937\n",
      "\tTrain Loss: 3.823 | Train PPL:  45.753\n",
      "\tVal Loss: 3.509 |  Val PPL:  33.411\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7931437492370605\n",
      "Epoch: 1938\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.396\n",
      "\tVal Loss: 3.508 |  Val PPL:  33.397\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.81223726272583\n",
      "Epoch: 1939\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.252\n",
      "\tVal Loss: 3.508 |  Val PPL:  33.374\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8101401329040527\n",
      "Epoch: 1940\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.157\n",
      "\tVal Loss: 3.507 |  Val PPL:  33.351\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.804177761077881\n",
      "Epoch: 1941\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.888\n",
      "\tVal Loss: 3.506 |  Val PPL:  33.322\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8177077770233154\n",
      "Epoch: 1942\n",
      "\tTrain Loss: 3.818 | Train PPL:  45.500\n",
      "\tVal Loss: 3.505 |  Val PPL:  33.292\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.812178373336792\n",
      "Epoch: 1943\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.249\n",
      "\tVal Loss: 3.504 |  Val PPL:  33.257\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802737236022949\n",
      "Epoch: 1944\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.824\n",
      "\tVal Loss: 3.503 |  Val PPL:  33.221\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8174901008605957\n",
      "Epoch: 1945\n",
      "\tTrain Loss: 3.817 | Train PPL:  45.490\n",
      "\tVal Loss: 3.502 |  Val PPL:  33.188\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.81943941116333\n",
      "Epoch: 1946\n",
      "\tTrain Loss: 3.819 | Train PPL:  45.579\n",
      "\tVal Loss: 3.501 |  Val PPL:  33.154\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.789428949356079\n",
      "Epoch: 1947\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.231\n",
      "\tVal Loss: 3.500 |  Val PPL:  33.124\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.80924916267395\n",
      "Epoch: 1948\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.117\n",
      "\tVal Loss: 3.499 |  Val PPL:  33.092\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.789670467376709\n",
      "Epoch: 1949\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.242\n",
      "\tVal Loss: 3.498 |  Val PPL:  33.060\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.809293270111084\n",
      "Epoch: 1950\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.119\n",
      "\tVal Loss: 3.497 |  Val PPL:  33.032\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8094356060028076\n",
      "Epoch: 1951\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.125\n",
      "\tVal Loss: 3.497 |  Val PPL:  33.007\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7844700813293457\n",
      "Epoch: 1952\n",
      "\tTrain Loss: 3.784 | Train PPL:  44.012\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.983\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.794825553894043\n",
      "Epoch: 1953\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.470\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.969\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7987418174743652\n",
      "Epoch: 1954\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.645\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.958\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8217267990112305\n",
      "Epoch: 1955\n",
      "\tTrain Loss: 3.822 | Train PPL:  45.683\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.954\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7871792316436768\n",
      "Epoch: 1956\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.132\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.953\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.814943790435791\n",
      "Epoch: 1957\n",
      "\tTrain Loss: 3.815 | Train PPL:  45.374\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.958\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.795797109603882\n",
      "Epoch: 1958\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.514\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.965\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8111209869384766\n",
      "Epoch: 1959\n",
      "\tTrain Loss: 3.811 | Train PPL:  45.201\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.975\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8050341606140137\n",
      "Epoch: 1960\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.927\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.980\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8148696422576904\n",
      "Epoch: 1961\n",
      "\tTrain Loss: 3.815 | Train PPL:  45.371\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.988\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8263099193573\n",
      "Epoch: 1962\n",
      "\tTrain Loss: 3.826 | Train PPL:  45.893\n",
      "\tVal Loss: 3.497 |  Val PPL:  33.000\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8016767501831055\n",
      "Epoch: 1963\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.776\n",
      "\tVal Loss: 3.497 |  Val PPL:  33.010\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.798670530319214\n",
      "Epoch: 1964\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.642\n",
      "\tVal Loss: 3.497 |  Val PPL:  33.015\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8005573749542236\n",
      "Epoch: 1965\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.726\n",
      "\tVal Loss: 3.497 |  Val PPL:  33.026\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7994754314422607\n",
      "Epoch: 1966\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.678\n",
      "\tVal Loss: 3.497 |  Val PPL:  33.029\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7972824573516846\n",
      "Epoch: 1967\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.580\n",
      "\tVal Loss: 3.498 |  Val PPL:  33.033\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8065786361694336\n",
      "Epoch: 1968\n",
      "\tTrain Loss: 3.807 | Train PPL:  44.996\n",
      "\tVal Loss: 3.498 |  Val PPL:  33.040\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.808290958404541\n",
      "Epoch: 1969\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.073\n",
      "\tVal Loss: 3.498 |  Val PPL:  33.044\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8385984897613525\n",
      "Epoch: 1970\n",
      "\tTrain Loss: 3.839 | Train PPL:  46.460\n",
      "\tVal Loss: 3.498 |  Val PPL:  33.052\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7957346439361572\n",
      "Epoch: 1971\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.511\n",
      "\tVal Loss: 3.498 |  Val PPL:  33.059\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.80953049659729\n",
      "Epoch: 1972\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.129\n",
      "\tVal Loss: 3.499 |  Val PPL:  33.069\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8358395099639893\n",
      "Epoch: 1973\n",
      "\tTrain Loss: 3.836 | Train PPL:  46.332\n",
      "\tVal Loss: 3.499 |  Val PPL:  33.074\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.807919979095459\n",
      "Epoch: 1974\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.057\n",
      "\tVal Loss: 3.499 |  Val PPL:  33.073\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.769740581512451\n",
      "Epoch: 1975\n",
      "\tTrain Loss: 3.770 | Train PPL:  43.369\n",
      "\tVal Loss: 3.499 |  Val PPL:  33.073\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.823321580886841\n",
      "Epoch: 1976\n",
      "\tTrain Loss: 3.823 | Train PPL:  45.756\n",
      "\tVal Loss: 3.499 |  Val PPL:  33.068\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8180487155914307\n",
      "Epoch: 1977\n",
      "\tTrain Loss: 3.818 | Train PPL:  45.515\n",
      "\tVal Loss: 3.498 |  Val PPL:  33.061\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7924773693084717\n",
      "Epoch: 1978\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.366\n",
      "\tVal Loss: 3.498 |  Val PPL:  33.052\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.804750442504883\n",
      "Epoch: 1979\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.914\n",
      "\tVal Loss: 3.498 |  Val PPL:  33.043\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8066787719726562\n",
      "Epoch: 1980\n",
      "\tTrain Loss: 3.807 | Train PPL:  45.001\n",
      "\tVal Loss: 3.497 |  Val PPL:  33.029\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.821782350540161\n",
      "Epoch: 1981\n",
      "\tTrain Loss: 3.822 | Train PPL:  45.686\n",
      "\tVal Loss: 3.497 |  Val PPL:  33.017\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.815045118331909\n",
      "Epoch: 1982\n",
      "\tTrain Loss: 3.815 | Train PPL:  45.379\n",
      "\tVal Loss: 3.497 |  Val PPL:  33.009\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.798945665359497\n",
      "Epoch: 1983\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.654\n",
      "\tVal Loss: 3.497 |  Val PPL:  33.006\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.800632953643799\n",
      "Epoch: 1984\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.729\n",
      "\tVal Loss: 3.497 |  Val PPL:  33.003\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8041112422943115\n",
      "Epoch: 1985\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.885\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.999\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.809767961502075\n",
      "Epoch: 1986\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.140\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.993\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.808328628540039\n",
      "Epoch: 1987\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.075\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.986\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.818997859954834\n",
      "Epoch: 1988\n",
      "\tTrain Loss: 3.819 | Train PPL:  45.559\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.978\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.780137777328491\n",
      "Epoch: 1989\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.822\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.970\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.785914659500122\n",
      "Epoch: 1990\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.076\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.962\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8190104961395264\n",
      "Epoch: 1991\n",
      "\tTrain Loss: 3.819 | Train PPL:  45.559\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.953\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.78505802154541\n",
      "Epoch: 1992\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.038\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.949\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8330578804016113\n",
      "Epoch: 1993\n",
      "\tTrain Loss: 3.833 | Train PPL:  46.204\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.945\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.805955410003662\n",
      "Epoch: 1994\n",
      "\tTrain Loss: 3.806 | Train PPL:  44.968\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.943\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8193604946136475\n",
      "Epoch: 1995\n",
      "\tTrain Loss: 3.819 | Train PPL:  45.575\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.943\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8010687828063965\n",
      "Epoch: 1996\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.749\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.940\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7951297760009766\n",
      "Epoch: 1997\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.484\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.939\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.777954578399658\n",
      "Epoch: 1998\n",
      "\tTrain Loss: 3.778 | Train PPL:  43.727\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.940\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.830944061279297\n",
      "Epoch: 1999\n",
      "\tTrain Loss: 3.831 | Train PPL:  46.106\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.944\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.789185047149658\n",
      "Epoch: 2000\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.220\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.946\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8136215209960938\n",
      "Epoch: 2001\n",
      "\tTrain Loss: 3.814 | Train PPL:  45.314\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.951\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8066213130950928\n",
      "Epoch: 2002\n",
      "\tTrain Loss: 3.807 | Train PPL:  44.998\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.958\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.789854049682617\n",
      "Epoch: 2003\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.250\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.964\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7881715297698975\n",
      "Epoch: 2004\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.176\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.968\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7904915809631348\n",
      "Epoch: 2005\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.278\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.975\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8058114051818848\n",
      "Epoch: 2006\n",
      "\tTrain Loss: 3.806 | Train PPL:  44.962\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.980\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8143680095672607\n",
      "Epoch: 2007\n",
      "\tTrain Loss: 3.814 | Train PPL:  45.348\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.982\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.797191858291626\n",
      "Epoch: 2008\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.576\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.981\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.790234327316284\n",
      "Epoch: 2009\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.267\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.982\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7672805786132812\n",
      "Epoch: 2010\n",
      "\tTrain Loss: 3.767 | Train PPL:  43.262\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.980\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8032195568084717\n",
      "Epoch: 2011\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.845\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.980\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8216187953948975\n",
      "Epoch: 2012\n",
      "\tTrain Loss: 3.822 | Train PPL:  45.678\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.978\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7844576835632324\n",
      "Epoch: 2013\n",
      "\tTrain Loss: 3.784 | Train PPL:  44.012\n",
      "\tVal Loss: 3.496 |  Val PPL:  32.969\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.801701068878174\n",
      "Epoch: 2014\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.777\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.964\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8311028480529785\n",
      "Epoch: 2015\n",
      "\tTrain Loss: 3.831 | Train PPL:  46.113\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.962\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.794724225997925\n",
      "Epoch: 2016\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.466\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.963\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7667932510375977\n",
      "Epoch: 2017\n",
      "\tTrain Loss: 3.767 | Train PPL:  43.241\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.959\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8101754188537598\n",
      "Epoch: 2018\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.158\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.953\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.765505313873291\n",
      "Epoch: 2019\n",
      "\tTrain Loss: 3.766 | Train PPL:  43.186\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.944\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7903506755828857\n",
      "Epoch: 2020\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.272\n",
      "\tVal Loss: 3.495 |  Val PPL:  32.935\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.808422565460205\n",
      "Epoch: 2021\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.079\n",
      "\tVal Loss: 3.494 |  Val PPL:  32.928\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8053901195526123\n",
      "Epoch: 2022\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.943\n",
      "\tVal Loss: 3.494 |  Val PPL:  32.920\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.812067985534668\n",
      "Epoch: 2023\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.244\n",
      "\tVal Loss: 3.494 |  Val PPL:  32.912\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7964539527893066\n",
      "Epoch: 2024\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.543\n",
      "\tVal Loss: 3.494 |  Val PPL:  32.906\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8008570671081543\n",
      "Epoch: 2025\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.740\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.897\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.788670778274536\n",
      "Epoch: 2026\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.198\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.886\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8005564212799072\n",
      "Epoch: 2027\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.726\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.878\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.790734052658081\n",
      "Epoch: 2028\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.289\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.868\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7848258018493652\n",
      "Epoch: 2029\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.028\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.861\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7859151363372803\n",
      "Epoch: 2030\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.076\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.852\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.792681932449341\n",
      "Epoch: 2031\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.375\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.844\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7901768684387207\n",
      "Epoch: 2032\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.264\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.837\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.799445867538452\n",
      "Epoch: 2033\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.676\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.831\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.785693407058716\n",
      "Epoch: 2034\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.066\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.828\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7882251739501953\n",
      "Epoch: 2035\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.178\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.825\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.785646677017212\n",
      "Epoch: 2036\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.064\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.826\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.831620931625366\n",
      "Epoch: 2037\n",
      "\tTrain Loss: 3.832 | Train PPL:  46.137\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.826\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8144378662109375\n",
      "Epoch: 2038\n",
      "\tTrain Loss: 3.814 | Train PPL:  45.351\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.828\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8071281909942627\n",
      "Epoch: 2039\n",
      "\tTrain Loss: 3.807 | Train PPL:  45.021\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.829\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8197760581970215\n",
      "Epoch: 2040\n",
      "\tTrain Loss: 3.820 | Train PPL:  45.594\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.831\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.777125120162964\n",
      "Epoch: 2041\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.690\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.832\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.797048807144165\n",
      "Epoch: 2042\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.569\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.837\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7970659732818604\n",
      "Epoch: 2043\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.570\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.840\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8039796352386475\n",
      "Epoch: 2044\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.879\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.844\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.791952610015869\n",
      "Epoch: 2045\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.343\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.850\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7964277267456055\n",
      "Epoch: 2046\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.542\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.855\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.789586305618286\n",
      "Epoch: 2047\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.238\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.858\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8018295764923096\n",
      "Epoch: 2048\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.783\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.862\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7931931018829346\n",
      "Epoch: 2049\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.398\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.862\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7722995281219482\n",
      "Epoch: 2050\n",
      "\tTrain Loss: 3.772 | Train PPL:  43.480\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.863\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7865939140319824\n",
      "Epoch: 2051\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.106\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.862\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.788625955581665\n",
      "Epoch: 2052\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.196\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.860\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.811145782470703\n",
      "Epoch: 2053\n",
      "\tTrain Loss: 3.811 | Train PPL:  45.202\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.857\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.801290512084961\n",
      "Epoch: 2054\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.759\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.857\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8210713863372803\n",
      "Epoch: 2055\n",
      "\tTrain Loss: 3.821 | Train PPL:  45.653\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.861\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.799172878265381\n",
      "Epoch: 2056\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.664\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.863\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.798460006713867\n",
      "Epoch: 2057\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.632\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.865\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8151392936706543\n",
      "Epoch: 2058\n",
      "\tTrain Loss: 3.815 | Train PPL:  45.383\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.868\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.823397159576416\n",
      "Epoch: 2059\n",
      "\tTrain Loss: 3.823 | Train PPL:  45.759\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.874\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.787940502166748\n",
      "Epoch: 2060\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.165\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.878\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8018925189971924\n",
      "Epoch: 2061\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.786\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.884\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7980546951293945\n",
      "Epoch: 2062\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.614\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.889\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8254008293151855\n",
      "Epoch: 2063\n",
      "\tTrain Loss: 3.825 | Train PPL:  45.851\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.891\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8085548877716064\n",
      "Epoch: 2064\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.085\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.892\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.818835973739624\n",
      "Epoch: 2065\n",
      "\tTrain Loss: 3.819 | Train PPL:  45.551\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.892\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8114593029022217\n",
      "Epoch: 2066\n",
      "\tTrain Loss: 3.811 | Train PPL:  45.216\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.891\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7837977409362793\n",
      "Epoch: 2067\n",
      "\tTrain Loss: 3.784 | Train PPL:  43.983\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.891\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7871968746185303\n",
      "Epoch: 2068\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.133\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.892\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8253586292266846\n",
      "Epoch: 2069\n",
      "\tTrain Loss: 3.825 | Train PPL:  45.849\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.894\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802532434463501\n",
      "Epoch: 2070\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.815\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.894\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.765285015106201\n",
      "Epoch: 2071\n",
      "\tTrain Loss: 3.765 | Train PPL:  43.176\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.896\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7798378467559814\n",
      "Epoch: 2072\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.809\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.898\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7956175804138184\n",
      "Epoch: 2073\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.506\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.897\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7862160205841064\n",
      "Epoch: 2074\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.089\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.896\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8090155124664307\n",
      "Epoch: 2075\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.106\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.895\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7994158267974854\n",
      "Epoch: 2076\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.675\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.892\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7867870330810547\n",
      "Epoch: 2077\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.114\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.888\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7934858798980713\n",
      "Epoch: 2078\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.411\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.884\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7798478603363037\n",
      "Epoch: 2079\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.809\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.877\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.816007375717163\n",
      "Epoch: 2080\n",
      "\tTrain Loss: 3.816 | Train PPL:  45.422\n",
      "\tVal Loss: 3.493 |  Val PPL:  32.871\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7878472805023193\n",
      "Epoch: 2081\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.161\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.863\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7999792098999023\n",
      "Epoch: 2082\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.700\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.855\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8185031414031982\n",
      "Epoch: 2083\n",
      "\tTrain Loss: 3.819 | Train PPL:  45.536\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.850\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.803187370300293\n",
      "Epoch: 2084\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.844\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.846\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8065006732940674\n",
      "Epoch: 2085\n",
      "\tTrain Loss: 3.807 | Train PPL:  44.993\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.843\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.808133602142334\n",
      "Epoch: 2086\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.066\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.840\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.760145664215088\n",
      "Epoch: 2087\n",
      "\tTrain Loss: 3.760 | Train PPL:  42.955\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.838\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7958786487579346\n",
      "Epoch: 2088\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.517\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.836\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7927114963531494\n",
      "Epoch: 2089\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.377\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.834\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.79274845123291\n",
      "Epoch: 2090\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.378\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.831\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.77658748626709\n",
      "Epoch: 2091\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.667\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.830\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8079965114593506\n",
      "Epoch: 2092\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.060\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.828\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7658610343933105\n",
      "Epoch: 2093\n",
      "\tTrain Loss: 3.766 | Train PPL:  43.201\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.829\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.797715425491333\n",
      "Epoch: 2094\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.599\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.832\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8121869564056396\n",
      "Epoch: 2095\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.249\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.833\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8388969898223877\n",
      "Epoch: 2096\n",
      "\tTrain Loss: 3.839 | Train PPL:  46.474\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.833\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8043553829193115\n",
      "Epoch: 2097\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.896\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.831\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8031017780303955\n",
      "Epoch: 2098\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.840\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.830\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8074066638946533\n",
      "Epoch: 2099\n",
      "\tTrain Loss: 3.807 | Train PPL:  45.034\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.828\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.807460308074951\n",
      "Epoch: 2100\n",
      "\tTrain Loss: 3.807 | Train PPL:  45.036\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.825\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8046724796295166\n",
      "Epoch: 2101\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.911\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.823\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.786039352416992\n",
      "Epoch: 2102\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.081\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.821\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.833873748779297\n",
      "Epoch: 2103\n",
      "\tTrain Loss: 3.834 | Train PPL:  46.241\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.819\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.818786859512329\n",
      "Epoch: 2104\n",
      "\tTrain Loss: 3.819 | Train PPL:  45.549\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.819\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802961587905884\n",
      "Epoch: 2105\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.834\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.820\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.804347276687622\n",
      "Epoch: 2106\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.896\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.821\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.799436092376709\n",
      "Epoch: 2107\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.676\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.822\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802734136581421\n",
      "Epoch: 2108\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.824\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.823\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.811138153076172\n",
      "Epoch: 2109\n",
      "\tTrain Loss: 3.811 | Train PPL:  45.202\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.824\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.791153907775879\n",
      "Epoch: 2110\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.307\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.823\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.790076732635498\n",
      "Epoch: 2111\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.260\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.822\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.789956569671631\n",
      "Epoch: 2112\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.254\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.823\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7849812507629395\n",
      "Epoch: 2113\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.035\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.824\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8234269618988037\n",
      "Epoch: 2114\n",
      "\tTrain Loss: 3.823 | Train PPL:  45.761\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.824\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7982912063598633\n",
      "Epoch: 2115\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.625\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.825\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7957653999328613\n",
      "Epoch: 2116\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.512\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.826\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7943832874298096\n",
      "Epoch: 2117\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.451\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.827\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.782125234603882\n",
      "Epoch: 2118\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.909\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.827\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7711052894592285\n",
      "Epoch: 2119\n",
      "\tTrain Loss: 3.771 | Train PPL:  43.428\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.825\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7836263179779053\n",
      "Epoch: 2120\n",
      "\tTrain Loss: 3.784 | Train PPL:  43.975\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.825\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7945377826690674\n",
      "Epoch: 2121\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.458\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.823\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.812291383743286\n",
      "Epoch: 2122\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.254\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.822\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.799530506134033\n",
      "Epoch: 2123\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.680\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.822\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.779872417449951\n",
      "Epoch: 2124\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.810\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.822\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802760362625122\n",
      "Epoch: 2125\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.825\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.821\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.818882465362549\n",
      "Epoch: 2126\n",
      "\tTrain Loss: 3.819 | Train PPL:  45.553\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.823\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8180782794952393\n",
      "Epoch: 2127\n",
      "\tTrain Loss: 3.818 | Train PPL:  45.517\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.824\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.848658323287964\n",
      "Epoch: 2128\n",
      "\tTrain Loss: 3.849 | Train PPL:  46.930\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.826\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8252084255218506\n",
      "Epoch: 2129\n",
      "\tTrain Loss: 3.825 | Train PPL:  45.842\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.830\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8161633014678955\n",
      "Epoch: 2130\n",
      "\tTrain Loss: 3.816 | Train PPL:  45.430\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.834\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7924623489379883\n",
      "Epoch: 2131\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.366\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.838\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8044676780700684\n",
      "Epoch: 2132\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.901\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.841\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8412957191467285\n",
      "Epoch: 2133\n",
      "\tTrain Loss: 3.841 | Train PPL:  46.586\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.843\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7987406253814697\n",
      "Epoch: 2134\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.645\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.843\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7851064205169678\n",
      "Epoch: 2135\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.040\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.844\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7723100185394287\n",
      "Epoch: 2136\n",
      "\tTrain Loss: 3.772 | Train PPL:  43.480\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.843\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8041460514068604\n",
      "Epoch: 2137\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.887\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.843\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7943358421325684\n",
      "Epoch: 2138\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.449\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.841\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.81123948097229\n",
      "Epoch: 2139\n",
      "\tTrain Loss: 3.811 | Train PPL:  45.206\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.839\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.768742799758911\n",
      "Epoch: 2140\n",
      "\tTrain Loss: 3.769 | Train PPL:  43.326\n",
      "\tVal Loss: 3.492 |  Val PPL:  32.837\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7855632305145264\n",
      "Epoch: 2141\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.060\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.834\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7943084239959717\n",
      "Epoch: 2142\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.447\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.831\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8224899768829346\n",
      "Epoch: 2143\n",
      "\tTrain Loss: 3.822 | Train PPL:  45.718\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.829\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7693912982940674\n",
      "Epoch: 2144\n",
      "\tTrain Loss: 3.769 | Train PPL:  43.354\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.828\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.797457695007324\n",
      "Epoch: 2145\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.588\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.825\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.809741497039795\n",
      "Epoch: 2146\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.139\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.823\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8105311393737793\n",
      "Epoch: 2147\n",
      "\tTrain Loss: 3.811 | Train PPL:  45.174\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.821\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.799168825149536\n",
      "Epoch: 2148\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.664\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.818\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8153553009033203\n",
      "Epoch: 2149\n",
      "\tTrain Loss: 3.815 | Train PPL:  45.393\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.816\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.797694206237793\n",
      "Epoch: 2150\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.598\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.812\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8019347190856934\n",
      "Epoch: 2151\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.788\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.809\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8019511699676514\n",
      "Epoch: 2152\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.788\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.806\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.798375368118286\n",
      "Epoch: 2153\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.629\n",
      "\tVal Loss: 3.491 |  Val PPL:  32.804\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8090362548828125\n",
      "Epoch: 2154\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.107\n",
      "\tVal Loss: 3.490 |  Val PPL:  32.801\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7972252368927\n",
      "Epoch: 2155\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.577\n",
      "\tVal Loss: 3.490 |  Val PPL:  32.797\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.799852132797241\n",
      "Epoch: 2156\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.695\n",
      "\tVal Loss: 3.490 |  Val PPL:  32.794\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7881665229797363\n",
      "Epoch: 2157\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.175\n",
      "\tVal Loss: 3.490 |  Val PPL:  32.791\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.789937973022461\n",
      "Epoch: 2158\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.254\n",
      "\tVal Loss: 3.490 |  Val PPL:  32.789\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7845065593719482\n",
      "Epoch: 2159\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.014\n",
      "\tVal Loss: 3.490 |  Val PPL:  32.786\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.80622935295105\n",
      "Epoch: 2160\n",
      "\tTrain Loss: 3.806 | Train PPL:  44.981\n",
      "\tVal Loss: 3.490 |  Val PPL:  32.783\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.776810646057129\n",
      "Epoch: 2161\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.677\n",
      "\tVal Loss: 3.490 |  Val PPL:  32.781\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.768672466278076\n",
      "Epoch: 2162\n",
      "\tTrain Loss: 3.769 | Train PPL:  43.323\n",
      "\tVal Loss: 3.490 |  Val PPL:  32.778\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8163094520568848\n",
      "Epoch: 2163\n",
      "\tTrain Loss: 3.816 | Train PPL:  45.436\n",
      "\tVal Loss: 3.490 |  Val PPL:  32.774\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.767688035964966\n",
      "Epoch: 2164\n",
      "\tTrain Loss: 3.768 | Train PPL:  43.280\n",
      "\tVal Loss: 3.490 |  Val PPL:  32.770\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802703619003296\n",
      "Epoch: 2165\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.822\n",
      "\tVal Loss: 3.489 |  Val PPL:  32.765\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.764129638671875\n",
      "Epoch: 2166\n",
      "\tTrain Loss: 3.764 | Train PPL:  43.126\n",
      "\tVal Loss: 3.489 |  Val PPL:  32.761\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.779555559158325\n",
      "Epoch: 2167\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.797\n",
      "\tVal Loss: 3.489 |  Val PPL:  32.758\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.799257755279541\n",
      "Epoch: 2168\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.668\n",
      "\tVal Loss: 3.489 |  Val PPL:  32.756\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7936136722564697\n",
      "Epoch: 2169\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.417\n",
      "\tVal Loss: 3.489 |  Val PPL:  32.752\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7594194412231445\n",
      "Epoch: 2170\n",
      "\tTrain Loss: 3.759 | Train PPL:  42.923\n",
      "\tVal Loss: 3.489 |  Val PPL:  32.747\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8129324913024902\n",
      "Epoch: 2171\n",
      "\tTrain Loss: 3.813 | Train PPL:  45.283\n",
      "\tVal Loss: 3.489 |  Val PPL:  32.743\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.791659355163574\n",
      "Epoch: 2172\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.330\n",
      "\tVal Loss: 3.489 |  Val PPL:  32.741\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.80155348777771\n",
      "Epoch: 2173\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.771\n",
      "\tVal Loss: 3.489 |  Val PPL:  32.739\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.834604501724243\n",
      "Epoch: 2174\n",
      "\tTrain Loss: 3.835 | Train PPL:  46.275\n",
      "\tVal Loss: 3.489 |  Val PPL:  32.737\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.805840015411377\n",
      "Epoch: 2175\n",
      "\tTrain Loss: 3.806 | Train PPL:  44.963\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.735\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8106637001037598\n",
      "Epoch: 2176\n",
      "\tTrain Loss: 3.811 | Train PPL:  45.180\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.734\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.812451124191284\n",
      "Epoch: 2177\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.261\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.732\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8091988563537598\n",
      "Epoch: 2178\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.114\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.730\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.816153049468994\n",
      "Epoch: 2179\n",
      "\tTrain Loss: 3.816 | Train PPL:  45.429\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.728\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8150126934051514\n",
      "Epoch: 2180\n",
      "\tTrain Loss: 3.815 | Train PPL:  45.377\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.726\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8135221004486084\n",
      "Epoch: 2181\n",
      "\tTrain Loss: 3.814 | Train PPL:  45.310\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.726\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7798666954040527\n",
      "Epoch: 2182\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.810\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.725\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8184289932250977\n",
      "Epoch: 2183\n",
      "\tTrain Loss: 3.818 | Train PPL:  45.533\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.725\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.810293436050415\n",
      "Epoch: 2184\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.164\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.724\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8022239208221436\n",
      "Epoch: 2185\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.801\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.726\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8029582500457764\n",
      "Epoch: 2186\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.834\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.726\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.822571277618408\n",
      "Epoch: 2187\n",
      "\tTrain Loss: 3.823 | Train PPL:  45.722\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.727\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7998666763305664\n",
      "Epoch: 2188\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.695\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.728\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7999417781829834\n",
      "Epoch: 2189\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.699\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.730\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.813289165496826\n",
      "Epoch: 2190\n",
      "\tTrain Loss: 3.813 | Train PPL:  45.299\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.732\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7893314361572266\n",
      "Epoch: 2191\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.227\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.734\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7877213954925537\n",
      "Epoch: 2192\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.156\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.735\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7759344577789307\n",
      "Epoch: 2193\n",
      "\tTrain Loss: 3.776 | Train PPL:  43.638\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.734\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.824734926223755\n",
      "Epoch: 2194\n",
      "\tTrain Loss: 3.825 | Train PPL:  45.821\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.733\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8081188201904297\n",
      "Epoch: 2195\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.066\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.731\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.78601336479187\n",
      "Epoch: 2196\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.080\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.731\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8073673248291016\n",
      "Epoch: 2197\n",
      "\tTrain Loss: 3.807 | Train PPL:  45.032\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.730\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8122785091400146\n",
      "Epoch: 2198\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.253\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.730\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.81219482421875\n",
      "Epoch: 2199\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.250\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.730\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.761244773864746\n",
      "Epoch: 2200\n",
      "\tTrain Loss: 3.761 | Train PPL:  43.002\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.731\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802203416824341\n",
      "Epoch: 2201\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.800\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.730\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7886931896209717\n",
      "Epoch: 2202\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.199\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.729\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8136074542999268\n",
      "Epoch: 2203\n",
      "\tTrain Loss: 3.814 | Train PPL:  45.314\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.727\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.809253215789795\n",
      "Epoch: 2204\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.117\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.726\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.779123544692993\n",
      "Epoch: 2205\n",
      "\tTrain Loss: 3.779 | Train PPL:  43.778\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.723\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7959861755371094\n",
      "Epoch: 2206\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.522\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.721\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8017802238464355\n",
      "Epoch: 2207\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.781\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.718\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7907779216766357\n",
      "Epoch: 2208\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.291\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.716\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7939138412475586\n",
      "Epoch: 2209\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.430\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.714\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7931840419769287\n",
      "Epoch: 2210\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.398\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.713\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7917027473449707\n",
      "Epoch: 2211\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.332\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.713\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7886950969696045\n",
      "Epoch: 2212\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.199\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.712\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.796382427215576\n",
      "Epoch: 2213\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.540\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.711\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.777033805847168\n",
      "Epoch: 2214\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.686\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.710\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8068881034851074\n",
      "Epoch: 2215\n",
      "\tTrain Loss: 3.807 | Train PPL:  45.010\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.709\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8249378204345703\n",
      "Epoch: 2216\n",
      "\tTrain Loss: 3.825 | Train PPL:  45.830\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.709\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.796617269515991\n",
      "Epoch: 2217\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.550\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.709\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7889695167541504\n",
      "Epoch: 2218\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.211\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.709\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8012187480926514\n",
      "Epoch: 2219\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.756\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.708\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7764787673950195\n",
      "Epoch: 2220\n",
      "\tTrain Loss: 3.776 | Train PPL:  43.662\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.707\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.795227289199829\n",
      "Epoch: 2221\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.488\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.707\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.805495023727417\n",
      "Epoch: 2222\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.947\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.706\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7979564666748047\n",
      "Epoch: 2223\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.610\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.797529458999634\n",
      "Epoch: 2224\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.591\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8075013160705566\n",
      "Epoch: 2225\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.038\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7763407230377197\n",
      "Epoch: 2226\n",
      "\tTrain Loss: 3.776 | Train PPL:  43.656\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.704\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8164098262786865\n",
      "Epoch: 2227\n",
      "\tTrain Loss: 3.816 | Train PPL:  45.441\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.799501657485962\n",
      "Epoch: 2228\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.679\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.706\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.790924549102783\n",
      "Epoch: 2229\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.297\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.708\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7763617038726807\n",
      "Epoch: 2230\n",
      "\tTrain Loss: 3.776 | Train PPL:  43.657\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.708\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.807410955429077\n",
      "Epoch: 2231\n",
      "\tTrain Loss: 3.807 | Train PPL:  45.034\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.709\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7722866535186768\n",
      "Epoch: 2232\n",
      "\tTrain Loss: 3.772 | Train PPL:  43.479\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.708\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.835878610610962\n",
      "Epoch: 2233\n",
      "\tTrain Loss: 3.836 | Train PPL:  46.334\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.709\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8128345012664795\n",
      "Epoch: 2234\n",
      "\tTrain Loss: 3.813 | Train PPL:  45.279\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.708\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.79498553276062\n",
      "Epoch: 2235\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.478\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.709\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7892467975616455\n",
      "Epoch: 2236\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.223\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.708\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.797180652618408\n",
      "Epoch: 2237\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.575\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.707\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.777989387512207\n",
      "Epoch: 2238\n",
      "\tTrain Loss: 3.778 | Train PPL:  43.728\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.707\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7893829345703125\n",
      "Epoch: 2239\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.229\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.707\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.789031982421875\n",
      "Epoch: 2240\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.214\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.706\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.809678077697754\n",
      "Epoch: 2241\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.136\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.706\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.817110300064087\n",
      "Epoch: 2242\n",
      "\tTrain Loss: 3.817 | Train PPL:  45.473\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8018198013305664\n",
      "Epoch: 2243\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.783\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7997241020202637\n",
      "Epoch: 2244\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.689\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.826051712036133\n",
      "Epoch: 2245\n",
      "\tTrain Loss: 3.826 | Train PPL:  45.881\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.797300338745117\n",
      "Epoch: 2246\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.581\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.795546293258667\n",
      "Epoch: 2247\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.503\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.704\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8106000423431396\n",
      "Epoch: 2248\n",
      "\tTrain Loss: 3.811 | Train PPL:  45.178\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.704\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7964870929718018\n",
      "Epoch: 2249\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.544\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.704\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.795250654220581\n",
      "Epoch: 2250\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.489\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.704\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7945005893707275\n",
      "Epoch: 2251\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.456\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.704\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.789187431335449\n",
      "Epoch: 2252\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.220\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.704\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7771987915039062\n",
      "Epoch: 2253\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.693\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.703\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8270013332366943\n",
      "Epoch: 2254\n",
      "\tTrain Loss: 3.827 | Train PPL:  45.925\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.703\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8095290660858154\n",
      "Epoch: 2255\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.129\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.702\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8044917583465576\n",
      "Epoch: 2256\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.902\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.702\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8101158142089844\n",
      "Epoch: 2257\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.156\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.702\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.805809497833252\n",
      "Epoch: 2258\n",
      "\tTrain Loss: 3.806 | Train PPL:  44.962\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.702\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802643060684204\n",
      "Epoch: 2259\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.819\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.702\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8073902130126953\n",
      "Epoch: 2260\n",
      "\tTrain Loss: 3.807 | Train PPL:  45.033\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.702\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802379846572876\n",
      "Epoch: 2261\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.808\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.703\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7740495204925537\n",
      "Epoch: 2262\n",
      "\tTrain Loss: 3.774 | Train PPL:  43.556\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.703\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7868001461029053\n",
      "Epoch: 2263\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.115\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.704\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7816555500030518\n",
      "Epoch: 2264\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.889\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.704\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7917532920837402\n",
      "Epoch: 2265\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.334\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.704\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7690677642822266\n",
      "Epoch: 2266\n",
      "\tTrain Loss: 3.769 | Train PPL:  43.340\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.703\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.793208360671997\n",
      "Epoch: 2267\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.399\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.703\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.779313564300537\n",
      "Epoch: 2268\n",
      "\tTrain Loss: 3.779 | Train PPL:  43.786\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.703\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7948217391967773\n",
      "Epoch: 2269\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.470\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.703\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7978127002716064\n",
      "Epoch: 2270\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.604\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.703\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.791238784790039\n",
      "Epoch: 2271\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.311\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.703\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8176748752593994\n",
      "Epoch: 2272\n",
      "\tTrain Loss: 3.818 | Train PPL:  45.498\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.703\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8168671131134033\n",
      "Epoch: 2273\n",
      "\tTrain Loss: 3.817 | Train PPL:  45.462\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.704\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.765211582183838\n",
      "Epoch: 2274\n",
      "\tTrain Loss: 3.765 | Train PPL:  43.173\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.776059865951538\n",
      "Epoch: 2275\n",
      "\tTrain Loss: 3.776 | Train PPL:  43.644\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.793416738510132\n",
      "Epoch: 2276\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.408\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.798776149749756\n",
      "Epoch: 2277\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.647\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7968368530273438\n",
      "Epoch: 2278\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.560\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.827117919921875\n",
      "Epoch: 2279\n",
      "\tTrain Loss: 3.827 | Train PPL:  45.930\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7929651737213135\n",
      "Epoch: 2280\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.388\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.706\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8089330196380615\n",
      "Epoch: 2281\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.102\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.706\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7937426567077637\n",
      "Epoch: 2282\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.422\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.706\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.795193910598755\n",
      "Epoch: 2283\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.487\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7975211143493652\n",
      "Epoch: 2284\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.591\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.796107292175293\n",
      "Epoch: 2285\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.528\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.794802188873291\n",
      "Epoch: 2286\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.469\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.769819736480713\n",
      "Epoch: 2287\n",
      "\tTrain Loss: 3.770 | Train PPL:  43.372\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.706\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7935338020324707\n",
      "Epoch: 2288\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.413\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.706\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.788487434387207\n",
      "Epoch: 2289\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.190\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.706\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7996034622192383\n",
      "Epoch: 2290\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.683\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.807812213897705\n",
      "Epoch: 2291\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.052\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7939743995666504\n",
      "Epoch: 2292\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.433\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.705\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7929320335388184\n",
      "Epoch: 2293\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.386\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.704\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.77983021736145\n",
      "Epoch: 2294\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.809\n",
      "\tVal Loss: 3.488 |  Val PPL:  32.704\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7882721424102783\n",
      "Epoch: 2295\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.180\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.703\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.796752691268921\n",
      "Epoch: 2296\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.556\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.703\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7946200370788574\n",
      "Epoch: 2297\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.461\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.702\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.786924362182617\n",
      "Epoch: 2298\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.120\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.701\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.780914306640625\n",
      "Epoch: 2299\n",
      "\tTrain Loss: 3.781 | Train PPL:  43.856\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.701\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.781287670135498\n",
      "Epoch: 2300\n",
      "\tTrain Loss: 3.781 | Train PPL:  43.872\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.701\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8091347217559814\n",
      "Epoch: 2301\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.111\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.701\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7876932621002197\n",
      "Epoch: 2302\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.154\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.699\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.779024600982666\n",
      "Epoch: 2303\n",
      "\tTrain Loss: 3.779 | Train PPL:  43.773\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.698\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.837611675262451\n",
      "Epoch: 2304\n",
      "\tTrain Loss: 3.838 | Train PPL:  46.414\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.697\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8139586448669434\n",
      "Epoch: 2305\n",
      "\tTrain Loss: 3.814 | Train PPL:  45.330\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.697\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.797701835632324\n",
      "Epoch: 2306\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.599\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.696\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8256924152374268\n",
      "Epoch: 2307\n",
      "\tTrain Loss: 3.826 | Train PPL:  45.865\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.695\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.781660318374634\n",
      "Epoch: 2308\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.889\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.694\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.793764352798462\n",
      "Epoch: 2309\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.423\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.694\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7767210006713867\n",
      "Epoch: 2310\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.673\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.694\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8104217052459717\n",
      "Epoch: 2311\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.169\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.694\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8135998249053955\n",
      "Epoch: 2312\n",
      "\tTrain Loss: 3.814 | Train PPL:  45.313\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.694\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8023557662963867\n",
      "Epoch: 2313\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.807\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.695\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.807830572128296\n",
      "Epoch: 2314\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.053\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.694\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.79333758354187\n",
      "Epoch: 2315\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.404\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.694\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8120691776275635\n",
      "Epoch: 2316\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.244\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.694\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8172945976257324\n",
      "Epoch: 2317\n",
      "\tTrain Loss: 3.817 | Train PPL:  45.481\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.693\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.792201519012451\n",
      "Epoch: 2318\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.354\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.692\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7988085746765137\n",
      "Epoch: 2319\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.648\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.691\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8051364421844482\n",
      "Epoch: 2320\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.931\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.690\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.825450897216797\n",
      "Epoch: 2321\n",
      "\tTrain Loss: 3.825 | Train PPL:  45.853\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.689\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7866711616516113\n",
      "Epoch: 2322\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.109\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.687\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7767393589019775\n",
      "Epoch: 2323\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.673\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.686\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.791536808013916\n",
      "Epoch: 2324\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.324\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.684\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7969260215759277\n",
      "Epoch: 2325\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.564\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.683\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.782097578048706\n",
      "Epoch: 2326\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.908\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.681\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8045294284820557\n",
      "Epoch: 2327\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.904\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.681\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802061080932617\n",
      "Epoch: 2328\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.793\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.680\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8115394115448\n",
      "Epoch: 2329\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.220\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.679\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.806044101715088\n",
      "Epoch: 2330\n",
      "\tTrain Loss: 3.806 | Train PPL:  44.972\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.677\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.787097454071045\n",
      "Epoch: 2331\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.128\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.676\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.776679754257202\n",
      "Epoch: 2332\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.671\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.674\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.763434886932373\n",
      "Epoch: 2333\n",
      "\tTrain Loss: 3.763 | Train PPL:  43.096\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.673\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.786281108856201\n",
      "Epoch: 2334\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.092\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.673\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7945404052734375\n",
      "Epoch: 2335\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.458\n",
      "\tVal Loss: 3.487 |  Val PPL:  32.672\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7856969833374023\n",
      "Epoch: 2336\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.066\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.671\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8119633197784424\n",
      "Epoch: 2337\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.239\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.671\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.803557872772217\n",
      "Epoch: 2338\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.861\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.670\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.787790060043335\n",
      "Epoch: 2339\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.159\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.669\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8024330139160156\n",
      "Epoch: 2340\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.810\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.668\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.80434513092041\n",
      "Epoch: 2341\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.896\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.668\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7933998107910156\n",
      "Epoch: 2342\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.407\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.667\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.796091318130493\n",
      "Epoch: 2343\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.527\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.667\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.795241117477417\n",
      "Epoch: 2344\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.489\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.666\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.819319725036621\n",
      "Epoch: 2345\n",
      "\tTrain Loss: 3.819 | Train PPL:  45.573\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.664\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8048315048217773\n",
      "Epoch: 2346\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.918\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.663\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.785430908203125\n",
      "Epoch: 2347\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.055\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.662\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.803117036819458\n",
      "Epoch: 2348\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.841\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.662\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7872912883758545\n",
      "Epoch: 2349\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.137\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.662\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.771848678588867\n",
      "Epoch: 2350\n",
      "\tTrain Loss: 3.772 | Train PPL:  43.460\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.662\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802304744720459\n",
      "Epoch: 2351\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.804\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.662\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7899677753448486\n",
      "Epoch: 2352\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.255\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.662\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.812652111053467\n",
      "Epoch: 2353\n",
      "\tTrain Loss: 3.813 | Train PPL:  45.270\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.661\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8175127506256104\n",
      "Epoch: 2354\n",
      "\tTrain Loss: 3.818 | Train PPL:  45.491\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.660\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.81240177154541\n",
      "Epoch: 2355\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.259\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.659\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.809095621109009\n",
      "Epoch: 2356\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.110\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.658\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7819972038269043\n",
      "Epoch: 2357\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.904\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.657\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7950761318206787\n",
      "Epoch: 2358\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.482\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.656\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7727696895599365\n",
      "Epoch: 2359\n",
      "\tTrain Loss: 3.773 | Train PPL:  43.500\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.656\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7874462604522705\n",
      "Epoch: 2360\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.144\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.655\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7709269523620605\n",
      "Epoch: 2361\n",
      "\tTrain Loss: 3.771 | Train PPL:  43.420\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.655\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7839207649230957\n",
      "Epoch: 2362\n",
      "\tTrain Loss: 3.784 | Train PPL:  43.988\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.655\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.780425548553467\n",
      "Epoch: 2363\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.835\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.656\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8138060569763184\n",
      "Epoch: 2364\n",
      "\tTrain Loss: 3.814 | Train PPL:  45.323\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.656\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.795387029647827\n",
      "Epoch: 2365\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.495\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.657\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7753329277038574\n",
      "Epoch: 2366\n",
      "\tTrain Loss: 3.775 | Train PPL:  43.612\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.657\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.757821798324585\n",
      "Epoch: 2367\n",
      "\tTrain Loss: 3.758 | Train PPL:  42.855\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.657\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.808499813079834\n",
      "Epoch: 2368\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.083\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.657\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.797370433807373\n",
      "Epoch: 2369\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.584\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.657\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7807271480560303\n",
      "Epoch: 2370\n",
      "\tTrain Loss: 3.781 | Train PPL:  43.848\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.657\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.784379005432129\n",
      "Epoch: 2371\n",
      "\tTrain Loss: 3.784 | Train PPL:  44.008\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.658\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7766308784484863\n",
      "Epoch: 2372\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.669\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.659\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.782681465148926\n",
      "Epoch: 2373\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.934\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.660\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8239047527313232\n",
      "Epoch: 2374\n",
      "\tTrain Loss: 3.824 | Train PPL:  45.783\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.661\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7983481884002686\n",
      "Epoch: 2375\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.627\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.662\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7889277935028076\n",
      "Epoch: 2376\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.209\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.663\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7686197757720947\n",
      "Epoch: 2377\n",
      "\tTrain Loss: 3.769 | Train PPL:  43.320\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.663\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8045036792755127\n",
      "Epoch: 2378\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.903\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.663\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8012330532073975\n",
      "Epoch: 2379\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.756\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.663\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7856638431549072\n",
      "Epoch: 2380\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.065\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.664\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.78377103805542\n",
      "Epoch: 2381\n",
      "\tTrain Loss: 3.784 | Train PPL:  43.982\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.664\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7956135272979736\n",
      "Epoch: 2382\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.506\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.665\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8092105388641357\n",
      "Epoch: 2383\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.115\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.666\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7965660095214844\n",
      "Epoch: 2384\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.548\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.666\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8029232025146484\n",
      "Epoch: 2385\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.832\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.667\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.804246425628662\n",
      "Epoch: 2386\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.891\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.667\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7652204036712646\n",
      "Epoch: 2387\n",
      "\tTrain Loss: 3.765 | Train PPL:  43.173\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.667\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7807962894439697\n",
      "Epoch: 2388\n",
      "\tTrain Loss: 3.781 | Train PPL:  43.851\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.666\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7966806888580322\n",
      "Epoch: 2389\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.553\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.666\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.773338794708252\n",
      "Epoch: 2390\n",
      "\tTrain Loss: 3.773 | Train PPL:  43.525\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.666\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.788423538208008\n",
      "Epoch: 2391\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.187\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.666\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7828197479248047\n",
      "Epoch: 2392\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.940\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.666\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7784645557403564\n",
      "Epoch: 2393\n",
      "\tTrain Loss: 3.778 | Train PPL:  43.749\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.666\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8253531455993652\n",
      "Epoch: 2394\n",
      "\tTrain Loss: 3.825 | Train PPL:  45.849\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.665\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7881250381469727\n",
      "Epoch: 2395\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.173\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.665\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8178746700286865\n",
      "Epoch: 2396\n",
      "\tTrain Loss: 3.818 | Train PPL:  45.507\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.664\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7911794185638428\n",
      "Epoch: 2397\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.309\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.662\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8224031925201416\n",
      "Epoch: 2398\n",
      "\tTrain Loss: 3.822 | Train PPL:  45.714\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.661\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7994937896728516\n",
      "Epoch: 2399\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.679\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.659\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7788641452789307\n",
      "Epoch: 2400\n",
      "\tTrain Loss: 3.779 | Train PPL:  43.766\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.658\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8100059032440186\n",
      "Epoch: 2401\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.151\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.656\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.776566505432129\n",
      "Epoch: 2402\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.666\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.655\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7956702709198\n",
      "Epoch: 2403\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.508\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.654\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7693870067596436\n",
      "Epoch: 2404\n",
      "\tTrain Loss: 3.769 | Train PPL:  43.353\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.653\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.803781032562256\n",
      "Epoch: 2405\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.871\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.653\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7547857761383057\n",
      "Epoch: 2406\n",
      "\tTrain Loss: 3.755 | Train PPL:  42.725\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.652\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8115408420562744\n",
      "Epoch: 2407\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.220\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.650\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.793254852294922\n",
      "Epoch: 2408\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.401\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.648\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7954928874969482\n",
      "Epoch: 2409\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.500\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.647\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8175265789031982\n",
      "Epoch: 2410\n",
      "\tTrain Loss: 3.818 | Train PPL:  45.492\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.645\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.808196783065796\n",
      "Epoch: 2411\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.069\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.644\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.783287763595581\n",
      "Epoch: 2412\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.960\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.643\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7949399948120117\n",
      "Epoch: 2413\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.476\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.643\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7800400257110596\n",
      "Epoch: 2414\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.818\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.643\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7839839458465576\n",
      "Epoch: 2415\n",
      "\tTrain Loss: 3.784 | Train PPL:  43.991\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.643\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7896203994750977\n",
      "Epoch: 2416\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.240\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.643\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.758009672164917\n",
      "Epoch: 2417\n",
      "\tTrain Loss: 3.758 | Train PPL:  42.863\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.643\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.787121295928955\n",
      "Epoch: 2418\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.129\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.642\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7878639698028564\n",
      "Epoch: 2419\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.162\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.640\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7955899238586426\n",
      "Epoch: 2420\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.504\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.639\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7935853004455566\n",
      "Epoch: 2421\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.415\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.638\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.805915355682373\n",
      "Epoch: 2422\n",
      "\tTrain Loss: 3.806 | Train PPL:  44.966\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.636\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7939016819000244\n",
      "Epoch: 2423\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.429\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.635\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.793893337249756\n",
      "Epoch: 2424\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.429\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.635\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7954728603363037\n",
      "Epoch: 2425\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.499\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.634\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7933037281036377\n",
      "Epoch: 2426\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.403\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.633\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7843823432922363\n",
      "Epoch: 2427\n",
      "\tTrain Loss: 3.784 | Train PPL:  44.008\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.632\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7905783653259277\n",
      "Epoch: 2428\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.282\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.632\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.791224241256714\n",
      "Epoch: 2429\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.311\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.632\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.785808801651001\n",
      "Epoch: 2430\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.071\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.631\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.818270444869995\n",
      "Epoch: 2431\n",
      "\tTrain Loss: 3.818 | Train PPL:  45.525\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.631\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7551631927490234\n",
      "Epoch: 2432\n",
      "\tTrain Loss: 3.755 | Train PPL:  42.741\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.630\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8061938285827637\n",
      "Epoch: 2433\n",
      "\tTrain Loss: 3.806 | Train PPL:  44.979\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.629\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7779135704040527\n",
      "Epoch: 2434\n",
      "\tTrain Loss: 3.778 | Train PPL:  43.725\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.629\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7832677364349365\n",
      "Epoch: 2435\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.959\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.628\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.785792112350464\n",
      "Epoch: 2436\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.071\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.628\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7820048332214355\n",
      "Epoch: 2437\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.904\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.628\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802582025527954\n",
      "Epoch: 2438\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.817\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.627\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7709572315216064\n",
      "Epoch: 2439\n",
      "\tTrain Loss: 3.771 | Train PPL:  43.422\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.626\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.775054454803467\n",
      "Epoch: 2440\n",
      "\tTrain Loss: 3.775 | Train PPL:  43.600\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.625\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.803863048553467\n",
      "Epoch: 2441\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.874\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.624\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.781538963317871\n",
      "Epoch: 2442\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.884\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.623\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7977712154388428\n",
      "Epoch: 2443\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.602\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.622\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7865824699401855\n",
      "Epoch: 2444\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.105\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.622\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.797266960144043\n",
      "Epoch: 2445\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.579\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.621\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7699618339538574\n",
      "Epoch: 2446\n",
      "\tTrain Loss: 3.770 | Train PPL:  43.378\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.620\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.788159132003784\n",
      "Epoch: 2447\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.175\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.620\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7636666297912598\n",
      "Epoch: 2448\n",
      "\tTrain Loss: 3.764 | Train PPL:  43.106\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.619\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.796076774597168\n",
      "Epoch: 2449\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.526\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.618\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.801213264465332\n",
      "Epoch: 2450\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.755\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.618\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7995264530181885\n",
      "Epoch: 2451\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.680\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.617\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8025619983673096\n",
      "Epoch: 2452\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.816\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.617\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8118679523468018\n",
      "Epoch: 2453\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.235\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.617\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7939677238464355\n",
      "Epoch: 2454\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.432\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.616\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8214104175567627\n",
      "Epoch: 2455\n",
      "\tTrain Loss: 3.821 | Train PPL:  45.669\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.616\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.801358222961426\n",
      "Epoch: 2456\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.762\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.615\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.782209873199463\n",
      "Epoch: 2457\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.913\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.615\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7816381454467773\n",
      "Epoch: 2458\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.888\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.614\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.772922992706299\n",
      "Epoch: 2459\n",
      "\tTrain Loss: 3.773 | Train PPL:  43.507\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.614\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.814974308013916\n",
      "Epoch: 2460\n",
      "\tTrain Loss: 3.815 | Train PPL:  45.376\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.614\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.783334255218506\n",
      "Epoch: 2461\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.962\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.614\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.820168972015381\n",
      "Epoch: 2462\n",
      "\tTrain Loss: 3.820 | Train PPL:  45.612\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.613\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8083322048187256\n",
      "Epoch: 2463\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.075\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.613\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7812283039093018\n",
      "Epoch: 2464\n",
      "\tTrain Loss: 3.781 | Train PPL:  43.870\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.613\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.796243190765381\n",
      "Epoch: 2465\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.534\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.614\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.757030963897705\n",
      "Epoch: 2466\n",
      "\tTrain Loss: 3.757 | Train PPL:  42.821\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.614\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.797922372817993\n",
      "Epoch: 2467\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.608\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.614\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.796203136444092\n",
      "Epoch: 2468\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.532\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.614\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7993998527526855\n",
      "Epoch: 2469\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.674\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.614\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7764718532562256\n",
      "Epoch: 2470\n",
      "\tTrain Loss: 3.776 | Train PPL:  43.662\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.614\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.776742696762085\n",
      "Epoch: 2471\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.674\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.615\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7845065593719482\n",
      "Epoch: 2472\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.014\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.616\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7803449630737305\n",
      "Epoch: 2473\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.831\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.617\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7953901290893555\n",
      "Epoch: 2474\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.496\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.618\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.796501636505127\n",
      "Epoch: 2475\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.545\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.619\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7721190452575684\n",
      "Epoch: 2476\n",
      "\tTrain Loss: 3.772 | Train PPL:  43.472\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.621\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.812067747116089\n",
      "Epoch: 2477\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.244\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.622\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7929112911224365\n",
      "Epoch: 2478\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.385\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.623\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8031089305877686\n",
      "Epoch: 2479\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.840\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.624\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7791647911071777\n",
      "Epoch: 2480\n",
      "\tTrain Loss: 3.779 | Train PPL:  43.779\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.624\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.79927134513855\n",
      "Epoch: 2481\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.669\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.625\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7808878421783447\n",
      "Epoch: 2482\n",
      "\tTrain Loss: 3.781 | Train PPL:  43.855\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.626\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7987847328186035\n",
      "Epoch: 2483\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.647\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.627\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7832648754119873\n",
      "Epoch: 2484\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.959\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.628\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7692744731903076\n",
      "Epoch: 2485\n",
      "\tTrain Loss: 3.769 | Train PPL:  43.349\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.629\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.794990062713623\n",
      "Epoch: 2486\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.478\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.629\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8184876441955566\n",
      "Epoch: 2487\n",
      "\tTrain Loss: 3.818 | Train PPL:  45.535\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.630\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7850170135498047\n",
      "Epoch: 2488\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.036\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.631\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.776146650314331\n",
      "Epoch: 2489\n",
      "\tTrain Loss: 3.776 | Train PPL:  43.648\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.632\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.797379970550537\n",
      "Epoch: 2490\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.584\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.633\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7790138721466064\n",
      "Epoch: 2491\n",
      "\tTrain Loss: 3.779 | Train PPL:  43.773\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.634\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7973217964172363\n",
      "Epoch: 2492\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.582\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.635\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8045408725738525\n",
      "Epoch: 2493\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.905\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.636\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.811947822570801\n",
      "Epoch: 2494\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.238\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.637\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7831382751464844\n",
      "Epoch: 2495\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.954\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.638\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7867085933685303\n",
      "Epoch: 2496\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.111\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.639\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.799790859222412\n",
      "Epoch: 2497\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.692\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.639\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.771724224090576\n",
      "Epoch: 2498\n",
      "\tTrain Loss: 3.772 | Train PPL:  43.455\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.639\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7982592582702637\n",
      "Epoch: 2499\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.623\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.639\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7888758182525635\n",
      "Epoch: 2500\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.207\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.640\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.826697826385498\n",
      "Epoch: 2501\n",
      "\tTrain Loss: 3.827 | Train PPL:  45.911\n",
      "\tVal Loss: 3.486 |  Val PPL:  32.639\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.791327714920044\n",
      "Epoch: 2502\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.315\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.638\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.794642210006714\n",
      "Epoch: 2503\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.462\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.637\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7968201637268066\n",
      "Epoch: 2504\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.559\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.636\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8308963775634766\n",
      "Epoch: 2505\n",
      "\tTrain Loss: 3.831 | Train PPL:  46.104\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.636\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7838211059570312\n",
      "Epoch: 2506\n",
      "\tTrain Loss: 3.784 | Train PPL:  43.984\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.636\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7891957759857178\n",
      "Epoch: 2507\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.221\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.635\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.786750316619873\n",
      "Epoch: 2508\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.113\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.636\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.798187017440796\n",
      "Epoch: 2509\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.620\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.635\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8101351261138916\n",
      "Epoch: 2510\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.157\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.634\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7800040245056152\n",
      "Epoch: 2511\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.816\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.632\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.774834632873535\n",
      "Epoch: 2512\n",
      "\tTrain Loss: 3.775 | Train PPL:  43.590\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.631\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7833566665649414\n",
      "Epoch: 2513\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.963\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.629\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7802276611328125\n",
      "Epoch: 2514\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.826\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.628\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7982707023620605\n",
      "Epoch: 2515\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.624\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.627\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.784461259841919\n",
      "Epoch: 2516\n",
      "\tTrain Loss: 3.784 | Train PPL:  44.012\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.626\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8086929321289062\n",
      "Epoch: 2517\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.091\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.625\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8055882453918457\n",
      "Epoch: 2518\n",
      "\tTrain Loss: 3.806 | Train PPL:  44.952\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.624\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7862491607666016\n",
      "Epoch: 2519\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.091\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.623\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8141705989837646\n",
      "Epoch: 2520\n",
      "\tTrain Loss: 3.814 | Train PPL:  45.339\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.622\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.775374174118042\n",
      "Epoch: 2521\n",
      "\tTrain Loss: 3.775 | Train PPL:  43.614\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.621\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8146400451660156\n",
      "Epoch: 2522\n",
      "\tTrain Loss: 3.815 | Train PPL:  45.360\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.620\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.777848482131958\n",
      "Epoch: 2523\n",
      "\tTrain Loss: 3.778 | Train PPL:  43.722\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.619\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.813868761062622\n",
      "Epoch: 2524\n",
      "\tTrain Loss: 3.814 | Train PPL:  45.325\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.619\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.803943157196045\n",
      "Epoch: 2525\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.878\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.618\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.793788194656372\n",
      "Epoch: 2526\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.424\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.617\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7814807891845703\n",
      "Epoch: 2527\n",
      "\tTrain Loss: 3.781 | Train PPL:  43.881\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.617\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.773682117462158\n",
      "Epoch: 2528\n",
      "\tTrain Loss: 3.774 | Train PPL:  43.540\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.617\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.817349433898926\n",
      "Epoch: 2529\n",
      "\tTrain Loss: 3.817 | Train PPL:  45.483\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.617\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.775002956390381\n",
      "Epoch: 2530\n",
      "\tTrain Loss: 3.775 | Train PPL:  43.598\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.616\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7926862239837646\n",
      "Epoch: 2531\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.375\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.615\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.792881488800049\n",
      "Epoch: 2532\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.384\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.615\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.790605306625366\n",
      "Epoch: 2533\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.283\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.614\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.788121223449707\n",
      "Epoch: 2534\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.173\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.612\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.771791696548462\n",
      "Epoch: 2535\n",
      "\tTrain Loss: 3.772 | Train PPL:  43.458\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.797189474105835\n",
      "Epoch: 2536\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.576\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.609\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.785120964050293\n",
      "Epoch: 2537\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.041\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.609\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.794480085372925\n",
      "Epoch: 2538\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.455\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.608\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7912487983703613\n",
      "Epoch: 2539\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.312\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.608\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7869341373443604\n",
      "Epoch: 2540\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.121\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.609\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8012447357177734\n",
      "Epoch: 2541\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.757\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.609\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.838157892227173\n",
      "Epoch: 2542\n",
      "\tTrain Loss: 3.838 | Train PPL:  46.440\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.610\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7944657802581787\n",
      "Epoch: 2543\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.454\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.610\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.815946340560913\n",
      "Epoch: 2544\n",
      "\tTrain Loss: 3.816 | Train PPL:  45.420\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.610\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7729697227478027\n",
      "Epoch: 2545\n",
      "\tTrain Loss: 3.773 | Train PPL:  43.509\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.610\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8075110912323\n",
      "Epoch: 2546\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.038\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.610\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7546708583831787\n",
      "Epoch: 2547\n",
      "\tTrain Loss: 3.755 | Train PPL:  42.720\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.610\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.784449338912964\n",
      "Epoch: 2548\n",
      "\tTrain Loss: 3.784 | Train PPL:  44.011\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.610\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7939369678497314\n",
      "Epoch: 2549\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.431\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.610\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.791842460632324\n",
      "Epoch: 2550\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.338\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.610\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.769627094268799\n",
      "Epoch: 2551\n",
      "\tTrain Loss: 3.770 | Train PPL:  43.364\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7936666011810303\n",
      "Epoch: 2552\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.419\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.807222366333008\n",
      "Epoch: 2553\n",
      "\tTrain Loss: 3.807 | Train PPL:  45.025\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7902774810791016\n",
      "Epoch: 2554\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.269\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7966012954711914\n",
      "Epoch: 2555\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.550\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8176629543304443\n",
      "Epoch: 2556\n",
      "\tTrain Loss: 3.818 | Train PPL:  45.498\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.798933744430542\n",
      "Epoch: 2557\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.654\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7767493724823\n",
      "Epoch: 2558\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.674\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7914633750915527\n",
      "Epoch: 2559\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.321\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.777143955230713\n",
      "Epoch: 2560\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.691\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.78484845161438\n",
      "Epoch: 2561\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.029\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7656233310699463\n",
      "Epoch: 2562\n",
      "\tTrain Loss: 3.766 | Train PPL:  43.191\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7821569442749023\n",
      "Epoch: 2563\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.911\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7698099613189697\n",
      "Epoch: 2564\n",
      "\tTrain Loss: 3.770 | Train PPL:  43.372\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.782487154006958\n",
      "Epoch: 2565\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.925\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8044071197509766\n",
      "Epoch: 2566\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.899\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.610\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7723686695098877\n",
      "Epoch: 2567\n",
      "\tTrain Loss: 3.772 | Train PPL:  43.483\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.610\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8154585361480713\n",
      "Epoch: 2568\n",
      "\tTrain Loss: 3.815 | Train PPL:  45.398\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7793009281158447\n",
      "Epoch: 2569\n",
      "\tTrain Loss: 3.779 | Train PPL:  43.785\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.612\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7765889167785645\n",
      "Epoch: 2570\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.667\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.612\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.787351369857788\n",
      "Epoch: 2571\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.139\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.613\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7915146350860596\n",
      "Epoch: 2572\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.323\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.612\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7820146083831787\n",
      "Epoch: 2573\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.904\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.612\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7765543460845947\n",
      "Epoch: 2574\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.665\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.612\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7872939109802246\n",
      "Epoch: 2575\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.137\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8051352500915527\n",
      "Epoch: 2576\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.931\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.611\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.78112530708313\n",
      "Epoch: 2577\n",
      "\tTrain Loss: 3.781 | Train PPL:  43.865\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.610\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.790388822555542\n",
      "Epoch: 2578\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.274\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.610\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.816645622253418\n",
      "Epoch: 2579\n",
      "\tTrain Loss: 3.817 | Train PPL:  45.451\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.609\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7855026721954346\n",
      "Epoch: 2580\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.058\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.609\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.804231882095337\n",
      "Epoch: 2581\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.891\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.608\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.772026538848877\n",
      "Epoch: 2582\n",
      "\tTrain Loss: 3.772 | Train PPL:  43.468\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.607\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8069512844085693\n",
      "Epoch: 2583\n",
      "\tTrain Loss: 3.807 | Train PPL:  45.013\n",
      "\tVal Loss: 3.485 |  Val PPL:  32.606\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.808764696121216\n",
      "Epoch: 2584\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.095\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.605\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8051042556762695\n",
      "Epoch: 2585\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.930\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.604\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.761821746826172\n",
      "Epoch: 2586\n",
      "\tTrain Loss: 3.762 | Train PPL:  43.027\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.603\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8020317554473877\n",
      "Epoch: 2587\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.792\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.602\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7812302112579346\n",
      "Epoch: 2588\n",
      "\tTrain Loss: 3.781 | Train PPL:  43.870\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.601\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.794431209564209\n",
      "Epoch: 2589\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.453\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.599\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.780987501144409\n",
      "Epoch: 2590\n",
      "\tTrain Loss: 3.781 | Train PPL:  43.859\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.598\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8171582221984863\n",
      "Epoch: 2591\n",
      "\tTrain Loss: 3.817 | Train PPL:  45.475\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.596\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8137831687927246\n",
      "Epoch: 2592\n",
      "\tTrain Loss: 3.814 | Train PPL:  45.322\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.595\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8113198280334473\n",
      "Epoch: 2593\n",
      "\tTrain Loss: 3.811 | Train PPL:  45.210\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.594\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8035085201263428\n",
      "Epoch: 2594\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.858\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.593\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7891006469726562\n",
      "Epoch: 2595\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.217\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.593\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7914929389953613\n",
      "Epoch: 2596\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.323\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.592\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7663686275482178\n",
      "Epoch: 2597\n",
      "\tTrain Loss: 3.766 | Train PPL:  43.223\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.591\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8022236824035645\n",
      "Epoch: 2598\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.801\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.590\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.789503335952759\n",
      "Epoch: 2599\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.234\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.589\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.791332960128784\n",
      "Epoch: 2600\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.315\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.589\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.799330472946167\n",
      "Epoch: 2601\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.671\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.588\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7896220684051514\n",
      "Epoch: 2602\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.240\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.586\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8047375679016113\n",
      "Epoch: 2603\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.913\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.585\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8094325065612793\n",
      "Epoch: 2604\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.125\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.584\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7866790294647217\n",
      "Epoch: 2605\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.110\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.583\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.792880058288574\n",
      "Epoch: 2606\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.384\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.582\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8150579929351807\n",
      "Epoch: 2607\n",
      "\tTrain Loss: 3.815 | Train PPL:  45.379\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.581\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7942121028900146\n",
      "Epoch: 2608\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.443\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.580\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7665629386901855\n",
      "Epoch: 2609\n",
      "\tTrain Loss: 3.767 | Train PPL:  43.231\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.579\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8018405437469482\n",
      "Epoch: 2610\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.784\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.578\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.792175054550171\n",
      "Epoch: 2611\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.353\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.577\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.779728651046753\n",
      "Epoch: 2612\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.804\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.576\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.791426181793213\n",
      "Epoch: 2613\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.320\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.576\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7950029373168945\n",
      "Epoch: 2614\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.478\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.577\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.777132749557495\n",
      "Epoch: 2615\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.691\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.577\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.79060697555542\n",
      "Epoch: 2616\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.283\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.577\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7945563793182373\n",
      "Epoch: 2617\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.459\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.577\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.810299873352051\n",
      "Epoch: 2618\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.164\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.577\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7769811153411865\n",
      "Epoch: 2619\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.684\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.578\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.796149969100952\n",
      "Epoch: 2620\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.529\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.578\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8035404682159424\n",
      "Epoch: 2621\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.860\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.578\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.764293670654297\n",
      "Epoch: 2622\n",
      "\tTrain Loss: 3.764 | Train PPL:  43.133\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.579\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7941315174102783\n",
      "Epoch: 2623\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.440\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.580\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7958102226257324\n",
      "Epoch: 2624\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.514\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.580\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7989752292633057\n",
      "Epoch: 2625\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.655\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.581\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8024630546569824\n",
      "Epoch: 2626\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.811\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.581\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8083181381225586\n",
      "Epoch: 2627\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.075\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.582\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8093230724334717\n",
      "Epoch: 2628\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.120\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.583\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.807875633239746\n",
      "Epoch: 2629\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.055\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.583\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8026788234710693\n",
      "Epoch: 2630\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.821\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.583\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.803802251815796\n",
      "Epoch: 2631\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.871\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.583\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7899205684661865\n",
      "Epoch: 2632\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.253\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.583\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.767859935760498\n",
      "Epoch: 2633\n",
      "\tTrain Loss: 3.768 | Train PPL:  43.287\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.583\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.800360679626465\n",
      "Epoch: 2634\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.717\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.583\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.799940347671509\n",
      "Epoch: 2635\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.699\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.583\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7851622104644775\n",
      "Epoch: 2636\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.043\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.584\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.789900541305542\n",
      "Epoch: 2637\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.252\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.585\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.812528371810913\n",
      "Epoch: 2638\n",
      "\tTrain Loss: 3.813 | Train PPL:  45.265\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.586\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.79274845123291\n",
      "Epoch: 2639\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.378\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.588\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7904648780822754\n",
      "Epoch: 2640\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.277\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.589\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7954697608947754\n",
      "Epoch: 2641\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.499\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.591\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.776932954788208\n",
      "Epoch: 2642\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.682\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.592\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.790947914123535\n",
      "Epoch: 2643\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.298\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.594\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8005051612854004\n",
      "Epoch: 2644\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.724\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.595\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.811075210571289\n",
      "Epoch: 2645\n",
      "\tTrain Loss: 3.811 | Train PPL:  45.199\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.596\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7899417877197266\n",
      "Epoch: 2646\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.254\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.598\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7825496196746826\n",
      "Epoch: 2647\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.928\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.599\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7770631313323975\n",
      "Epoch: 2648\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.688\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.601\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.797618865966797\n",
      "Epoch: 2649\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.595\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.602\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7989084720611572\n",
      "Epoch: 2650\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.652\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.603\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.773329973220825\n",
      "Epoch: 2651\n",
      "\tTrain Loss: 3.773 | Train PPL:  43.525\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.604\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7889320850372314\n",
      "Epoch: 2652\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.209\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.604\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.796339511871338\n",
      "Epoch: 2653\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.538\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.604\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.784400224685669\n",
      "Epoch: 2654\n",
      "\tTrain Loss: 3.784 | Train PPL:  44.009\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.604\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7940480709075928\n",
      "Epoch: 2655\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.436\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.605\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7837917804718018\n",
      "Epoch: 2656\n",
      "\tTrain Loss: 3.784 | Train PPL:  43.982\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.605\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.794537305831909\n",
      "Epoch: 2657\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.458\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.604\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.780054807662964\n",
      "Epoch: 2658\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.818\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.604\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.821791648864746\n",
      "Epoch: 2659\n",
      "\tTrain Loss: 3.822 | Train PPL:  45.686\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.603\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8069465160369873\n",
      "Epoch: 2660\n",
      "\tTrain Loss: 3.807 | Train PPL:  45.013\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.602\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.781691551208496\n",
      "Epoch: 2661\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.890\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.601\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7984578609466553\n",
      "Epoch: 2662\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.632\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.600\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.79902720451355\n",
      "Epoch: 2663\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.658\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.599\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7907328605651855\n",
      "Epoch: 2664\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.289\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.597\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.752101421356201\n",
      "Epoch: 2665\n",
      "\tTrain Loss: 3.752 | Train PPL:  42.611\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.596\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7751479148864746\n",
      "Epoch: 2666\n",
      "\tTrain Loss: 3.775 | Train PPL:  43.604\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.594\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.811326026916504\n",
      "Epoch: 2667\n",
      "\tTrain Loss: 3.811 | Train PPL:  45.210\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.592\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.757871627807617\n",
      "Epoch: 2668\n",
      "\tTrain Loss: 3.758 | Train PPL:  42.857\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.590\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8147497177124023\n",
      "Epoch: 2669\n",
      "\tTrain Loss: 3.815 | Train PPL:  45.365\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.588\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7599430084228516\n",
      "Epoch: 2670\n",
      "\tTrain Loss: 3.760 | Train PPL:  42.946\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.586\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8131818771362305\n",
      "Epoch: 2671\n",
      "\tTrain Loss: 3.813 | Train PPL:  45.294\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.585\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.81857967376709\n",
      "Epoch: 2672\n",
      "\tTrain Loss: 3.819 | Train PPL:  45.539\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.584\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.82344388961792\n",
      "Epoch: 2673\n",
      "\tTrain Loss: 3.823 | Train PPL:  45.762\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.584\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7888505458831787\n",
      "Epoch: 2674\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.206\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.583\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.793328046798706\n",
      "Epoch: 2675\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.404\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.582\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7813944816589355\n",
      "Epoch: 2676\n",
      "\tTrain Loss: 3.781 | Train PPL:  43.877\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.582\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7934539318084717\n",
      "Epoch: 2677\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.410\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.581\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8117570877075195\n",
      "Epoch: 2678\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.230\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.581\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8029110431671143\n",
      "Epoch: 2679\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.832\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.581\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7986550331115723\n",
      "Epoch: 2680\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.641\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.581\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.808279514312744\n",
      "Epoch: 2681\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.073\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.582\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7951130867004395\n",
      "Epoch: 2682\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.483\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.582\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7980310916900635\n",
      "Epoch: 2683\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.613\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.582\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7915186882019043\n",
      "Epoch: 2684\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.324\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.582\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.794142723083496\n",
      "Epoch: 2685\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.440\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.582\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7777490615844727\n",
      "Epoch: 2686\n",
      "\tTrain Loss: 3.778 | Train PPL:  43.718\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.583\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7914390563964844\n",
      "Epoch: 2687\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.320\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.584\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.765075445175171\n",
      "Epoch: 2688\n",
      "\tTrain Loss: 3.765 | Train PPL:  43.167\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.585\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8031187057495117\n",
      "Epoch: 2689\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.841\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.586\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.80314040184021\n",
      "Epoch: 2690\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.842\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.586\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7870941162109375\n",
      "Epoch: 2691\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.128\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.587\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.795396089553833\n",
      "Epoch: 2692\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.496\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.588\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.778118848800659\n",
      "Epoch: 2693\n",
      "\tTrain Loss: 3.778 | Train PPL:  43.734\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.589\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7955482006073\n",
      "Epoch: 2694\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.503\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.590\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.791924476623535\n",
      "Epoch: 2695\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.342\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.590\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7989330291748047\n",
      "Epoch: 2696\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.654\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.590\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.779423952102661\n",
      "Epoch: 2697\n",
      "\tTrain Loss: 3.779 | Train PPL:  43.791\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.591\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7813165187835693\n",
      "Epoch: 2698\n",
      "\tTrain Loss: 3.781 | Train PPL:  43.874\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.591\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.80554461479187\n",
      "Epoch: 2699\n",
      "\tTrain Loss: 3.806 | Train PPL:  44.950\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.591\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.788182020187378\n",
      "Epoch: 2700\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.176\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.590\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.779689073562622\n",
      "Epoch: 2701\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.802\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.590\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.775118827819824\n",
      "Epoch: 2702\n",
      "\tTrain Loss: 3.775 | Train PPL:  43.603\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.589\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7977538108825684\n",
      "Epoch: 2703\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.601\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.588\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8003897666931152\n",
      "Epoch: 2704\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.719\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.588\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7859866619110107\n",
      "Epoch: 2705\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.079\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.587\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.764648675918579\n",
      "Epoch: 2706\n",
      "\tTrain Loss: 3.765 | Train PPL:  43.149\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.585\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7883267402648926\n",
      "Epoch: 2707\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.182\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.584\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7801380157470703\n",
      "Epoch: 2708\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.822\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.581\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.786302328109741\n",
      "Epoch: 2709\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.093\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.580\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.787485122680664\n",
      "Epoch: 2710\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.145\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.578\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7805545330047607\n",
      "Epoch: 2711\n",
      "\tTrain Loss: 3.781 | Train PPL:  43.840\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.576\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7988133430480957\n",
      "Epoch: 2712\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.648\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.574\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7633209228515625\n",
      "Epoch: 2713\n",
      "\tTrain Loss: 3.763 | Train PPL:  43.091\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.572\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.771552801132202\n",
      "Epoch: 2714\n",
      "\tTrain Loss: 3.772 | Train PPL:  43.447\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.571\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.783133029937744\n",
      "Epoch: 2715\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.954\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.570\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7766082286834717\n",
      "Epoch: 2716\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.668\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.568\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.805009126663208\n",
      "Epoch: 2717\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.926\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.568\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7932660579681396\n",
      "Epoch: 2718\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.401\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.566\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.758697748184204\n",
      "Epoch: 2719\n",
      "\tTrain Loss: 3.759 | Train PPL:  42.893\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.565\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.792818784713745\n",
      "Epoch: 2720\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.381\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.564\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7955148220062256\n",
      "Epoch: 2721\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.501\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.563\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7561349868774414\n",
      "Epoch: 2722\n",
      "\tTrain Loss: 3.756 | Train PPL:  42.783\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.562\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7637939453125\n",
      "Epoch: 2723\n",
      "\tTrain Loss: 3.764 | Train PPL:  43.112\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.561\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7666938304901123\n",
      "Epoch: 2724\n",
      "\tTrain Loss: 3.767 | Train PPL:  43.237\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.560\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.799705982208252\n",
      "Epoch: 2725\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.688\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.559\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7786552906036377\n",
      "Epoch: 2726\n",
      "\tTrain Loss: 3.779 | Train PPL:  43.757\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.559\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7863829135894775\n",
      "Epoch: 2727\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.097\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.558\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7769436836242676\n",
      "Epoch: 2728\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.682\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.557\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7690789699554443\n",
      "Epoch: 2729\n",
      "\tTrain Loss: 3.769 | Train PPL:  43.340\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.556\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.792418956756592\n",
      "Epoch: 2730\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.364\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.555\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8071017265319824\n",
      "Epoch: 2731\n",
      "\tTrain Loss: 3.807 | Train PPL:  45.020\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.555\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8223299980163574\n",
      "Epoch: 2732\n",
      "\tTrain Loss: 3.822 | Train PPL:  45.711\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.555\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.779757261276245\n",
      "Epoch: 2733\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.805\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.555\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7964375019073486\n",
      "Epoch: 2734\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.542\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.555\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.799926519393921\n",
      "Epoch: 2735\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.698\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.556\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.794015407562256\n",
      "Epoch: 2736\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.434\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.555\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.780311107635498\n",
      "Epoch: 2737\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.830\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.555\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7933425903320312\n",
      "Epoch: 2738\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.405\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.556\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7609503269195557\n",
      "Epoch: 2739\n",
      "\tTrain Loss: 3.761 | Train PPL:  42.989\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.555\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7907068729400635\n",
      "Epoch: 2740\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.288\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.555\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7965681552886963\n",
      "Epoch: 2741\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.548\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.555\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7864482402801514\n",
      "Epoch: 2742\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.099\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.554\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7875516414642334\n",
      "Epoch: 2743\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.148\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.553\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7934517860412598\n",
      "Epoch: 2744\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.409\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.553\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.775263547897339\n",
      "Epoch: 2745\n",
      "\tTrain Loss: 3.775 | Train PPL:  43.609\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.553\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.796926975250244\n",
      "Epoch: 2746\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.564\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.553\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7897400856018066\n",
      "Epoch: 2747\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.245\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.553\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7834761142730713\n",
      "Epoch: 2748\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.969\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.554\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.807346820831299\n",
      "Epoch: 2749\n",
      "\tTrain Loss: 3.807 | Train PPL:  45.031\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.554\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8005764484405518\n",
      "Epoch: 2750\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.727\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.555\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8094897270202637\n",
      "Epoch: 2751\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.127\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.555\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7969443798065186\n",
      "Epoch: 2752\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.565\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.555\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8011622428894043\n",
      "Epoch: 2753\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.753\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.555\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8168938159942627\n",
      "Epoch: 2754\n",
      "\tTrain Loss: 3.817 | Train PPL:  45.463\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.556\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7878031730651855\n",
      "Epoch: 2755\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.159\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.557\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.821528434753418\n",
      "Epoch: 2756\n",
      "\tTrain Loss: 3.822 | Train PPL:  45.674\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.558\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7780399322509766\n",
      "Epoch: 2757\n",
      "\tTrain Loss: 3.778 | Train PPL:  43.730\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.559\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7634668350219727\n",
      "Epoch: 2758\n",
      "\tTrain Loss: 3.763 | Train PPL:  43.098\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.560\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7929582595825195\n",
      "Epoch: 2759\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.388\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.561\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8075642585754395\n",
      "Epoch: 2760\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.041\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.562\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7889692783355713\n",
      "Epoch: 2761\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.211\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.562\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7828876972198486\n",
      "Epoch: 2762\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.943\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.563\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7846126556396484\n",
      "Epoch: 2763\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.019\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.564\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7941107749938965\n",
      "Epoch: 2764\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.439\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.565\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.798558473587036\n",
      "Epoch: 2765\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.637\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.566\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7829489707946777\n",
      "Epoch: 2766\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.945\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.566\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.815847158432007\n",
      "Epoch: 2767\n",
      "\tTrain Loss: 3.816 | Train PPL:  45.415\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.567\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.808856725692749\n",
      "Epoch: 2768\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.099\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.569\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.788559675216675\n",
      "Epoch: 2769\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.193\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.570\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.811520576477051\n",
      "Epoch: 2770\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.219\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.570\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7763235569000244\n",
      "Epoch: 2771\n",
      "\tTrain Loss: 3.776 | Train PPL:  43.655\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.571\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.771125316619873\n",
      "Epoch: 2772\n",
      "\tTrain Loss: 3.771 | Train PPL:  43.429\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.572\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.768298864364624\n",
      "Epoch: 2773\n",
      "\tTrain Loss: 3.768 | Train PPL:  43.306\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.573\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8059420585632324\n",
      "Epoch: 2774\n",
      "\tTrain Loss: 3.806 | Train PPL:  44.968\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.574\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.790005683898926\n",
      "Epoch: 2775\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.257\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.574\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7928526401519775\n",
      "Epoch: 2776\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.383\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.575\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8000266551971436\n",
      "Epoch: 2777\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.702\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.576\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7732598781585693\n",
      "Epoch: 2778\n",
      "\tTrain Loss: 3.773 | Train PPL:  43.522\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.575\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7874820232391357\n",
      "Epoch: 2779\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.145\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.575\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7664294242858887\n",
      "Epoch: 2780\n",
      "\tTrain Loss: 3.766 | Train PPL:  43.225\n",
      "\tVal Loss: 3.484 |  Val PPL:  32.574\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.78210711479187\n",
      "Epoch: 2781\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.908\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.573\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.781414031982422\n",
      "Epoch: 2782\n",
      "\tTrain Loss: 3.781 | Train PPL:  43.878\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.573\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7942585945129395\n",
      "Epoch: 2783\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.445\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.572\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8003978729248047\n",
      "Epoch: 2784\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.719\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.572\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7957301139831543\n",
      "Epoch: 2785\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.511\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.571\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7787017822265625\n",
      "Epoch: 2786\n",
      "\tTrain Loss: 3.779 | Train PPL:  43.759\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.571\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.806428909301758\n",
      "Epoch: 2787\n",
      "\tTrain Loss: 3.806 | Train PPL:  44.989\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.570\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7978765964508057\n",
      "Epoch: 2788\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.606\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.570\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7837038040161133\n",
      "Epoch: 2789\n",
      "\tTrain Loss: 3.784 | Train PPL:  43.979\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.569\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.798809289932251\n",
      "Epoch: 2790\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.648\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.569\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.803544044494629\n",
      "Epoch: 2791\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.860\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.569\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8126437664031982\n",
      "Epoch: 2792\n",
      "\tTrain Loss: 3.813 | Train PPL:  45.270\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.569\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7879958152770996\n",
      "Epoch: 2793\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.168\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.568\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.763871669769287\n",
      "Epoch: 2794\n",
      "\tTrain Loss: 3.764 | Train PPL:  43.115\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.568\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7782554626464844\n",
      "Epoch: 2795\n",
      "\tTrain Loss: 3.778 | Train PPL:  43.740\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.567\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7917609214782715\n",
      "Epoch: 2796\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.334\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.567\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.778991937637329\n",
      "Epoch: 2797\n",
      "\tTrain Loss: 3.779 | Train PPL:  43.772\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.567\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7939109802246094\n",
      "Epoch: 2798\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.430\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.566\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7861239910125732\n",
      "Epoch: 2799\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.085\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.566\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7909841537475586\n",
      "Epoch: 2800\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.300\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.567\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.812469482421875\n",
      "Epoch: 2801\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.262\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.567\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7776541709899902\n",
      "Epoch: 2802\n",
      "\tTrain Loss: 3.778 | Train PPL:  43.713\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.567\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802779197692871\n",
      "Epoch: 2803\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.826\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.567\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7670035362243652\n",
      "Epoch: 2804\n",
      "\tTrain Loss: 3.767 | Train PPL:  43.250\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.566\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.793936014175415\n",
      "Epoch: 2805\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.431\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.566\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802816867828369\n",
      "Epoch: 2806\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.827\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.566\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.782634973526001\n",
      "Epoch: 2807\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.932\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.566\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.783203125\n",
      "Epoch: 2808\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.957\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.566\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7961678504943848\n",
      "Epoch: 2809\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.530\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.566\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7969210147857666\n",
      "Epoch: 2810\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.564\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.566\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8205740451812744\n",
      "Epoch: 2811\n",
      "\tTrain Loss: 3.821 | Train PPL:  45.630\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.566\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8129961490631104\n",
      "Epoch: 2812\n",
      "\tTrain Loss: 3.813 | Train PPL:  45.286\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.566\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7825469970703125\n",
      "Epoch: 2813\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.928\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.565\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7960731983184814\n",
      "Epoch: 2814\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.526\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.565\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7861924171447754\n",
      "Epoch: 2815\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.088\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.564\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7967379093170166\n",
      "Epoch: 2816\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.556\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.564\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.81272554397583\n",
      "Epoch: 2817\n",
      "\tTrain Loss: 3.813 | Train PPL:  45.274\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.564\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.796008586883545\n",
      "Epoch: 2818\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.523\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.563\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7985527515411377\n",
      "Epoch: 2819\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.637\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.563\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7873127460479736\n",
      "Epoch: 2820\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.138\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.562\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.779958486557007\n",
      "Epoch: 2821\n",
      "\tTrain Loss: 3.780 | Train PPL:  43.814\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.561\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.771111249923706\n",
      "Epoch: 2822\n",
      "\tTrain Loss: 3.771 | Train PPL:  43.428\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.560\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.800800323486328\n",
      "Epoch: 2823\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.737\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.559\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7726149559020996\n",
      "Epoch: 2824\n",
      "\tTrain Loss: 3.773 | Train PPL:  43.494\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.557\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7853200435638428\n",
      "Epoch: 2825\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.050\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.556\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8249661922454834\n",
      "Epoch: 2826\n",
      "\tTrain Loss: 3.825 | Train PPL:  45.831\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.555\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.815196990966797\n",
      "Epoch: 2827\n",
      "\tTrain Loss: 3.815 | Train PPL:  45.386\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.553\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.805704355239868\n",
      "Epoch: 2828\n",
      "\tTrain Loss: 3.806 | Train PPL:  44.957\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.552\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7830469608306885\n",
      "Epoch: 2829\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.950\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.550\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7758264541625977\n",
      "Epoch: 2830\n",
      "\tTrain Loss: 3.776 | Train PPL:  43.634\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.548\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.784012794494629\n",
      "Epoch: 2831\n",
      "\tTrain Loss: 3.784 | Train PPL:  43.992\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.547\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.770935535430908\n",
      "Epoch: 2832\n",
      "\tTrain Loss: 3.771 | Train PPL:  43.421\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.546\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.769320487976074\n",
      "Epoch: 2833\n",
      "\tTrain Loss: 3.769 | Train PPL:  43.351\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.545\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.785315752029419\n",
      "Epoch: 2834\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.050\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.545\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.782851219177246\n",
      "Epoch: 2835\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.941\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.544\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7895102500915527\n",
      "Epoch: 2836\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.235\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.543\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7882657051086426\n",
      "Epoch: 2837\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.180\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.543\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7844784259796143\n",
      "Epoch: 2838\n",
      "\tTrain Loss: 3.784 | Train PPL:  44.013\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.543\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7933707237243652\n",
      "Epoch: 2839\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.406\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.543\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7994349002838135\n",
      "Epoch: 2840\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.676\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.543\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.76420521736145\n",
      "Epoch: 2841\n",
      "\tTrain Loss: 3.764 | Train PPL:  43.129\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.542\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7988572120666504\n",
      "Epoch: 2842\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.650\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.542\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7868192195892334\n",
      "Epoch: 2843\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.116\n",
      "\tVal Loss: 3.483 |  Val PPL:  32.541\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.809474229812622\n",
      "Epoch: 2844\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.127\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.540\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7902657985687256\n",
      "Epoch: 2845\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.268\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.538\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.800281047821045\n",
      "Epoch: 2846\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.714\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.537\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.789353132247925\n",
      "Epoch: 2847\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.228\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.535\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7848973274230957\n",
      "Epoch: 2848\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.031\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.534\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7949750423431396\n",
      "Epoch: 2849\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.477\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.533\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7863810062408447\n",
      "Epoch: 2850\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.097\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.531\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7827365398406982\n",
      "Epoch: 2851\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.936\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.531\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7905242443084717\n",
      "Epoch: 2852\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.280\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.531\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7534825801849365\n",
      "Epoch: 2853\n",
      "\tTrain Loss: 3.753 | Train PPL:  42.669\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.530\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.787219762802124\n",
      "Epoch: 2854\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.134\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.531\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8203892707824707\n",
      "Epoch: 2855\n",
      "\tTrain Loss: 3.820 | Train PPL:  45.622\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.531\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8231897354125977\n",
      "Epoch: 2856\n",
      "\tTrain Loss: 3.823 | Train PPL:  45.750\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.530\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8088576793670654\n",
      "Epoch: 2857\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.099\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.530\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8080105781555176\n",
      "Epoch: 2858\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.061\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.529\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7913198471069336\n",
      "Epoch: 2859\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.315\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.529\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7865121364593506\n",
      "Epoch: 2860\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.102\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.528\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7829976081848145\n",
      "Epoch: 2861\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.948\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.527\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8036439418792725\n",
      "Epoch: 2862\n",
      "\tTrain Loss: 3.804 | Train PPL:  44.864\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.526\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7789461612701416\n",
      "Epoch: 2863\n",
      "\tTrain Loss: 3.779 | Train PPL:  43.770\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.525\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802457332611084\n",
      "Epoch: 2864\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.811\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.525\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8049848079681396\n",
      "Epoch: 2865\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.925\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.525\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.795459508895874\n",
      "Epoch: 2866\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.499\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.524\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.792048454284668\n",
      "Epoch: 2867\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.347\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.523\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.775493621826172\n",
      "Epoch: 2868\n",
      "\tTrain Loss: 3.775 | Train PPL:  43.619\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.522\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.805075168609619\n",
      "Epoch: 2869\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.929\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.522\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.795797348022461\n",
      "Epoch: 2870\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.514\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.522\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7726075649261475\n",
      "Epoch: 2871\n",
      "\tTrain Loss: 3.773 | Train PPL:  43.493\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.522\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7922189235687256\n",
      "Epoch: 2872\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.355\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.521\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7715678215026855\n",
      "Epoch: 2873\n",
      "\tTrain Loss: 3.772 | Train PPL:  43.448\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.520\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8138577938079834\n",
      "Epoch: 2874\n",
      "\tTrain Loss: 3.814 | Train PPL:  45.325\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.521\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.790802478790283\n",
      "Epoch: 2875\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.292\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.521\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.80846905708313\n",
      "Epoch: 2876\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.081\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.521\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7945327758789062\n",
      "Epoch: 2877\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.457\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.520\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7727878093719482\n",
      "Epoch: 2878\n",
      "\tTrain Loss: 3.773 | Train PPL:  43.501\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.520\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.797929525375366\n",
      "Epoch: 2879\n",
      "\tTrain Loss: 3.798 | Train PPL:  44.609\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.519\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8005075454711914\n",
      "Epoch: 2880\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.724\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.519\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.784092426300049\n",
      "Epoch: 2881\n",
      "\tTrain Loss: 3.784 | Train PPL:  43.996\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.518\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.800299644470215\n",
      "Epoch: 2882\n",
      "\tTrain Loss: 3.800 | Train PPL:  44.715\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.518\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.776890754699707\n",
      "Epoch: 2883\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.680\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.517\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.784677743911743\n",
      "Epoch: 2884\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.021\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.516\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.786571741104126\n",
      "Epoch: 2885\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.105\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.516\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7818121910095215\n",
      "Epoch: 2886\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.896\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.515\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7685883045196533\n",
      "Epoch: 2887\n",
      "\tTrain Loss: 3.769 | Train PPL:  43.319\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.514\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7824575901031494\n",
      "Epoch: 2888\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.924\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.513\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.784552812576294\n",
      "Epoch: 2889\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.016\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.512\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7616045475006104\n",
      "Epoch: 2890\n",
      "\tTrain Loss: 3.762 | Train PPL:  43.017\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.512\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.788583755493164\n",
      "Epoch: 2891\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.194\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.510\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.786625862121582\n",
      "Epoch: 2892\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.107\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.510\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8155694007873535\n",
      "Epoch: 2893\n",
      "\tTrain Loss: 3.816 | Train PPL:  45.403\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.509\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.786867141723633\n",
      "Epoch: 2894\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.118\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.509\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.811152696609497\n",
      "Epoch: 2895\n",
      "\tTrain Loss: 3.811 | Train PPL:  45.203\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.509\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.821986675262451\n",
      "Epoch: 2896\n",
      "\tTrain Loss: 3.822 | Train PPL:  45.695\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.509\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.785161018371582\n",
      "Epoch: 2897\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.043\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.508\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.810694456100464\n",
      "Epoch: 2898\n",
      "\tTrain Loss: 3.811 | Train PPL:  45.182\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.508\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7909841537475586\n",
      "Epoch: 2899\n",
      "\tTrain Loss: 3.791 | Train PPL:  44.300\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.508\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8006534576416016\n",
      "Epoch: 2900\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.730\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.508\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7675673961639404\n",
      "Epoch: 2901\n",
      "\tTrain Loss: 3.768 | Train PPL:  43.275\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.507\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7669122219085693\n",
      "Epoch: 2902\n",
      "\tTrain Loss: 3.767 | Train PPL:  43.246\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.507\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.763288974761963\n",
      "Epoch: 2903\n",
      "\tTrain Loss: 3.763 | Train PPL:  43.090\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.507\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.789947748184204\n",
      "Epoch: 2904\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.254\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.508\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7734413146972656\n",
      "Epoch: 2905\n",
      "\tTrain Loss: 3.773 | Train PPL:  43.530\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.509\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7823173999786377\n",
      "Epoch: 2906\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.918\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.510\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7986180782318115\n",
      "Epoch: 2907\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.639\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.511\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.809248208999634\n",
      "Epoch: 2908\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.117\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.511\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8124895095825195\n",
      "Epoch: 2909\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.263\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.511\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.795337677001953\n",
      "Epoch: 2910\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.493\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.511\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8016247749328613\n",
      "Epoch: 2911\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.774\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.510\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7827095985412598\n",
      "Epoch: 2912\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.935\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.509\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7839198112487793\n",
      "Epoch: 2913\n",
      "\tTrain Loss: 3.784 | Train PPL:  43.988\n",
      "\tVal Loss: 3.482 |  Val PPL:  32.509\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.762101650238037\n",
      "Epoch: 2914\n",
      "\tTrain Loss: 3.762 | Train PPL:  43.039\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.508\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.775191068649292\n",
      "Epoch: 2915\n",
      "\tTrain Loss: 3.775 | Train PPL:  43.606\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.506\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.785860061645508\n",
      "Epoch: 2916\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.074\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.505\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.759361982345581\n",
      "Epoch: 2917\n",
      "\tTrain Loss: 3.759 | Train PPL:  42.921\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.504\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7766127586364746\n",
      "Epoch: 2918\n",
      "\tTrain Loss: 3.777 | Train PPL:  43.668\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.503\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7988502979278564\n",
      "Epoch: 2919\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.650\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.501\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.778069496154785\n",
      "Epoch: 2920\n",
      "\tTrain Loss: 3.778 | Train PPL:  43.732\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.500\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.763599157333374\n",
      "Epoch: 2921\n",
      "\tTrain Loss: 3.764 | Train PPL:  43.103\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.498\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8016011714935303\n",
      "Epoch: 2922\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.773\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.497\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7874746322631836\n",
      "Epoch: 2923\n",
      "\tTrain Loss: 3.787 | Train PPL:  44.145\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.496\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.789447784423828\n",
      "Epoch: 2924\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.232\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.496\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8364057540893555\n",
      "Epoch: 2925\n",
      "\tTrain Loss: 3.836 | Train PPL:  46.359\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.496\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.802548885345459\n",
      "Epoch: 2926\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.815\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.495\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7864301204681396\n",
      "Epoch: 2927\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.099\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.495\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8110623359680176\n",
      "Epoch: 2928\n",
      "\tTrain Loss: 3.811 | Train PPL:  45.198\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.495\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7734837532043457\n",
      "Epoch: 2929\n",
      "\tTrain Loss: 3.773 | Train PPL:  43.531\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.495\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7945950031280518\n",
      "Epoch: 2930\n",
      "\tTrain Loss: 3.795 | Train PPL:  44.460\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.494\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7760658264160156\n",
      "Epoch: 2931\n",
      "\tTrain Loss: 3.776 | Train PPL:  43.644\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.495\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7989354133605957\n",
      "Epoch: 2932\n",
      "\tTrain Loss: 3.799 | Train PPL:  44.654\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.495\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7696568965911865\n",
      "Epoch: 2933\n",
      "\tTrain Loss: 3.770 | Train PPL:  43.365\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.495\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8050177097320557\n",
      "Epoch: 2934\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.926\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.496\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.766033411026001\n",
      "Epoch: 2935\n",
      "\tTrain Loss: 3.766 | Train PPL:  43.208\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.496\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8157379627227783\n",
      "Epoch: 2936\n",
      "\tTrain Loss: 3.816 | Train PPL:  45.410\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.495\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.809807300567627\n",
      "Epoch: 2937\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.142\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.494\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7895824909210205\n",
      "Epoch: 2938\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.238\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.493\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8104500770568848\n",
      "Epoch: 2939\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.171\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.492\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7834174633026123\n",
      "Epoch: 2940\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.966\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.492\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7970385551452637\n",
      "Epoch: 2941\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.569\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.491\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7854626178741455\n",
      "Epoch: 2942\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.056\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.491\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7619380950927734\n",
      "Epoch: 2943\n",
      "\tTrain Loss: 3.762 | Train PPL:  43.032\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.491\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.808032512664795\n",
      "Epoch: 2944\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.062\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.490\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8028385639190674\n",
      "Epoch: 2945\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.828\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.489\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.788311004638672\n",
      "Epoch: 2946\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.182\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.488\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7793400287628174\n",
      "Epoch: 2947\n",
      "\tTrain Loss: 3.779 | Train PPL:  43.787\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.488\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7650136947631836\n",
      "Epoch: 2948\n",
      "\tTrain Loss: 3.765 | Train PPL:  43.164\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.488\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8008458614349365\n",
      "Epoch: 2949\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.739\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.488\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.788761615753174\n",
      "Epoch: 2950\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.202\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.487\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7960658073425293\n",
      "Epoch: 2951\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.526\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.486\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.789792060852051\n",
      "Epoch: 2952\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.247\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.485\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7927212715148926\n",
      "Epoch: 2953\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.377\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.485\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.787992238998413\n",
      "Epoch: 2954\n",
      "\tTrain Loss: 3.788 | Train PPL:  44.168\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.483\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7855355739593506\n",
      "Epoch: 2955\n",
      "\tTrain Loss: 3.786 | Train PPL:  44.059\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.482\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.817134380340576\n",
      "Epoch: 2956\n",
      "\tTrain Loss: 3.817 | Train PPL:  45.474\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.481\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.760917901992798\n",
      "Epoch: 2957\n",
      "\tTrain Loss: 3.761 | Train PPL:  42.988\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.480\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7932889461517334\n",
      "Epoch: 2958\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.402\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.479\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.763005018234253\n",
      "Epoch: 2959\n",
      "\tTrain Loss: 3.763 | Train PPL:  43.078\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.478\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8143832683563232\n",
      "Epoch: 2960\n",
      "\tTrain Loss: 3.814 | Train PPL:  45.349\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.478\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8128600120544434\n",
      "Epoch: 2961\n",
      "\tTrain Loss: 3.813 | Train PPL:  45.280\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.477\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.781966209411621\n",
      "Epoch: 2962\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.902\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.477\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.765559196472168\n",
      "Epoch: 2963\n",
      "\tTrain Loss: 3.766 | Train PPL:  43.188\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.477\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7746403217315674\n",
      "Epoch: 2964\n",
      "\tTrain Loss: 3.775 | Train PPL:  43.582\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.477\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7933270931243896\n",
      "Epoch: 2965\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.404\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.477\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7850353717803955\n",
      "Epoch: 2966\n",
      "\tTrain Loss: 3.785 | Train PPL:  44.037\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.477\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.747821807861328\n",
      "Epoch: 2967\n",
      "\tTrain Loss: 3.748 | Train PPL:  42.429\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.477\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7809832096099854\n",
      "Epoch: 2968\n",
      "\tTrain Loss: 3.781 | Train PPL:  43.859\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.478\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7928307056427\n",
      "Epoch: 2969\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.382\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.478\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.781581163406372\n",
      "Epoch: 2970\n",
      "\tTrain Loss: 3.782 | Train PPL:  43.885\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.479\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7754406929016113\n",
      "Epoch: 2971\n",
      "\tTrain Loss: 3.775 | Train PPL:  43.617\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.479\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.778334617614746\n",
      "Epoch: 2972\n",
      "\tTrain Loss: 3.778 | Train PPL:  43.743\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.478\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.752525568008423\n",
      "Epoch: 2973\n",
      "\tTrain Loss: 3.753 | Train PPL:  42.629\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.478\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7764642238616943\n",
      "Epoch: 2974\n",
      "\tTrain Loss: 3.776 | Train PPL:  43.661\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.477\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.773419141769409\n",
      "Epoch: 2975\n",
      "\tTrain Loss: 3.773 | Train PPL:  43.529\n",
      "\tVal Loss: 3.481 |  Val PPL:  32.476\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.811490535736084\n",
      "Epoch: 2976\n",
      "\tTrain Loss: 3.811 | Train PPL:  45.218\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.475\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.812185287475586\n",
      "Epoch: 2977\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.249\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.474\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.789456605911255\n",
      "Epoch: 2978\n",
      "\tTrain Loss: 3.789 | Train PPL:  44.232\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.473\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.812295436859131\n",
      "Epoch: 2979\n",
      "\tTrain Loss: 3.812 | Train PPL:  45.254\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.471\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.791581869125366\n",
      "Epoch: 2980\n",
      "\tTrain Loss: 3.792 | Train PPL:  44.326\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.470\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.776134967803955\n",
      "Epoch: 2981\n",
      "\tTrain Loss: 3.776 | Train PPL:  43.647\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.469\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7932817935943604\n",
      "Epoch: 2982\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.402\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.468\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7592339515686035\n",
      "Epoch: 2983\n",
      "\tTrain Loss: 3.759 | Train PPL:  42.916\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.466\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8096728324890137\n",
      "Epoch: 2984\n",
      "\tTrain Loss: 3.810 | Train PPL:  45.136\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.465\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7942588329315186\n",
      "Epoch: 2985\n",
      "\tTrain Loss: 3.794 | Train PPL:  44.445\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.463\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7635793685913086\n",
      "Epoch: 2986\n",
      "\tTrain Loss: 3.764 | Train PPL:  43.102\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.461\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.775404930114746\n",
      "Epoch: 2987\n",
      "\tTrain Loss: 3.775 | Train PPL:  43.615\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.460\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7828187942504883\n",
      "Epoch: 2988\n",
      "\tTrain Loss: 3.783 | Train PPL:  43.940\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.459\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.755234479904175\n",
      "Epoch: 2989\n",
      "\tTrain Loss: 3.755 | Train PPL:  42.744\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.459\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7899627685546875\n",
      "Epoch: 2990\n",
      "\tTrain Loss: 3.790 | Train PPL:  44.255\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.457\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7736072540283203\n",
      "Epoch: 2991\n",
      "\tTrain Loss: 3.774 | Train PPL:  43.537\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.456\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.816053628921509\n",
      "Epoch: 2992\n",
      "\tTrain Loss: 3.816 | Train PPL:  45.425\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.456\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.8081443309783936\n",
      "Epoch: 2993\n",
      "\tTrain Loss: 3.808 | Train PPL:  45.067\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.455\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.801737070083618\n",
      "Epoch: 2994\n",
      "\tTrain Loss: 3.802 | Train PPL:  44.779\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.455\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7959861755371094\n",
      "Epoch: 2995\n",
      "\tTrain Loss: 3.796 | Train PPL:  44.522\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.455\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7564005851745605\n",
      "Epoch: 2996\n",
      "\tTrain Loss: 3.756 | Train PPL:  42.794\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.455\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.805324077606201\n",
      "Epoch: 2997\n",
      "\tTrain Loss: 3.805 | Train PPL:  44.940\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.454\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.7692365646362305\n",
      "Epoch: 2998\n",
      "\tTrain Loss: 3.769 | Train PPL:  43.347\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.454\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.796964645385742\n",
      "Epoch: 2999\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.566\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.454\n",
      "\tBLEU Score: 0.000\n",
      "step : 0.0 % , loss : 3.800527334213257\n",
      "Epoch: 3000\n",
      "\tTrain Loss: 3.801 | Train PPL:  44.725\n",
      "\tVal Loss: 3.480 |  Val PPL:  32.453\n",
      "\tBLEU Score: 0.000\n"
     ]
    }
   ],
   "source": [
    "run(total_epoch = 1000, best_loss = inf, best_bleu = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "['chuyên_gia', 'chuyên_gia', 'chuyên_gia', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'về', 'biến_đổi', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['trong', '4', 'phút', ',', 'chuyên_gia', 'hoá_học', 'khí_quyển', 'rachel', 'pike', 'giới_thiệu', 'sơ_lược', 'về', 'những', 'nỗ_lực', 'khoa_học', 'miệt_mài', 'đằng', 'sau', 'những', 'tiêu_đề', 'táo_bạo', 'về', 'biến_đổi', 'khí_hậu', ',', 'cùng', 'với', 'đoàn', 'nghiên_cứu', 'của', 'mình', '-', '-', 'hàng', 'ngàn', 'người', 'đã', 'cống_hiến', 'cho', 'dự_án', 'này', '-', '-', 'một', 'chuyến', 'bay', 'mạo_hiểm', 'qua', 'rừng_già', 'để', 'tìm_kiếm', 'thông_tin', 'về', 'một', 'phân_tử', 'then_chốt', '.']\n",
      "------------------------------\n",
      "['chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'cái', 'cái', 'cái', 'cái', 'tìm', 'suốt', 'suốt', 'suốt', 'suốt', 'suốt', 'suốt', 'suốt', 'suốt', 'suốt', 'suốt', 'suốt', 'suốt', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm', 'tìm']\n",
      "['chúng_tôi', 'tìm', 'thấy', 'một', 'tháp_canh', 'khí_hậu', 'toàn_cầu', 'ở', 'đó', ',', 'ngay', 'giữa', 'rừng', 'sâu', ',', 'và', 'chúng_tôi', 'treo', 'các', 'thiết_bị', 'nghiên_cứu', 'trị_giá', 'hàng', 'trăm', 'ngàn', 'đô_la', 'xa', 'khỏi', 'cái', 'tháp', 'để', 'tìm', 'isoprene', ',', 'và', 'tất_nhiên', 'là', 'những', 'thứ', 'khác', 'nữa', 'trong', 'suốt', 'thời_gian', 'ở', 'đó', '.']\n",
      "------------------------------\n",
      "['chúng_tôi', 'chúng_tôi', 'chúng_tôi', ',', 'sự', 'sự', 'sự', 'sự', 'sự', 'sự', 'sự', 'sự', 'sự', 'sự', 'sự', 'sự', 'sự', 'sự', 'sự', 'sự', 'sự', 'sự', 'sự', 'từ', 'từ', 'từ', 'từ', 'từ', 'từ', 'từ', 'từ', 'từ', 'từ', 'từ', 'từ', 'từ', 'từ', 'nhiên_liệu', 'nhiên_liệu', 'nhiên_liệu', 'nhiên_liệu', 'nhiên_liệu', 'nhiên_liệu', 'nhiên_liệu', 'nhiên_liệu', 'nhiên_liệu', 'từ', 'từ', 'từ', 'từ', 'từ', 'từ', 'từ', 'từ', 'từ', 'từ', 'từ', 'từ']\n",
      "['với', 'chúng_tôi', ',', 'tại', 'cambridge', ',', 'các', 'đề_tài', 'thay_đổi', 'từ', 'sự', 'dao_động', 'của', 'el_niño', ',', 'vốn', 'có', 'tác_động', 'đến', 'thời_tiết', 'và', 'khí_hậu', ',', 'sự', 'đồng_hoá', 'thông_tin', 'từ', 'vệ_tinh', ',', 'khí_thải', 'từ', 'những', 'cánh', 'đồng', 'nhiên_liệu', 'sinh_học', ',', 'tình_cờ', 'lại', 'là', 'đề_tài', 'tôi', 'nghiên_cứu', '.']\n",
      "------------------------------\n",
      "['lĩnh_vực', 'lĩnh_vực', 'lĩnh_vực', 'lĩnh_vực', 'lĩnh_vực', 'lĩnh_vực', 'lĩnh_vực', 'lĩnh_vực', 'lĩnh_vực', 'những', 'những', 'những', 'những', 'những', 'những', ',', ',', ',', ',', 'như', 'như', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'vài', 'vài', 'vài', 'vài', 'vài', 'vài', 'vài', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể', 'cụ_thể']\n",
      "['mỗi', 'lĩnh_vực', 'nghiên_cứu', 'lại', 'chia', 'ra', 'những', 'lĩnh_vực', 'nhỏ', 'hơn', ',', 'và', 'những', 'nghiên_cứu_sinh', 'có', 'bằng', 'tiến_sĩ', ',', 'như', 'tôi', ',', 'phải', 'nghiên_cứu', 'những', 'đề_tài', 'vô_cùng', 'cụ_thể', ',', 'cụ_thể', 'như', 'chỉ', 'vài', 'quy_trình', 'hay', 'vài', 'phân_tử', '.']\n",
      "------------------------------\n",
      "['một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['khi', 'một', 'phần', 'kiến_thức', 'dần', 'định_hình', ',', 'nó', 'sẽ', 'tạo', 'thành', 'một', 'tiểu', 'mục', ',', 'hay', 'một', 'tiểu', '-', 'tiểu_mục', 'trong', 'một', 'bản', 'kiểm_định', 'như', 'ở', 'ipcc', ',', 'mặc_dù', 'còn', 'có', 'nhiều', 'bài', 'khác', '.']\n",
      "------------------------------\n",
      "['một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', 'một', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['một', 'trong', 'số', 'những', 'phân_tử', 'tôi', 'nghiên_cứu', 'tên', 'là', 'isoprene', '.', 'đây', '.', 'nó', 'là', 'một', 'phân_tử', 'hữu_cơ', 'nhỏ', '.', 'có_thể', 'các', 'bạn', 'cũng', 'chưa', 'từng', 'nghe', 'tên', '.']\n",
      "------------------------------\n",
      "['thế', 'thế', 'thế', 'thế', 'thế', 'này', 'này', 'này', 'này', 'này', 'này', 'này', 'này', 'này', 'này', 'này', 'này', 'là', 'là', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#']\n",
      "['đó', 'là', 'cả', 'một', 'cộng_đồng', 'lớn', ',', 'lớn', 'đến_nỗi', 'trên', 'thực_tế', 'cuộc', 'tụ_hội', 'hằng', 'năm', 'của', 'chúng_tôi', 'là', 'hội_nghị', 'khoa_học', '&', '#', '91', ';', 'tự_nhiên', '&', '#', '93', ';', 'lớn', 'nhất', 'thế_giới', '.']\n",
      "------------------------------\n",
      "['thế', 'thế', 'thế', 'thế', 'thế', 'này', 'này', 'này', 'này', 'này', 'này', 'này', 'này', 'này', 'này', 'này', 'này', 'là', 'là', 'là', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#']\n",
      "['các', 'tiêu_đề', 'gần', 'đây', 'trông', 'như', 'thế', 'này', 'khi', 'ban', 'điều_hành', 'biến_đổi', 'khí_hậu', 'liên', 'chính_phủ', ',', 'gọi', 'tắt', 'là', 'ipcc', 'đưa', 'ra', 'bài', 'nghiên_cứu', 'của', 'họ', 'về', 'hệ_thống', 'khí_quyển', '.']\n",
      "------------------------------\n",
      "['thế', 'thế', 'thế', 'thế', 'thế', 'thế', 'thế', 'thế', 'này', 'này', 'này', 'này', 'này', 'này', 'này', 'này', 'này', 'này', 'là', 'về', 'về', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#']\n",
      "['có', 'những', 'dòng', 'trông', 'như', 'thế', 'này', 'khi', 'bàn', 'về', 'biến_đổi', 'khí_hậu', ',', 'và', 'như', 'thế', 'này', 'khi', 'nói', 'về', 'chất_lượng', 'không_khí', 'hay', 'khói', 'bụi', '.']\n",
      "------------------------------\n",
      "['chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'bay', 'bay', 'bay', 'bay', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['chúng_tôi', 'không', 'chỉ', 'bay', '.', 'chúng_tôi', 'bay', 'cách', 'tầng', 'vòm', 'của', 'rừng', '100', 'mét', 'để', 'đo_đạc', 'phân_tử', 'này', '-', '-', 'chuyện', 'vô_cùng', 'nguy_hiểm', '.']\n",
      "------------------------------\n",
      "['chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'bản', 'bản', 'bản', 'bản', 'bản', 'bản', 'bản', 'viết', 'viết', 'viết', 'ngang_ngửa', 'vẫy', '-', '-', '-', '-', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['dù', 'trọng_lượng', 'phân_tử', 'rất', 'nhỏ', ',', 'thế', 'nhưng', 'lượng', 'isoprene', 'được', 'thải', 'vào', 'khí_quyển', 'hàng', 'năm', 'ngang_ngửa', 'với', 'tổng', 'trọng_lượng', 'của', 'dân_số', 'toàn_cầu', '.']\n",
      "------------------------------\n",
      "['bạn', 'bạn', 'bạn', 'bạn', 'bạn', 'các', 'các', 'các', 'các', 'các', 'các', 'các', 'đã', 'đã', 'đã', 'đã', 'và', 'và', 'và', 'thấy', 'thấy', 'thấy', 'thấy', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['tôi', 'muốn', 'cho', 'các', 'bạn', 'biết', 'về', 'sự', 'to_lớn', 'của', 'những', 'nỗ_lực', 'khoa_học', 'đã', 'góp_phần', 'làm_nên', 'các', 'dòng', 'tít', 'bạn', 'thường', 'thấy', 'trên', 'báo', '.']\n",
      "------------------------------\n",
      "['khi', 'khi', 'khi', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', 'về', 'về', 'về']\n",
      "['khi', 'nghiên_cứu_sinh', 'như', 'tôi', 'có', 'sở_thích', 'hay', 'hiểu_biết', 'về', 'phân_tử', 'đó', ',', 'đại_loại', 'như', 'thế', ',', 'họ', 'sẽ', 'viết', 'cả', 'một', 'bài', 'nghiên_cứu', 'khoa_học', 'về', 'đề_tài', 'đó', '.']\n",
      "------------------------------\n",
      "['đây', 'đây', 'đây', 'quot', 'quot', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['trọng_lượng', 'của', 'một', 'chiếc', 'kẹp', 'giấy', 'vào_khoảng', '900', 'zeta', '-', 'illion', '-', '-', '10', 'mũ', '21', '-', '-', 'phân_tử', 'isoprene', '.']\n",
      "------------------------------\n",
      "['là', 'là', 'vì_vậy', 'không', 'không', 'không', 'không', 'không', 'không', 'không', 'không', 'không', 'không', 'không', 'không', 'nào', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['vì_vậy', ',', 'bạn', 'có_thể_hình_dung', ',', 'bên', 'trong', 'đó', 'hoàn_toàn', 'không', 'giống', 'với', 'bất_kỳ', 'chiếc', 'máy_bay', 'du_lịch', 'nào', 'khác', '.']\n",
      "------------------------------\n",
      "['chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'và', 'và', 'và', 'tá', 'tá', 'tá', 'tá', 'tá', 'tá', 'tá', 'tá', 'tá', 'tá', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['và', 'ngoài', 'cuộc', 'khảo_sát', 'đó', 'chúng_tôi', 'sẽ', 'còn', 'hàng', 'tá', 'bài', 'nghiên_cứu', 'về', 'hàng', 'tá', 'các', 'quy_trình', 'hay', 'phân_tử', '.']\n",
      "------------------------------\n",
      "['khi', 'khi', 'chính', 'được', 'được', 'được', 'được', 'được', ',', 'được', 'được', 'được', 'được', '2g', 'này', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['chính', 'vì', 'nó', 'có', 'ý_nghĩa', 'quan_trọng', 'với', 'hệ_thống', 'khí_quyển', ',', 'giá', 'nào', 'chúng_tôi', 'cũng', 'theo_đuổi', 'nghiên_cứu', 'này', 'đến', 'cùng', '.']\n",
      "------------------------------\n",
      "['đều', 'đều', 'đều', 'đều', 'đều', 'đều', 'và', 'và', 'nghiên_cứu', 'nghiên_cứu', 'nghiên_cứu', 'nghiên_cứu', 'nghiên_cứu', 'tá', 'tá', 'tá', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['mỗi_một', 'khoa_học', 'gia', 'đều', 'thuộc', 'một', 'nhóm', 'nghiên_cứu', ',', 'và', 'mỗi', 'nhóm', 'đều', 'nghiên_cứu', 'rất', 'nhiều', 'đề_tài', 'đa_dạng', '.']\n",
      "------------------------------\n",
      "[',', ',', ',', ',', ',', ',', 'sở_hữu', 'sở_hữu', 'sở_hữu', 'sở_hữu', 'sở_hữu', '130', '130', '130', '130', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['chiếc', 'phi_cơ', 'này', ',', 'mẫu', 'ba146', 'do', 'faam', 'sở_hữu', 'thông_thường', 'có_thể', 'chở', 'từ', '120', '-', '130', 'người', '.']\n",
      "------------------------------\n",
      "['khi', 'khi', 'khi', 'được', 'được', 'được', 'được', ',', ',', 'được', 'được', 'và', 'và', '2g', 'này', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['và', 'tất_cả', 'các', 'trang', 'đều', 'được', 'xem_xét', 'bởi', '400', 'khoa_học', 'gia', 'và', 'nhà', 'phê_bình', 'khác', 'từ', '113', 'quốc_gia', '.']\n",
      "------------------------------\n",
      "['họ', 'họ', ',', ',', ',', ',', ',', ',', ',', ',', 'đường', 'đường', 'đường', 'đường', '.']\n",
      "['các', 'nhà', 'khoa_học', 'phải', 'được', 'thắt', 'chặt', 'hoàn_toàn', 'vào', 'ghế', 'để', 'có_thể', 'thực_hiện', 'đo_đạc', 'trên', 'máy_bay', '.']\n",
      "------------------------------\n",
      "['khi', 'khi', 'khi', 'được', 'được', ',', ',', ',', ',', ',', ',', 'và', 'tác_động', '2g', 'này', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['khi', 'bay', 'quanh', 'những', 'bờ', 'sông', 'ở', 'thung_lũng', ',', 'các', 'lực', 'tác_động', 'có_thể', 'lên', 'tới', '2g', '.']\n",
      "------------------------------\n",
      "['lượng', 'lượng', 'lượng', 'lượng', ',', ',', ',', ',', ',', ',', ',', 'với', 'những', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['mô_hình', 'của', 'chúng_tôi', 'gồm', 'hàng', 'trăm', 'ngàn', 'thùng', 'xếp', 'chồng', 'tính_toán', 'với', 'hàng', 'trăm', 'biến_số', 'trong', 'thời_gian', 'cực', 'ngắn', '.']\n",
      "------------------------------\n",
      "['là', 'là', 'lượng', 'lượng', ',', ',', ',', ',', ',', ',', ',', 'với', 'với', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['nổ', 'trong', 'không_khí', 'hay', 'cháy', 'hoàn_toàn', 'diễn', 'ra', 'chậm', 'hơn', '15,000', 'lần', 'so', 'với', 'những', 'phản_ứng', 'trong', 'động_cơ', 'xe', '.']\n",
      "------------------------------\n",
      "['cần', 'cần', 'cần', 'cần', 'cần', 'chương', 'chương', 'chương', 'đến', 'đến', 'đến', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['mỗi_một', 'chương', 'trong', '11', 'chương', 'của', 'ipcc', 'có', 'từ', '6', 'đến', '10', 'tiểu', 'mục', 'như', 'thế', '.']\n",
      "------------------------------\n",
      "['là', 'là', 'là', 'là', ',', ',', ',', ',', ',', ',', 'với', 'với', 'những', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['đó', 'là', 'cả', 'một', 'phòng', 'thí_nghiệm', 'di_động', 'để', 'giúp', 'chúng_tôi', 'thực_hiện', 'các', 'phép', 'đo', '.']\n",
      "------------------------------\n",
      "['lượng', 'lượng', 'lượng', 'lượng', ',', ',', ',', ',', ',', ',', 'với', 'với', 'những', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['chính', 'vì', 'lượng', 'khí_thải', 'rất', 'lớn', ',', 'nó', 'có', 'ý_nghĩa', 'quan_trọng', 'với', 'hệ_thống', 'khí_quyển', '.']\n",
      "------------------------------\n",
      "['là', 'là', 'là', 'là', ',', ',', ',', ',', ',', ',', 'với', 'với', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['đó', 'là', 'một', 'lượng', 'khí_thải', 'khổng_lồ', ',', 'bằng', 'tổng', 'trọng_lượng', 'của', 'mêtan', '.']\n",
      "------------------------------\n",
      "['chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'để', 'để', 'để', '.', '.', '.', '.', '.']\n",
      "['chúng_tôi', 'cần', 'làm_hàng', 'tá', 'phép_tính', 'như', 'thế', 'để', 'hiểu', 'được', 'những', 'gì', 'đang', 'xảy', 'ra', '.']\n",
      "------------------------------\n",
      "['đây', 'đây', 'đây', 'đây', 'một', 'một', 'một', 'một', 'một', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['gần', 'đây', 'tôi', 'tham_gia', 'một', 'cuộc', 'khảo_sát', 'thực_địa', 'ở', 'malaysia', '.', 'còn', 'nhiều', 'chuyến', 'khác', 'nữa', '.']\n",
      "------------------------------\n",
      "['chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'từ', 'từ', 'từ', 'từ', '.', '.', '.', '.']\n",
      "['chúng_tôi', 'chạy', 'những', 'mô_hình', 'khổng_lồ', 'trên', 'siêu', 'máy_tính', ';', 'đây', 'là', 'công_việc', 'của', 'tôi', '.']\n",
      "------------------------------\n",
      "['tôi', 'tôi', 'tôi', 'não', 'não', ',', ',', ',', ',', ',', '.', '.']\n",
      "['đây', 'chính', 'là', 'cái', 'tháp', 'giữa', 'rừng', 'sâu', ',', 'nhìn', 'từ', 'trên', 'cao', '.']\n",
      "------------------------------\n",
      "['chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'để', 'từ', 'từ', '.', '.', '.', '.', '.']\n",
      "['chúng_tôi', 'phải', 'bay', 'với', 'độ', 'nghiêng', 'đặc_biệt', 'để', 'thực_hiện', 'các', 'phép', 'đo', '.']\n",
      "------------------------------\n",
      "['đây', 'đây', 'đây', 'đây', 'một', 'một', 'một', 'một', 'một', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['cả', 'hai', 'đều', 'là', 'một', 'nhánh', 'của', 'cùng', 'một', 'lĩnh_vực', 'trong', 'ngành', 'khoa_học', 'khí_quyển', '.']\n",
      "------------------------------\n",
      "['có_thể', 'có_thể', 'có_thể', 'họ', 'một', 'một', 'này', 'này', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['rất', 'có_thể', 'bạn', 'đã', 'ở', 'trên', 'một', 'chiếc', 'tương_tự', 'khi', 'đến', 'đây', 'hôm_nay', '.']\n",
      "------------------------------\n",
      "['có_thể', 'có_thể', 'có_thể', 'họ', 'một', 'một', 'này', 'này', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['mỗi', 'năm', ',', 'hơn', '15,000', 'nhà', 'khoa_học', 'đến', 'san_francisco', 'để', 'tham_dự', 'hội_nghị', 'này', '.']\n",
      "------------------------------\n",
      "['đây', 'đây', 'đây', 'đây', 'một', 'một', 'một', 'một', 'một', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['chúng_tôi', 'làm', 'tất_cả', 'chỉ', 'để', 'tìm_hiểu', 'tính_chất', 'hoá_học', 'của', 'một', 'phân_tử', '.']\n",
      "------------------------------\n",
      "['chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'từ', 'từ', '.', '.', '.', '.', '.']\n",
      "['có', 'giai_đoạn', 'chúng_tôi', 'còn', 'mang', 'cả', 'máy_bay', 'theo', '.']\n",
      "------------------------------\n",
      "['có_thể', 'có_thể', 'có_thể', 'một', 'một', 'để', 'này', 'này', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['chúng_tôi', 'còn', 'bay', 'khắp', 'thế_giới', 'để', 'tìm', 'phân_tử', 'này', '.']\n",
      "------------------------------\n",
      "['bạn', 'bạn', 'bạn', 'bạn', 'và', 'và', 'và', 'cánh_tay']\n",
      "['nghiên_cứu', 'được', 'viết', 'bởi', '620', 'nhà', 'khoa_học', 'từ', '40', 'quốc_gia', 'khác', 'nhau', '.']\n",
      "------------------------------\n",
      "['chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'xem_xét', 'xem_xét', 'xem_xét', 'chủ_đề', 'mảnh', '.']\n",
      "['nói', 'như', 'thế', 'để', 'bạn', 'hình_dung', 'được', 'quy_mô', 'của', 'những', 'nỗ_lực', 'này', '.']\n",
      "------------------------------\n",
      "['vẫn', 'vẫn', 'vẫn', 'vẫn', 'vẫn', 'mảnh', 'mảnh', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['mà', 'vẫn', 'cần', 'hàng', 'tuần', 'mới', 'thực_hiện', 'xong', 'các', 'phép', 'tích_phân', '.']\n",
      "------------------------------\n",
      "['bạn', 'bạn', 'bạn', 'bạn', 'và', 'và', 'điều_khiển', '.']\n",
      "['phải', 'thuê', 'quân_đội', 'và', 'sát_hạch', 'phi_cơ', 'để', 'điều_khiển', 'máy_bay', '.']\n",
      "------------------------------\n",
      "['chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'xem_xét', 'xem_xét', 'xem_xét', 'từng', 'mảnh', '.']\n",
      "['chúng_tôi', 'cho', 'nó', 'nổ', 'và', 'xem_xét', 'từng', 'mảnh', 'nhỏ', '.']\n",
      "------------------------------\n",
      "['chúng_tôi', 'chúng_tôi', 'chúng_tôi', 'xem_xét', 'xem_xét', 'về', 'mảnh', '.']\n",
      "['họ', 'viết', 'gần', '1000', 'trang', 'về', 'chủ_đề', 'này', '.']\n",
      "------------------------------\n",
      "['vẫn', 'vẫn', 'vẫn', 'vẫn', 'mảnh', 'mảnh', '.', '.']\n",
      "['đây', 'là', 'phòng', 'nghiên_cứu', 'khói', 'bụi', 'euphore', 'ở', 'tây_ban_nha', '.']\n",
      "------------------------------\n",
      "['vẫn', 'vẫn', 'vẫn', 'vẫn', 'mảnh', 'mảnh', 'mảnh', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['dù_vậy', ',', 'chúng_tôi', 'vẫn', 'xem_xét', 'từng', 'mảnh', 'nhỏ', '.']\n",
      "------------------------------\n",
      "['lệnh', 'lệnh', 'lệnh', 'thực_hiện', '.']\n",
      "['phải', 'xin', 'lệnh', 'đặc_biệt', 'cho', 'phép', 'bay', '.']\n",
      "------------------------------\n",
      "['vẫn', 'vẫn', 'vẫn', 'vẫn', 'mảnh', 'mảnh', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "['khoa_học', 'đằng', 'sau', 'một', 'tiêu_đề', 'về', 'khí_hậu']\n",
      "------------------------------\n",
      "['sẽ', 'sẽ', 'lệnh', '.']\n",
      "['và', 'từ', 'dưới', 'đất', '.']\n",
      "Final result :\n",
      "3.479806900024414   [0.0]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_and_print(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    batch_bleu = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src.to(device)\n",
    "            trg = batch.trg.to(device)\n",
    "\n",
    "            output = model(src, trg[:, :-1])\n",
    "            output_reshape = output.contiguous().view(-1, output.shape[-1])\n",
    "            trg = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "            loss = criterion(output_reshape, trg)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            total_bleu = []\n",
    "            for j in range(batch_size):\n",
    "                try:\n",
    "                    trg_words = idx_to_word(batch.trg[j], loader.target.vocab)\n",
    "                    output_words = output[j].max(dim=1)[1]\n",
    "\n",
    "                    output_words = idx_to_word(output_words, loader.target.vocab)\n",
    "                    bleu = get_bleu(output_words, trg_words)\n",
    "\n",
    "                    print('-' * 30)\n",
    "                    print(output_words.split())\n",
    "                    print(trg_words.split())\n",
    "\n",
    "                    total_bleu.append(bleu)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            total_bleu = sum(total_bleu) / len(total_bleu)\n",
    "            batch_bleu.append(total_bleu)\n",
    "\n",
    "            #src = src.detach()\n",
    "            #trg = trg.detach()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    #batch_bleu = sum(batch_bleu) / len(batch_bleu)\n",
    "    print('Final result :')\n",
    "    print(epoch_loss / len(iterator),' ', batch_bleu) \n",
    "\n",
    "evaluate_and_print(model, valid_iter, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Transformer:\n\tMissing key(s) in state_dict: \"encoder.layers.2.attention.w_q.weight\", \"encoder.layers.2.attention.w_q.bias\", \"encoder.layers.2.attention.w_k.weight\", \"encoder.layers.2.attention.w_k.bias\", \"encoder.layers.2.attention.w_v.weight\", \"encoder.layers.2.attention.w_v.bias\", \"encoder.layers.2.attention.w_concat.weight\", \"encoder.layers.2.attention.w_concat.bias\", \"encoder.layers.2.ffn.linear1.weight\", \"encoder.layers.2.ffn.linear1.bias\", \"encoder.layers.2.ffn.linear2.weight\", \"encoder.layers.2.ffn.linear2.bias\", \"encoder.layers.2.norm1.gamma\", \"encoder.layers.2.norm1.beta\", \"encoder.layers.2.norm2.gamma\", \"encoder.layers.2.norm2.beta\", \"encoder.layers.3.attention.w_q.weight\", \"encoder.layers.3.attention.w_q.bias\", \"encoder.layers.3.attention.w_k.weight\", \"encoder.layers.3.attention.w_k.bias\", \"encoder.layers.3.attention.w_v.weight\", \"encoder.layers.3.attention.w_v.bias\", \"encoder.layers.3.attention.w_concat.weight\", \"encoder.layers.3.attention.w_concat.bias\", \"encoder.layers.3.ffn.linear1.weight\", \"encoder.layers.3.ffn.linear1.bias\", \"encoder.layers.3.ffn.linear2.weight\", \"encoder.layers.3.ffn.linear2.bias\", \"encoder.layers.3.norm1.gamma\", \"encoder.layers.3.norm1.beta\", \"encoder.layers.3.norm2.gamma\", \"encoder.layers.3.norm2.beta\", \"encoder.layers.4.attention.w_q.weight\", \"encoder.layers.4.attention.w_q.bias\", \"encoder.layers.4.attention.w_k.weight\", \"encoder.layers.4.attention.w_k.bias\", \"encoder.layers.4.attention.w_v.weight\", \"encoder.layers.4.attention.w_v.bias\", \"encoder.layers.4.attention.w_concat.weight\", \"encoder.layers.4.attention.w_concat.bias\", \"encoder.layers.4.ffn.linear1.weight\", \"encoder.layers.4.ffn.linear1.bias\", \"encoder.layers.4.ffn.linear2.weight\", \"encoder.layers.4.ffn.linear2.bias\", \"encoder.layers.4.norm1.gamma\", \"encoder.layers.4.norm1.beta\", \"encoder.layers.4.norm2.gamma\", \"encoder.layers.4.norm2.beta\", \"decoder.layers.2.self_attention.w_q.weight\", \"decoder.layers.2.self_attention.w_q.bias\", \"decoder.layers.2.self_attention.w_k.weight\", \"decoder.layers.2.self_attention.w_k.bias\", \"decoder.layers.2.self_attention.w_v.weight\", \"decoder.layers.2.self_attention.w_v.bias\", \"decoder.layers.2.self_attention.w_concat.weight\", \"decoder.layers.2.self_attention.w_concat.bias\", \"decoder.layers.2.enc_dec_attention.w_q.weight\", \"decoder.layers.2.enc_dec_attention.w_q.bias\", \"decoder.layers.2.enc_dec_attention.w_k.weight\", \"decoder.layers.2.enc_dec_attention.w_k.bias\", \"decoder.layers.2.enc_dec_attention.w_v.weight\", \"decoder.layers.2.enc_dec_attention.w_v.bias\", \"decoder.layers.2.enc_dec_attention.w_concat.weight\", \"decoder.layers.2.enc_dec_attention.w_concat.bias\", \"decoder.layers.2.ffn.linear1.weight\", \"decoder.layers.2.ffn.linear1.bias\", \"decoder.layers.2.ffn.linear2.weight\", \"decoder.layers.2.ffn.linear2.bias\", \"decoder.layers.2.norm1.gamma\", \"decoder.layers.2.norm1.beta\", \"decoder.layers.2.norm2.gamma\", \"decoder.layers.2.norm2.beta\", \"decoder.layers.2.norm3.gamma\", \"decoder.layers.2.norm3.beta\", \"decoder.layers.3.self_attention.w_q.weight\", \"decoder.layers.3.self_attention.w_q.bias\", \"decoder.layers.3.self_attention.w_k.weight\", \"decoder.layers.3.self_attention.w_k.bias\", \"decoder.layers.3.self_attention.w_v.weight\", \"decoder.layers.3.self_attention.w_v.bias\", \"decoder.layers.3.self_attention.w_concat.weight\", \"decoder.layers.3.self_attention.w_concat.bias\", \"decoder.layers.3.enc_dec_attention.w_q.weight\", \"decoder.layers.3.enc_dec_attention.w_q.bias\", \"decoder.layers.3.enc_dec_attention.w_k.weight\", \"decoder.layers.3.enc_dec_attention.w_k.bias\", \"decoder.layers.3.enc_dec_attention.w_v.weight\", \"decoder.layers.3.enc_dec_attention.w_v.bias\", \"decoder.layers.3.enc_dec_attention.w_concat.weight\", \"decoder.layers.3.enc_dec_attention.w_concat.bias\", \"decoder.layers.3.ffn.linear1.weight\", \"decoder.layers.3.ffn.linear1.bias\", \"decoder.layers.3.ffn.linear2.weight\", \"decoder.layers.3.ffn.linear2.bias\", \"decoder.layers.3.norm1.gamma\", \"decoder.layers.3.norm1.beta\", \"decoder.layers.3.norm2.gamma\", \"decoder.layers.3.norm2.beta\", \"decoder.layers.3.norm3.gamma\", \"decoder.layers.3.norm3.beta\", \"decoder.layers.4.self_attention.w_q.weight\", \"decoder.layers.4.self_attention.w_q.bias\", \"decoder.layers.4.self_attention.w_k.weight\", \"decoder.layers.4.self_attention.w_k.bias\", \"decoder.layers.4.self_attention.w_v.weight\", \"decoder.layers.4.self_attention.w_v.bias\", \"decoder.layers.4.self_attention.w_concat.weight\", \"decoder.layers.4.self_attention.w_concat.bias\", \"decoder.layers.4.enc_dec_attention.w_q.weight\", \"decoder.layers.4.enc_dec_attention.w_q.bias\", \"decoder.layers.4.enc_dec_attention.w_k.weight\", \"decoder.layers.4.enc_dec_attention.w_k.bias\", \"decoder.layers.4.enc_dec_attention.w_v.weight\", \"decoder.layers.4.enc_dec_attention.w_v.bias\", \"decoder.layers.4.enc_dec_attention.w_concat.weight\", \"decoder.layers.4.enc_dec_attention.w_concat.bias\", \"decoder.layers.4.ffn.linear1.weight\", \"decoder.layers.4.ffn.linear1.bias\", \"decoder.layers.4.ffn.linear2.weight\", \"decoder.layers.4.ffn.linear2.bias\", \"decoder.layers.4.norm1.gamma\", \"decoder.layers.4.norm1.beta\", \"decoder.layers.4.norm2.gamma\", \"decoder.layers.4.norm2.beta\", \"decoder.layers.4.norm3.gamma\", \"decoder.layers.4.norm3.beta\". \n\tsize mismatch for encoder.emb.tok_emb.weight: copying a param with shape torch.Size([561, 128]) from checkpoint, the shape in current model is torch.Size([561, 512]).\n\tsize mismatch for encoder.layers.0.attention.w_q.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.layers.0.attention.w_q.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.0.attention.w_k.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.layers.0.attention.w_k.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.0.attention.w_v.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.layers.0.attention.w_v.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.0.attention.w_concat.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.layers.0.attention.w_concat.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.0.ffn.linear1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 512]).\n\tsize mismatch for encoder.layers.0.ffn.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layers.0.ffn.linear2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 256]).\n\tsize mismatch for encoder.layers.0.ffn.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.0.norm1.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.0.norm1.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.0.norm2.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.0.norm2.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.attention.w_q.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.layers.1.attention.w_q.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.attention.w_k.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.layers.1.attention.w_k.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.attention.w_v.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.layers.1.attention.w_v.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.attention.w_concat.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.layers.1.attention.w_concat.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.ffn.linear1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 512]).\n\tsize mismatch for encoder.layers.1.ffn.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layers.1.ffn.linear2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 256]).\n\tsize mismatch for encoder.layers.1.ffn.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.norm1.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.norm1.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.norm2.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.norm2.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.emb.tok_emb.weight: copying a param with shape torch.Size([563, 128]) from checkpoint, the shape in current model is torch.Size([563, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.w_q.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.w_q.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.self_attention.w_k.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.w_k.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.self_attention.w_v.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.w_v.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.self_attention.w_concat.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.w_concat.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.enc_dec_attention.w_q.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.enc_dec_attention.w_q.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.enc_dec_attention.w_k.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.enc_dec_attention.w_k.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.enc_dec_attention.w_v.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.enc_dec_attention.w_v.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.enc_dec_attention.w_concat.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.enc_dec_attention.w_concat.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.ffn.linear1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 512]).\n\tsize mismatch for decoder.layers.0.ffn.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder.layers.0.ffn.linear2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 256]).\n\tsize mismatch for decoder.layers.0.ffn.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm1.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm1.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm2.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm2.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm3.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm3.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.self_attention.w_q.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.1.self_attention.w_q.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.self_attention.w_k.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.1.self_attention.w_k.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.self_attention.w_v.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.1.self_attention.w_v.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.self_attention.w_concat.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.1.self_attention.w_concat.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.enc_dec_attention.w_q.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.1.enc_dec_attention.w_q.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.enc_dec_attention.w_k.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.1.enc_dec_attention.w_k.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.enc_dec_attention.w_v.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.1.enc_dec_attention.w_v.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.enc_dec_attention.w_concat.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.1.enc_dec_attention.w_concat.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.ffn.linear1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 512]).\n\tsize mismatch for decoder.layers.1.ffn.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder.layers.1.ffn.linear2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 256]).\n\tsize mismatch for decoder.layers.1.ffn.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.norm1.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.norm1.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.norm2.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.norm2.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.norm3.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.norm3.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.linear.weight: copying a param with shape torch.Size([563, 128]) from checkpoint, the shape in current model is torch.Size([563, 512]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m     loaded_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(f \u001b[38;5;241m=\u001b[39m path))\n\u001b[1;32m     17\u001b[0m     evaluate_and_print(loaded_model, valid_iter, criterion)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/dominhnhat/Pose_Estimation/MFSvi/debug/models/best_bleu.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     21\u001b[0m test_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/dominhnhat/Pose_Estimation/MFSvi/debug/models/best_loss.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m Transformer(src_pad_idx\u001b[38;5;241m=\u001b[39msrc_pad_idx,\n\u001b[1;32m      3\u001b[0m                     trg_pad_idx\u001b[38;5;241m=\u001b[39mtrg_pad_idx,\n\u001b[1;32m      4\u001b[0m                     trg_sos_idx\u001b[38;5;241m=\u001b[39mtrg_sos_idx,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m                     n_layers\u001b[38;5;241m=\u001b[39mn_layers,\n\u001b[1;32m     12\u001b[0m                     drop_prob\u001b[38;5;241m=\u001b[39mdrop_prob)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(model_path)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m evaluate_and_print(loaded_model, valid_iter, criterion)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Transformer:\n\tMissing key(s) in state_dict: \"encoder.layers.2.attention.w_q.weight\", \"encoder.layers.2.attention.w_q.bias\", \"encoder.layers.2.attention.w_k.weight\", \"encoder.layers.2.attention.w_k.bias\", \"encoder.layers.2.attention.w_v.weight\", \"encoder.layers.2.attention.w_v.bias\", \"encoder.layers.2.attention.w_concat.weight\", \"encoder.layers.2.attention.w_concat.bias\", \"encoder.layers.2.ffn.linear1.weight\", \"encoder.layers.2.ffn.linear1.bias\", \"encoder.layers.2.ffn.linear2.weight\", \"encoder.layers.2.ffn.linear2.bias\", \"encoder.layers.2.norm1.gamma\", \"encoder.layers.2.norm1.beta\", \"encoder.layers.2.norm2.gamma\", \"encoder.layers.2.norm2.beta\", \"encoder.layers.3.attention.w_q.weight\", \"encoder.layers.3.attention.w_q.bias\", \"encoder.layers.3.attention.w_k.weight\", \"encoder.layers.3.attention.w_k.bias\", \"encoder.layers.3.attention.w_v.weight\", \"encoder.layers.3.attention.w_v.bias\", \"encoder.layers.3.attention.w_concat.weight\", \"encoder.layers.3.attention.w_concat.bias\", \"encoder.layers.3.ffn.linear1.weight\", \"encoder.layers.3.ffn.linear1.bias\", \"encoder.layers.3.ffn.linear2.weight\", \"encoder.layers.3.ffn.linear2.bias\", \"encoder.layers.3.norm1.gamma\", \"encoder.layers.3.norm1.beta\", \"encoder.layers.3.norm2.gamma\", \"encoder.layers.3.norm2.beta\", \"encoder.layers.4.attention.w_q.weight\", \"encoder.layers.4.attention.w_q.bias\", \"encoder.layers.4.attention.w_k.weight\", \"encoder.layers.4.attention.w_k.bias\", \"encoder.layers.4.attention.w_v.weight\", \"encoder.layers.4.attention.w_v.bias\", \"encoder.layers.4.attention.w_concat.weight\", \"encoder.layers.4.attention.w_concat.bias\", \"encoder.layers.4.ffn.linear1.weight\", \"encoder.layers.4.ffn.linear1.bias\", \"encoder.layers.4.ffn.linear2.weight\", \"encoder.layers.4.ffn.linear2.bias\", \"encoder.layers.4.norm1.gamma\", \"encoder.layers.4.norm1.beta\", \"encoder.layers.4.norm2.gamma\", \"encoder.layers.4.norm2.beta\", \"decoder.layers.2.self_attention.w_q.weight\", \"decoder.layers.2.self_attention.w_q.bias\", \"decoder.layers.2.self_attention.w_k.weight\", \"decoder.layers.2.self_attention.w_k.bias\", \"decoder.layers.2.self_attention.w_v.weight\", \"decoder.layers.2.self_attention.w_v.bias\", \"decoder.layers.2.self_attention.w_concat.weight\", \"decoder.layers.2.self_attention.w_concat.bias\", \"decoder.layers.2.enc_dec_attention.w_q.weight\", \"decoder.layers.2.enc_dec_attention.w_q.bias\", \"decoder.layers.2.enc_dec_attention.w_k.weight\", \"decoder.layers.2.enc_dec_attention.w_k.bias\", \"decoder.layers.2.enc_dec_attention.w_v.weight\", \"decoder.layers.2.enc_dec_attention.w_v.bias\", \"decoder.layers.2.enc_dec_attention.w_concat.weight\", \"decoder.layers.2.enc_dec_attention.w_concat.bias\", \"decoder.layers.2.ffn.linear1.weight\", \"decoder.layers.2.ffn.linear1.bias\", \"decoder.layers.2.ffn.linear2.weight\", \"decoder.layers.2.ffn.linear2.bias\", \"decoder.layers.2.norm1.gamma\", \"decoder.layers.2.norm1.beta\", \"decoder.layers.2.norm2.gamma\", \"decoder.layers.2.norm2.beta\", \"decoder.layers.2.norm3.gamma\", \"decoder.layers.2.norm3.beta\", \"decoder.layers.3.self_attention.w_q.weight\", \"decoder.layers.3.self_attention.w_q.bias\", \"decoder.layers.3.self_attention.w_k.weight\", \"decoder.layers.3.self_attention.w_k.bias\", \"decoder.layers.3.self_attention.w_v.weight\", \"decoder.layers.3.self_attention.w_v.bias\", \"decoder.layers.3.self_attention.w_concat.weight\", \"decoder.layers.3.self_attention.w_concat.bias\", \"decoder.layers.3.enc_dec_attention.w_q.weight\", \"decoder.layers.3.enc_dec_attention.w_q.bias\", \"decoder.layers.3.enc_dec_attention.w_k.weight\", \"decoder.layers.3.enc_dec_attention.w_k.bias\", \"decoder.layers.3.enc_dec_attention.w_v.weight\", \"decoder.layers.3.enc_dec_attention.w_v.bias\", \"decoder.layers.3.enc_dec_attention.w_concat.weight\", \"decoder.layers.3.enc_dec_attention.w_concat.bias\", \"decoder.layers.3.ffn.linear1.weight\", \"decoder.layers.3.ffn.linear1.bias\", \"decoder.layers.3.ffn.linear2.weight\", \"decoder.layers.3.ffn.linear2.bias\", \"decoder.layers.3.norm1.gamma\", \"decoder.layers.3.norm1.beta\", \"decoder.layers.3.norm2.gamma\", \"decoder.layers.3.norm2.beta\", \"decoder.layers.3.norm3.gamma\", \"decoder.layers.3.norm3.beta\", \"decoder.layers.4.self_attention.w_q.weight\", \"decoder.layers.4.self_attention.w_q.bias\", \"decoder.layers.4.self_attention.w_k.weight\", \"decoder.layers.4.self_attention.w_k.bias\", \"decoder.layers.4.self_attention.w_v.weight\", \"decoder.layers.4.self_attention.w_v.bias\", \"decoder.layers.4.self_attention.w_concat.weight\", \"decoder.layers.4.self_attention.w_concat.bias\", \"decoder.layers.4.enc_dec_attention.w_q.weight\", \"decoder.layers.4.enc_dec_attention.w_q.bias\", \"decoder.layers.4.enc_dec_attention.w_k.weight\", \"decoder.layers.4.enc_dec_attention.w_k.bias\", \"decoder.layers.4.enc_dec_attention.w_v.weight\", \"decoder.layers.4.enc_dec_attention.w_v.bias\", \"decoder.layers.4.enc_dec_attention.w_concat.weight\", \"decoder.layers.4.enc_dec_attention.w_concat.bias\", \"decoder.layers.4.ffn.linear1.weight\", \"decoder.layers.4.ffn.linear1.bias\", \"decoder.layers.4.ffn.linear2.weight\", \"decoder.layers.4.ffn.linear2.bias\", \"decoder.layers.4.norm1.gamma\", \"decoder.layers.4.norm1.beta\", \"decoder.layers.4.norm2.gamma\", \"decoder.layers.4.norm2.beta\", \"decoder.layers.4.norm3.gamma\", \"decoder.layers.4.norm3.beta\". \n\tsize mismatch for encoder.emb.tok_emb.weight: copying a param with shape torch.Size([561, 128]) from checkpoint, the shape in current model is torch.Size([561, 512]).\n\tsize mismatch for encoder.layers.0.attention.w_q.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.layers.0.attention.w_q.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.0.attention.w_k.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.layers.0.attention.w_k.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.0.attention.w_v.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.layers.0.attention.w_v.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.0.attention.w_concat.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.layers.0.attention.w_concat.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.0.ffn.linear1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 512]).\n\tsize mismatch for encoder.layers.0.ffn.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layers.0.ffn.linear2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 256]).\n\tsize mismatch for encoder.layers.0.ffn.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.0.norm1.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.0.norm1.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.0.norm2.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.0.norm2.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.attention.w_q.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.layers.1.attention.w_q.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.attention.w_k.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.layers.1.attention.w_k.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.attention.w_v.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.layers.1.attention.w_v.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.attention.w_concat.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.layers.1.attention.w_concat.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.ffn.linear1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 512]).\n\tsize mismatch for encoder.layers.1.ffn.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layers.1.ffn.linear2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 256]).\n\tsize mismatch for encoder.layers.1.ffn.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.norm1.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.norm1.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.norm2.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layers.1.norm2.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.emb.tok_emb.weight: copying a param with shape torch.Size([563, 128]) from checkpoint, the shape in current model is torch.Size([563, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.w_q.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.w_q.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.self_attention.w_k.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.w_k.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.self_attention.w_v.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.w_v.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.self_attention.w_concat.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.w_concat.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.enc_dec_attention.w_q.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.enc_dec_attention.w_q.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.enc_dec_attention.w_k.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.enc_dec_attention.w_k.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.enc_dec_attention.w_v.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.enc_dec_attention.w_v.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.enc_dec_attention.w_concat.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.enc_dec_attention.w_concat.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.ffn.linear1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 512]).\n\tsize mismatch for decoder.layers.0.ffn.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder.layers.0.ffn.linear2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 256]).\n\tsize mismatch for decoder.layers.0.ffn.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm1.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm1.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm2.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm2.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm3.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm3.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.self_attention.w_q.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.1.self_attention.w_q.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.self_attention.w_k.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.1.self_attention.w_k.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.self_attention.w_v.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.1.self_attention.w_v.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.self_attention.w_concat.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.1.self_attention.w_concat.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.enc_dec_attention.w_q.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.1.enc_dec_attention.w_q.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.enc_dec_attention.w_k.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.1.enc_dec_attention.w_k.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.enc_dec_attention.w_v.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.1.enc_dec_attention.w_v.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.enc_dec_attention.w_concat.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.1.enc_dec_attention.w_concat.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.ffn.linear1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 512]).\n\tsize mismatch for decoder.layers.1.ffn.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder.layers.1.ffn.linear2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 256]).\n\tsize mismatch for decoder.layers.1.ffn.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.norm1.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.norm1.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.norm2.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.norm2.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.norm3.gamma: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.1.norm3.beta: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.linear.weight: copying a param with shape torch.Size([563, 128]) from checkpoint, the shape in current model is torch.Size([563, 512])."
     ]
    }
   ],
   "source": [
    "def test_model(model_path):\n",
    "    loaded_model = Transformer(src_pad_idx=src_pad_idx,\n",
    "                        trg_pad_idx=trg_pad_idx,\n",
    "                        trg_sos_idx=trg_sos_idx,\n",
    "                        d_model=d_model,\n",
    "                        enc_voc_size=enc_voc_size,\n",
    "                        dec_voc_size=dec_voc_size,\n",
    "                        max_len=max_len,\n",
    "                        ffn_hidden=ffn_hidden,\n",
    "                        n_head=n_heads,\n",
    "                        n_layers=n_layers,\n",
    "                        drop_prob=drop_prob).to(device)\n",
    "\n",
    "    path = Path(model_path)\n",
    "    loaded_model.load_state_dict(torch.load(f = path))\n",
    "\n",
    "    evaluate_and_print(loaded_model, valid_iter, criterion)\n",
    "\n",
    "test_model('/home/dominhnhat/Pose_Estimation/MFSvi/debug/models/best_bleu.pth')\n",
    "print('\\n' * 3)\n",
    "test_model('/home/dominhnhat/Pose_Estimation/MFSvi/debug/models/best_loss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
